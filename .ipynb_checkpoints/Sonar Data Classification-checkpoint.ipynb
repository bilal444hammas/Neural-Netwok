{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import layers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score,StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
       "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
       "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
       "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
       "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
       "\n",
       "         9   ...      51      52      53      54      55      56      57  \\\n",
       "0    0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1    0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2    0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3    0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4    0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.2684  ...  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065  0.0115   \n",
       "204  0.2154  ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n",
       "205  0.2529  ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n",
       "206  0.2354  ...  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034  0.0079   \n",
       "207  0.2354  ...  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040  0.0036   \n",
       "\n",
       "         58      59  60  \n",
       "0    0.0090  0.0032   R  \n",
       "1    0.0052  0.0044   R  \n",
       "2    0.0095  0.0078   R  \n",
       "3    0.0040  0.0117   R  \n",
       "4    0.0107  0.0094   R  \n",
       "..      ...     ...  ..  \n",
       "203  0.0193  0.0157   M  \n",
       "204  0.0062  0.0067   M  \n",
       "205  0.0077  0.0031   M  \n",
       "206  0.0036  0.0048   M  \n",
       "207  0.0061  0.0115   M  \n",
       "\n",
       "[208 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"sonar.csv\", header = None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.1117</td>\n",
       "      <td>0.1506</td>\n",
       "      <td>0.1776</td>\n",
       "      <td>0.0997</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>0.2227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0621</td>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.1072</td>\n",
       "      <td>0.2587</td>\n",
       "      <td>0.2304</td>\n",
       "      <td>0.2067</td>\n",
       "      <td>0.3416</td>\n",
       "      <td>0.4284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0466</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.0657</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1384</td>\n",
       "      <td>0.1376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>0.0787</td>\n",
       "      <td>0.0662</td>\n",
       "      <td>0.1108</td>\n",
       "      <td>0.1777</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>0.0915</td>\n",
       "      <td>0.0949</td>\n",
       "      <td>0.1504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.0411</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.1039</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>0.2592</td>\n",
       "      <td>0.3745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0679</td>\n",
       "      <td>0.0981</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.0759</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "117  0.0228  0.0106  0.0130  0.0842  0.1117  0.1506  0.1776  0.0997  0.1428   \n",
       "90   0.0126  0.0519  0.0621  0.0518  0.1072  0.2587  0.2304  0.2067  0.3416   \n",
       "76   0.0239  0.0189  0.0466  0.0440  0.0657  0.0742  0.1380  0.1099  0.1384   \n",
       "195  0.0129  0.0141  0.0309  0.0375  0.0767  0.0787  0.0662  0.1108  0.1777   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "56   0.0152  0.0102  0.0113  0.0263  0.0097  0.0391  0.0857  0.0915  0.0949   \n",
       "182  0.0095  0.0308  0.0539  0.0411  0.0613  0.1039  0.1016  0.1394  0.2592   \n",
       "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "37   0.0333  0.0221  0.0270  0.0481  0.0679  0.0981  0.0843  0.1172  0.0759   \n",
       "8    0.0223  0.0375  0.0484  0.0475  0.0647  0.0591  0.0753  0.0098  0.0684   \n",
       "\n",
       "         9   ...      51      52      53      54      55      56      57  \\\n",
       "4    0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "117  0.2227  ...  0.0098  0.0178  0.0077  0.0074  0.0095  0.0055  0.0045   \n",
       "90   0.4284  ...  0.0208  0.0048  0.0199  0.0126  0.0022  0.0037  0.0034   \n",
       "76   0.1376  ...  0.0091  0.0151  0.0080  0.0018  0.0078  0.0045  0.0026   \n",
       "195  0.2245  ...  0.0124  0.0093  0.0072  0.0019  0.0027  0.0054  0.0017   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "56   0.1504  ...  0.0049  0.0041  0.0036  0.0013  0.0046  0.0037  0.0011   \n",
       "182  0.3745  ...  0.0181  0.0019  0.0102  0.0133  0.0040  0.0042  0.0030   \n",
       "3    0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "37   0.0920  ...  0.0022  0.0032  0.0060  0.0054  0.0063  0.0143  0.0132   \n",
       "8    0.1487  ...  0.0145  0.0128  0.0145  0.0058  0.0049  0.0065  0.0093   \n",
       "\n",
       "         58      59  60  \n",
       "4    0.0107  0.0094   R  \n",
       "117  0.0063  0.0039   M  \n",
       "90   0.0114  0.0077   R  \n",
       "76   0.0036  0.0024   R  \n",
       "195  0.0024  0.0029   M  \n",
       "..      ...     ...  ..  \n",
       "56   0.0034  0.0033   R  \n",
       "182  0.0031  0.0033   M  \n",
       "3    0.0040  0.0117   R  \n",
       "37   0.0051  0.0041   R  \n",
       "8    0.0059  0.0022   R  \n",
       "\n",
       "[208 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_data = data.sample(frac = 1)\n",
    "shuffled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0762, 0.0666, 0.0481, ..., 0.0107, 0.0094, 'R'],\n",
       "       [0.0228, 0.0106, 0.013, ..., 0.0063, 0.0039, 'M'],\n",
       "       [0.0126, 0.0519, 0.0621, ..., 0.0114, 0.0077, 'R'],\n",
       "       ...,\n",
       "       [0.01, 0.0171, 0.0623, ..., 0.004, 0.0117, 'R'],\n",
       "       [0.0333, 0.0221, 0.027, ..., 0.0051, 0.0041, 'R'],\n",
       "       [0.0223, 0.0375, 0.0484, ..., 0.0059, 0.0022, 'R']], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = shuffled_data.values\n",
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data_set[:144,:60].astype(\"float32\")\n",
    "y_train = data_set[:144,60]\n",
    "\n",
    "x_test = data_set[144:185,:60].astype(\"float32\")\n",
    "y_test = data_set[144:185,60]\n",
    "\n",
    "x_val = data_set[185:,:60].astype(\"float32\")\n",
    "y_val = data_set[185:,60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "encoded_y_train = le.fit_transform(y_train)\n",
    "encoded_y_test = le.fit_transform(y_test)\n",
    "encoded_y_val = le.fit_transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(60, activation = \"relu\"))\n",
    "    model.add(layers.Dense(30, activation = \"relu\"))\n",
    "    model.add(layers.Dense(10, activation = \"sigmoid\"))\n",
    "    model.Dropout = 0.02\n",
    "    model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "    model.compile(optimizer = optimizers.RMSprop(lr = 0.001),\n",
    "                  loss = losses.binary_crossentropy,\n",
    "                  metrics = [metrics.binary_accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = neural_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.7140 - binary_accuracy: 0.4375\n",
      "Epoch 2/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.6852 - binary_accuracy: 0.5972\n",
      "Epoch 3/200\n",
      "144/144 [==============================] - 0s 138us/step - loss: 0.6776 - binary_accuracy: 0.6042\n",
      "Epoch 4/200\n",
      "144/144 [==============================] - 0s 187us/step - loss: 0.6733 - binary_accuracy: 0.6111\n",
      "Epoch 5/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.6678 - binary_accuracy: 0.6181\n",
      "Epoch 6/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.6663 - binary_accuracy: 0.5694\n",
      "Epoch 7/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.6604 - binary_accuracy: 0.6389\n",
      "Epoch 8/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.6581 - binary_accuracy: 0.5972\n",
      "Epoch 9/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.6536 - binary_accuracy: 0.6181\n",
      "Epoch 10/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6495 - binary_accuracy: 0.6250\n",
      "Epoch 11/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.6442 - binary_accuracy: 0.7083\n",
      "Epoch 12/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.6418 - binary_accuracy: 0.6736\n",
      "Epoch 13/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.6334 - binary_accuracy: 0.6875\n",
      "Epoch 14/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.6284 - binary_accuracy: 0.6528\n",
      "Epoch 15/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.6214 - binary_accuracy: 0.7431\n",
      "Epoch 16/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6169 - binary_accuracy: 0.6736\n",
      "Epoch 17/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.6110 - binary_accuracy: 0.7222\n",
      "Epoch 18/200\n",
      "144/144 [==============================] - 0s 166us/step - loss: 0.6029 - binary_accuracy: 0.7014\n",
      "Epoch 19/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5955 - binary_accuracy: 0.7431\n",
      "Epoch 20/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.5911 - binary_accuracy: 0.7153\n",
      "Epoch 21/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5812 - binary_accuracy: 0.7361\n",
      "Epoch 22/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.5753 - binary_accuracy: 0.7431\n",
      "Epoch 23/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.5715 - binary_accuracy: 0.7569\n",
      "Epoch 24/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.5574 - binary_accuracy: 0.7500\n",
      "Epoch 25/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5570 - binary_accuracy: 0.7569\n",
      "Epoch 26/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5435 - binary_accuracy: 0.7986\n",
      "Epoch 27/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5532 - binary_accuracy: 0.7569\n",
      "Epoch 28/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.5321 - binary_accuracy: 0.7569\n",
      "Epoch 29/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.5256 - binary_accuracy: 0.7708\n",
      "Epoch 30/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.5182 - binary_accuracy: 0.7639\n",
      "Epoch 31/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.5130 - binary_accuracy: 0.7917\n",
      "Epoch 32/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.5176 - binary_accuracy: 0.7847\n",
      "Epoch 33/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.5036 - binary_accuracy: 0.7986\n",
      "Epoch 34/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.5058 - binary_accuracy: 0.7569\n",
      "Epoch 35/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.4928 - binary_accuracy: 0.7778\n",
      "Epoch 36/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.4843 - binary_accuracy: 0.8125\n",
      "Epoch 37/200\n",
      "144/144 [==============================] - 0s 138us/step - loss: 0.4800 - binary_accuracy: 0.7986\n",
      "Epoch 38/200\n",
      "144/144 [==============================] - 0s 138us/step - loss: 0.4792 - binary_accuracy: 0.7986\n",
      "Epoch 39/200\n",
      "144/144 [==============================] - 0s 146us/step - loss: 0.4701 - binary_accuracy: 0.7986\n",
      "Epoch 40/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4621 - binary_accuracy: 0.8194\n",
      "Epoch 41/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4540 - binary_accuracy: 0.8403\n",
      "Epoch 42/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4551 - binary_accuracy: 0.8264\n",
      "Epoch 43/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4472 - binary_accuracy: 0.8125\n",
      "Epoch 44/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4460 - binary_accuracy: 0.7986\n",
      "Epoch 45/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4346 - binary_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.4409 - binary_accuracy: 0.8264\n",
      "Epoch 47/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4332 - binary_accuracy: 0.8194\n",
      "Epoch 48/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4255 - binary_accuracy: 0.8194\n",
      "Epoch 49/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4202 - binary_accuracy: 0.8403\n",
      "Epoch 50/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.4284 - binary_accuracy: 0.8403\n",
      "Epoch 51/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4151 - binary_accuracy: 0.8403\n",
      "Epoch 52/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4096 - binary_accuracy: 0.8194\n",
      "Epoch 53/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.4038 - binary_accuracy: 0.8403\n",
      "Epoch 54/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4032 - binary_accuracy: 0.8611\n",
      "Epoch 55/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3932 - binary_accuracy: 0.8819\n",
      "Epoch 56/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.4014 - binary_accuracy: 0.8194\n",
      "Epoch 57/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3930 - binary_accuracy: 0.8542\n",
      "Epoch 58/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3929 - binary_accuracy: 0.8472\n",
      "Epoch 59/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3808 - binary_accuracy: 0.8681\n",
      "Epoch 60/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3840 - binary_accuracy: 0.8472\n",
      "Epoch 61/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3859 - binary_accuracy: 0.8681\n",
      "Epoch 62/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.3732 - binary_accuracy: 0.8542\n",
      "Epoch 63/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3877 - binary_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3719 - binary_accuracy: 0.8472\n",
      "Epoch 65/200\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.3784 - binary_accuracy: 0.8472\n",
      "Epoch 66/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.3648 - binary_accuracy: 0.8611\n",
      "Epoch 67/200\n",
      "144/144 [==============================] - 0s 138us/step - loss: 0.3652 - binary_accuracy: 0.8611\n",
      "Epoch 68/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3653 - binary_accuracy: 0.8819\n",
      "Epoch 69/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3524 - binary_accuracy: 0.8889\n",
      "Epoch 70/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3511 - binary_accuracy: 0.8681\n",
      "Epoch 71/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3530 - binary_accuracy: 0.8611\n",
      "Epoch 72/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3687 - binary_accuracy: 0.8542\n",
      "Epoch 73/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3531 - binary_accuracy: 0.8472\n",
      "Epoch 74/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3423 - binary_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3430 - binary_accuracy: 0.8542\n",
      "Epoch 76/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3298 - binary_accuracy: 0.8889\n",
      "Epoch 77/200\n",
      "144/144 [==============================] - 0s 131us/step - loss: 0.3429 - binary_accuracy: 0.8819\n",
      "Epoch 78/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3325 - binary_accuracy: 0.9028\n",
      "Epoch 79/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3477 - binary_accuracy: 0.8403\n",
      "Epoch 80/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3253 - binary_accuracy: 0.8958\n",
      "Epoch 81/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3221 - binary_accuracy: 0.8958\n",
      "Epoch 82/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3284 - binary_accuracy: 0.8889\n",
      "Epoch 83/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3148 - binary_accuracy: 0.8958\n",
      "Epoch 84/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3146 - binary_accuracy: 0.9028\n",
      "Epoch 85/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3155 - binary_accuracy: 0.9097\n",
      "Epoch 86/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3110 - binary_accuracy: 0.8958\n",
      "Epoch 87/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3207 - binary_accuracy: 0.8819\n",
      "Epoch 88/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3197 - binary_accuracy: 0.8819\n",
      "Epoch 89/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2993 - binary_accuracy: 0.9167\n",
      "Epoch 90/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2990 - binary_accuracy: 0.9028\n",
      "Epoch 91/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3090 - binary_accuracy: 0.8611\n",
      "Epoch 92/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3004 - binary_accuracy: 0.9097\n",
      "Epoch 93/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2992 - binary_accuracy: 0.8958\n",
      "Epoch 94/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2957 - binary_accuracy: 0.8958\n",
      "Epoch 95/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2897 - binary_accuracy: 0.9097\n",
      "Epoch 96/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2903 - binary_accuracy: 0.9028\n",
      "Epoch 97/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2939 - binary_accuracy: 0.8889\n",
      "Epoch 98/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2825 - binary_accuracy: 0.9167\n",
      "Epoch 99/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2872 - binary_accuracy: 0.8958\n",
      "Epoch 100/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2799 - binary_accuracy: 0.9097\n",
      "Epoch 101/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2859 - binary_accuracy: 0.8889\n",
      "Epoch 102/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2802 - binary_accuracy: 0.9028\n",
      "Epoch 103/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2797 - binary_accuracy: 0.9028\n",
      "Epoch 104/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2671 - binary_accuracy: 0.9306\n",
      "Epoch 105/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2845 - binary_accuracy: 0.9028\n",
      "Epoch 106/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2549 - binary_accuracy: 0.9375\n",
      "Epoch 107/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2506 - binary_accuracy: 0.9167\n",
      "Epoch 108/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2852 - binary_accuracy: 0.8750\n",
      "Epoch 109/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2712 - binary_accuracy: 0.9167\n",
      "Epoch 110/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2681 - binary_accuracy: 0.9028\n",
      "Epoch 111/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2551 - binary_accuracy: 0.9236\n",
      "Epoch 112/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2467 - binary_accuracy: 0.9306\n",
      "Epoch 113/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2441 - binary_accuracy: 0.9444\n",
      "Epoch 114/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2472 - binary_accuracy: 0.9236\n",
      "Epoch 115/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2588 - binary_accuracy: 0.9097\n",
      "Epoch 116/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2539 - binary_accuracy: 0.9375\n",
      "Epoch 117/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2526 - binary_accuracy: 0.9236\n",
      "Epoch 118/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2369 - binary_accuracy: 0.9306\n",
      "Epoch 119/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2288 - binary_accuracy: 0.9306\n",
      "Epoch 120/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2443 - binary_accuracy: 0.9097\n",
      "Epoch 121/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2283 - binary_accuracy: 0.9375\n",
      "Epoch 122/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2426 - binary_accuracy: 0.9236\n",
      "Epoch 123/200\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2286 - binary_accuracy: 0.9375\n",
      "Epoch 124/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2206 - binary_accuracy: 0.9514\n",
      "Epoch 125/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2180 - binary_accuracy: 0.9514\n",
      "Epoch 126/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2266 - binary_accuracy: 0.9375\n",
      "Epoch 127/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2098 - binary_accuracy: 0.9444\n",
      "Epoch 128/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2116 - binary_accuracy: 0.9444\n",
      "Epoch 129/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2046 - binary_accuracy: 0.9514\n",
      "Epoch 130/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.2165 - binary_accuracy: 0.9583\n",
      "Epoch 131/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2353 - binary_accuracy: 0.9236\n",
      "Epoch 132/200\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2124 - binary_accuracy: 0.9375\n",
      "Epoch 133/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2121 - binary_accuracy: 0.9444\n",
      "Epoch 134/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1994 - binary_accuracy: 0.9306\n",
      "Epoch 135/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2020 - binary_accuracy: 0.9444\n",
      "Epoch 136/200\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1955 - binary_accuracy: 0.9653\n",
      "Epoch 137/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1927 - binary_accuracy: 0.9583\n",
      "Epoch 138/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1871 - binary_accuracy: 0.9583\n",
      "Epoch 139/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2014 - binary_accuracy: 0.9375\n",
      "Epoch 140/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1838 - binary_accuracy: 0.9583\n",
      "Epoch 141/200\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1872 - binary_accuracy: 0.9444\n",
      "Epoch 142/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2005 - binary_accuracy: 0.9444\n",
      "Epoch 143/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1840 - binary_accuracy: 0.9444\n",
      "Epoch 144/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1827 - binary_accuracy: 0.9514\n",
      "Epoch 145/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1820 - binary_accuracy: 0.9514\n",
      "Epoch 146/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2125 - binary_accuracy: 0.9236\n",
      "Epoch 147/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1743 - binary_accuracy: 0.9514\n",
      "Epoch 148/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 111us/step - loss: 0.1950 - binary_accuracy: 0.9236\n",
      "Epoch 149/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1769 - binary_accuracy: 0.9583\n",
      "Epoch 150/200\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1619 - binary_accuracy: 0.9792\n",
      "Epoch 151/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1663 - binary_accuracy: 0.9722\n",
      "Epoch 152/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1570 - binary_accuracy: 0.9653\n",
      "Epoch 153/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1644 - binary_accuracy: 0.9375\n",
      "Epoch 154/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1736 - binary_accuracy: 0.9444\n",
      "Epoch 155/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1582 - binary_accuracy: 0.9653\n",
      "Epoch 156/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1485 - binary_accuracy: 0.9583\n",
      "Epoch 157/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1473 - binary_accuracy: 0.9653\n",
      "Epoch 158/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1453 - binary_accuracy: 0.9583\n",
      "Epoch 159/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1681 - binary_accuracy: 0.9375\n",
      "Epoch 160/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1459 - binary_accuracy: 0.9722\n",
      "Epoch 161/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1509 - binary_accuracy: 0.9514\n",
      "Epoch 162/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1447 - binary_accuracy: 0.9583\n",
      "Epoch 163/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1503 - binary_accuracy: 0.9444\n",
      "Epoch 164/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1311 - binary_accuracy: 0.9792\n",
      "Epoch 165/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1374 - binary_accuracy: 0.9722\n",
      "Epoch 166/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1424 - binary_accuracy: 0.9583\n",
      "Epoch 167/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1381 - binary_accuracy: 0.9722\n",
      "Epoch 168/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1332 - binary_accuracy: 0.9653\n",
      "Epoch 169/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1369 - binary_accuracy: 0.9583\n",
      "Epoch 170/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1458 - binary_accuracy: 0.9653\n",
      "Epoch 171/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1391 - binary_accuracy: 0.9653\n",
      "Epoch 172/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.1169 - binary_accuracy: 0.9861\n",
      "Epoch 173/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1336 - binary_accuracy: 0.9653\n",
      "Epoch 174/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1264 - binary_accuracy: 0.9722\n",
      "Epoch 175/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1332 - binary_accuracy: 0.9653\n",
      "Epoch 176/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1271 - binary_accuracy: 0.9792\n",
      "Epoch 177/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1144 - binary_accuracy: 0.9861\n",
      "Epoch 178/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1133 - binary_accuracy: 0.9861\n",
      "Epoch 179/200\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1200 - binary_accuracy: 0.9792\n",
      "Epoch 180/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1066 - binary_accuracy: 0.9931\n",
      "Epoch 181/200\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1429 - binary_accuracy: 0.9444\n",
      "Epoch 182/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1040 - binary_accuracy: 0.9792\n",
      "Epoch 183/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1053 - binary_accuracy: 0.9861\n",
      "Epoch 184/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1720 - binary_accuracy: 0.9236\n",
      "Epoch 185/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1010 - binary_accuracy: 0.9931\n",
      "Epoch 186/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0988 - binary_accuracy: 0.9861\n",
      "Epoch 187/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0975 - binary_accuracy: 0.9931\n",
      "Epoch 188/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1100 - binary_accuracy: 0.9861\n",
      "Epoch 189/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.0948 - binary_accuracy: 0.9931\n",
      "Epoch 190/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.0922 - binary_accuracy: 0.9931\n",
      "Epoch 191/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1092 - binary_accuracy: 0.9861\n",
      "Epoch 192/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.0920 - binary_accuracy: 0.9931\n",
      "Epoch 193/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1210 - binary_accuracy: 0.9722\n",
      "Epoch 194/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0917 - binary_accuracy: 0.9792\n",
      "Epoch 195/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0974 - binary_accuracy: 0.9931\n",
      "Epoch 196/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0917 - binary_accuracy: 0.9861\n",
      "Epoch 197/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0903 - binary_accuracy: 0.9931\n",
      "Epoch 198/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0962 - binary_accuracy: 0.9792\n",
      "Epoch 199/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0905 - binary_accuracy: 0.9792\n",
      "Epoch 200/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0844 - binary_accuracy: 0.9861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x25f759eb9c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, encoded_y_train, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(x_test, encoded_y_test, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.34747326374053955, 0.8292682766914368]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 144 samples, validate on 23 samples\n",
      "Epoch 1/200\n",
      "144/144 [==============================] - 0s 866us/step - loss: 0.6969 - binary_accuracy: 0.4514 - val_loss: 0.6948 - val_binary_accuracy: 0.4348\n",
      "Epoch 2/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.6816 - binary_accuracy: 0.6250 - val_loss: 0.7048 - val_binary_accuracy: 0.3478\n",
      "Epoch 3/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.6738 - binary_accuracy: 0.5625 - val_loss: 0.7085 - val_binary_accuracy: 0.3478\n",
      "Epoch 4/200\n",
      "144/144 [==============================] - 0s 166us/step - loss: 0.6691 - binary_accuracy: 0.5694 - val_loss: 0.7169 - val_binary_accuracy: 0.3478\n",
      "Epoch 5/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.6630 - binary_accuracy: 0.5694 - val_loss: 0.7136 - val_binary_accuracy: 0.3478\n",
      "Epoch 6/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.6579 - binary_accuracy: 0.5764 - val_loss: 0.7006 - val_binary_accuracy: 0.3478\n",
      "Epoch 7/200\n",
      "144/144 [==============================] - 0s 173us/step - loss: 0.6522 - binary_accuracy: 0.6250 - val_loss: 0.7006 - val_binary_accuracy: 0.3478\n",
      "Epoch 8/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.6458 - binary_accuracy: 0.6597 - val_loss: 0.7052 - val_binary_accuracy: 0.3478\n",
      "Epoch 9/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.6412 - binary_accuracy: 0.6111 - val_loss: 0.6832 - val_binary_accuracy: 0.5217\n",
      "Epoch 10/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.6354 - binary_accuracy: 0.6736 - val_loss: 0.6923 - val_binary_accuracy: 0.4783\n",
      "Epoch 11/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.6276 - binary_accuracy: 0.6667 - val_loss: 0.6832 - val_binary_accuracy: 0.5217\n",
      "Epoch 12/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.6224 - binary_accuracy: 0.6875 - val_loss: 0.6631 - val_binary_accuracy: 0.5652\n",
      "Epoch 13/200\n",
      "144/144 [==============================] - 0s 180us/step - loss: 0.6152 - binary_accuracy: 0.6875 - val_loss: 0.6622 - val_binary_accuracy: 0.5652\n",
      "Epoch 14/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.6109 - binary_accuracy: 0.6944 - val_loss: 0.6626 - val_binary_accuracy: 0.5652\n",
      "Epoch 15/200\n",
      "144/144 [==============================] - 0s 187us/step - loss: 0.6021 - binary_accuracy: 0.7153 - val_loss: 0.6702 - val_binary_accuracy: 0.5217\n",
      "Epoch 16/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.5978 - binary_accuracy: 0.7083 - val_loss: 0.6746 - val_binary_accuracy: 0.5217\n",
      "Epoch 17/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.5869 - binary_accuracy: 0.6875 - val_loss: 0.6401 - val_binary_accuracy: 0.6957\n",
      "Epoch 18/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.5798 - binary_accuracy: 0.7153 - val_loss: 0.6546 - val_binary_accuracy: 0.5652\n",
      "Epoch 19/200\n",
      "144/144 [==============================] - 0s 166us/step - loss: 0.5727 - binary_accuracy: 0.7083 - val_loss: 0.6381 - val_binary_accuracy: 0.6522\n",
      "Epoch 20/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.5682 - binary_accuracy: 0.7361 - val_loss: 0.6573 - val_binary_accuracy: 0.5652\n",
      "Epoch 21/200\n",
      "144/144 [==============================] - 0s 187us/step - loss: 0.5586 - binary_accuracy: 0.7500 - val_loss: 0.6593 - val_binary_accuracy: 0.5652\n",
      "Epoch 22/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.5576 - binary_accuracy: 0.7083 - val_loss: 0.6067 - val_binary_accuracy: 0.6522\n",
      "Epoch 23/200\n",
      "144/144 [==============================] - 0s 187us/step - loss: 0.5456 - binary_accuracy: 0.7708 - val_loss: 0.6343 - val_binary_accuracy: 0.6522\n",
      "Epoch 24/200\n",
      "144/144 [==============================] - 0s 166us/step - loss: 0.5411 - binary_accuracy: 0.7361 - val_loss: 0.6342 - val_binary_accuracy: 0.6957\n",
      "Epoch 25/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.5361 - binary_accuracy: 0.7292 - val_loss: 0.5954 - val_binary_accuracy: 0.6522\n",
      "Epoch 26/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.5295 - binary_accuracy: 0.7431 - val_loss: 0.6506 - val_binary_accuracy: 0.6087\n",
      "Epoch 27/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.5198 - binary_accuracy: 0.7361 - val_loss: 0.6014 - val_binary_accuracy: 0.6522\n",
      "Epoch 28/200\n",
      "144/144 [==============================] - 0s 166us/step - loss: 0.5131 - binary_accuracy: 0.7708 - val_loss: 0.6006 - val_binary_accuracy: 0.6522\n",
      "Epoch 29/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.5084 - binary_accuracy: 0.7847 - val_loss: 0.5763 - val_binary_accuracy: 0.6957\n",
      "Epoch 30/200\n",
      "144/144 [==============================] - 0s 166us/step - loss: 0.5007 - binary_accuracy: 0.8125 - val_loss: 0.6600 - val_binary_accuracy: 0.6087\n",
      "Epoch 31/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.4978 - binary_accuracy: 0.7639 - val_loss: 0.6441 - val_binary_accuracy: 0.6957\n",
      "Epoch 32/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.4904 - binary_accuracy: 0.7569 - val_loss: 0.5609 - val_binary_accuracy: 0.7391\n",
      "Epoch 33/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4840 - binary_accuracy: 0.8056 - val_loss: 0.5630 - val_binary_accuracy: 0.6957\n",
      "Epoch 34/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4800 - binary_accuracy: 0.8125 - val_loss: 0.6584 - val_binary_accuracy: 0.6957\n",
      "Epoch 35/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4737 - binary_accuracy: 0.7986 - val_loss: 0.5671 - val_binary_accuracy: 0.6957\n",
      "Epoch 36/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4701 - binary_accuracy: 0.8125 - val_loss: 0.5611 - val_binary_accuracy: 0.6957\n",
      "Epoch 37/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.4637 - binary_accuracy: 0.8264 - val_loss: 0.6546 - val_binary_accuracy: 0.6957\n",
      "Epoch 38/200\n",
      "144/144 [==============================] - 0s 138us/step - loss: 0.4630 - binary_accuracy: 0.7917 - val_loss: 0.6073 - val_binary_accuracy: 0.6522\n",
      "Epoch 39/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.4579 - binary_accuracy: 0.7847 - val_loss: 0.5530 - val_binary_accuracy: 0.6957\n",
      "Epoch 40/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4477 - binary_accuracy: 0.8264 - val_loss: 0.5509 - val_binary_accuracy: 0.6957\n",
      "Epoch 41/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4439 - binary_accuracy: 0.8125 - val_loss: 0.5559 - val_binary_accuracy: 0.6957\n",
      "Epoch 42/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4472 - binary_accuracy: 0.8472 - val_loss: 0.6100 - val_binary_accuracy: 0.7391\n",
      "Epoch 43/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4428 - binary_accuracy: 0.8056 - val_loss: 0.5993 - val_binary_accuracy: 0.6957\n",
      "Epoch 44/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4382 - binary_accuracy: 0.8194 - val_loss: 0.5584 - val_binary_accuracy: 0.7391\n",
      "Epoch 45/200\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.4375 - binary_accuracy: 0.8125 - val_loss: 0.5686 - val_binary_accuracy: 0.6957\n",
      "Epoch 46/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4346 - binary_accuracy: 0.8333 - val_loss: 0.6190 - val_binary_accuracy: 0.7391\n",
      "Epoch 47/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4279 - binary_accuracy: 0.8056 - val_loss: 0.6072 - val_binary_accuracy: 0.7391\n",
      "Epoch 48/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.4184 - binary_accuracy: 0.8264 - val_loss: 0.5118 - val_binary_accuracy: 0.7826\n",
      "Epoch 49/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4223 - binary_accuracy: 0.8542 - val_loss: 0.6041 - val_binary_accuracy: 0.7391\n",
      "Epoch 50/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4121 - binary_accuracy: 0.8472 - val_loss: 0.5560 - val_binary_accuracy: 0.6957\n",
      "Epoch 51/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4228 - binary_accuracy: 0.8264 - val_loss: 0.5636 - val_binary_accuracy: 0.6957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.4114 - binary_accuracy: 0.8333 - val_loss: 0.5845 - val_binary_accuracy: 0.6957\n",
      "Epoch 53/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.4030 - binary_accuracy: 0.8403 - val_loss: 0.6060 - val_binary_accuracy: 0.6957\n",
      "Epoch 54/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4190 - binary_accuracy: 0.8125 - val_loss: 0.5901 - val_binary_accuracy: 0.6957\n",
      "Epoch 55/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3979 - binary_accuracy: 0.8264 - val_loss: 0.5514 - val_binary_accuracy: 0.7391\n",
      "Epoch 56/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3941 - binary_accuracy: 0.8264 - val_loss: 0.5138 - val_binary_accuracy: 0.7391\n",
      "Epoch 57/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3968 - binary_accuracy: 0.8403 - val_loss: 0.5179 - val_binary_accuracy: 0.7391\n",
      "Epoch 58/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.3979 - binary_accuracy: 0.8194 - val_loss: 0.5666 - val_binary_accuracy: 0.6957\n",
      "Epoch 59/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3897 - binary_accuracy: 0.8403 - val_loss: 0.5565 - val_binary_accuracy: 0.7391\n",
      "Epoch 60/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.3813 - binary_accuracy: 0.8472 - val_loss: 0.5507 - val_binary_accuracy: 0.7391\n",
      "Epoch 61/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.3806 - binary_accuracy: 0.8333 - val_loss: 0.6061 - val_binary_accuracy: 0.7391\n",
      "Epoch 62/200\n",
      "144/144 [==============================] - 0s 180us/step - loss: 0.3784 - binary_accuracy: 0.8472 - val_loss: 0.5725 - val_binary_accuracy: 0.6957\n",
      "Epoch 63/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3829 - binary_accuracy: 0.8333 - val_loss: 0.5999 - val_binary_accuracy: 0.7391\n",
      "Epoch 64/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.3724 - binary_accuracy: 0.8333 - val_loss: 0.5778 - val_binary_accuracy: 0.6957\n",
      "Epoch 65/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.3711 - binary_accuracy: 0.8333 - val_loss: 0.6184 - val_binary_accuracy: 0.7391\n",
      "Epoch 66/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3698 - binary_accuracy: 0.8681 - val_loss: 0.5788 - val_binary_accuracy: 0.6957\n",
      "Epoch 67/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3799 - binary_accuracy: 0.8194 - val_loss: 0.5191 - val_binary_accuracy: 0.7391\n",
      "Epoch 68/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3617 - binary_accuracy: 0.8472 - val_loss: 0.5417 - val_binary_accuracy: 0.7391\n",
      "Epoch 69/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3654 - binary_accuracy: 0.8264 - val_loss: 0.5174 - val_binary_accuracy: 0.7391\n",
      "Epoch 70/200\n",
      "144/144 [==============================] - 0s 146us/step - loss: 0.3711 - binary_accuracy: 0.8264 - val_loss: 0.5413 - val_binary_accuracy: 0.7391\n",
      "Epoch 71/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3589 - binary_accuracy: 0.8611 - val_loss: 0.5134 - val_binary_accuracy: 0.7391\n",
      "Epoch 72/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3538 - binary_accuracy: 0.8611 - val_loss: 0.5155 - val_binary_accuracy: 0.7391\n",
      "Epoch 73/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3669 - binary_accuracy: 0.8542 - val_loss: 0.5781 - val_binary_accuracy: 0.7391\n",
      "Epoch 74/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.3493 - binary_accuracy: 0.8681 - val_loss: 0.5280 - val_binary_accuracy: 0.7391\n",
      "Epoch 75/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3441 - binary_accuracy: 0.8681 - val_loss: 0.5527 - val_binary_accuracy: 0.7391\n",
      "Epoch 76/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3419 - binary_accuracy: 0.8611 - val_loss: 0.6219 - val_binary_accuracy: 0.7391\n",
      "Epoch 77/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3423 - binary_accuracy: 0.8472 - val_loss: 0.6477 - val_binary_accuracy: 0.7391\n",
      "Epoch 78/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3448 - binary_accuracy: 0.8542 - val_loss: 0.5379 - val_binary_accuracy: 0.7391\n",
      "Epoch 79/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3304 - binary_accuracy: 0.8750 - val_loss: 0.6374 - val_binary_accuracy: 0.7391\n",
      "Epoch 80/200\n",
      "144/144 [==============================] - 0s 173us/step - loss: 0.3441 - binary_accuracy: 0.8611 - val_loss: 0.5400 - val_binary_accuracy: 0.6957\n",
      "Epoch 81/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.3316 - binary_accuracy: 0.8681 - val_loss: 0.5298 - val_binary_accuracy: 0.7391\n",
      "Epoch 82/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.3291 - binary_accuracy: 0.8611 - val_loss: 0.6119 - val_binary_accuracy: 0.7391\n",
      "Epoch 83/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3263 - binary_accuracy: 0.8681 - val_loss: 0.5294 - val_binary_accuracy: 0.7391\n",
      "Epoch 84/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.3179 - binary_accuracy: 0.8750 - val_loss: 0.5608 - val_binary_accuracy: 0.7391\n",
      "Epoch 85/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3211 - binary_accuracy: 0.8819 - val_loss: 0.5192 - val_binary_accuracy: 0.6957\n",
      "Epoch 86/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3311 - binary_accuracy: 0.8819 - val_loss: 0.5654 - val_binary_accuracy: 0.7391\n",
      "Epoch 87/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.3153 - binary_accuracy: 0.8889 - val_loss: 0.5296 - val_binary_accuracy: 0.6957\n",
      "Epoch 88/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3143 - binary_accuracy: 0.8611 - val_loss: 0.6618 - val_binary_accuracy: 0.7391\n",
      "Epoch 89/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3077 - binary_accuracy: 0.8819 - val_loss: 0.5358 - val_binary_accuracy: 0.6957\n",
      "Epoch 90/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.3041 - binary_accuracy: 0.8958 - val_loss: 0.5418 - val_binary_accuracy: 0.6957\n",
      "Epoch 91/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.3010 - binary_accuracy: 0.9028 - val_loss: 0.5836 - val_binary_accuracy: 0.7391\n",
      "Epoch 92/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2992 - binary_accuracy: 0.9028 - val_loss: 0.5555 - val_binary_accuracy: 0.6522\n",
      "Epoch 93/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3018 - binary_accuracy: 0.9236 - val_loss: 0.6375 - val_binary_accuracy: 0.7391\n",
      "Epoch 94/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3030 - binary_accuracy: 0.8750 - val_loss: 0.5672 - val_binary_accuracy: 0.7391\n",
      "Epoch 95/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3018 - binary_accuracy: 0.8819 - val_loss: 0.5743 - val_binary_accuracy: 0.7391\n",
      "Epoch 96/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2849 - binary_accuracy: 0.9097 - val_loss: 0.5791 - val_binary_accuracy: 0.7391\n",
      "Epoch 97/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2881 - binary_accuracy: 0.8958 - val_loss: 0.5590 - val_binary_accuracy: 0.6957\n",
      "Epoch 98/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2791 - binary_accuracy: 0.9028 - val_loss: 0.5750 - val_binary_accuracy: 0.6957\n",
      "Epoch 99/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2813 - binary_accuracy: 0.9028 - val_loss: 0.5592 - val_binary_accuracy: 0.6957\n",
      "Epoch 100/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2949 - binary_accuracy: 0.8750 - val_loss: 0.6156 - val_binary_accuracy: 0.6957\n",
      "Epoch 101/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2753 - binary_accuracy: 0.9167 - val_loss: 0.5991 - val_binary_accuracy: 0.7391\n",
      "Epoch 102/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2729 - binary_accuracy: 0.9097 - val_loss: 0.6198 - val_binary_accuracy: 0.6957\n",
      "Epoch 103/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 132us/step - loss: 0.2653 - binary_accuracy: 0.8958 - val_loss: 0.5733 - val_binary_accuracy: 0.6522\n",
      "Epoch 104/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2722 - binary_accuracy: 0.9097 - val_loss: 0.5764 - val_binary_accuracy: 0.6957\n",
      "Epoch 105/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2672 - binary_accuracy: 0.9167 - val_loss: 0.6628 - val_binary_accuracy: 0.7391\n",
      "Epoch 106/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.2693 - binary_accuracy: 0.8958 - val_loss: 0.5753 - val_binary_accuracy: 0.6957\n",
      "Epoch 107/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2571 - binary_accuracy: 0.9375 - val_loss: 0.6203 - val_binary_accuracy: 0.6957\n",
      "Epoch 108/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.2656 - binary_accuracy: 0.8750 - val_loss: 0.5885 - val_binary_accuracy: 0.6957\n",
      "Epoch 109/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.2514 - binary_accuracy: 0.9097 - val_loss: 0.5825 - val_binary_accuracy: 0.6957\n",
      "Epoch 110/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2483 - binary_accuracy: 0.9236 - val_loss: 0.5882 - val_binary_accuracy: 0.6957\n",
      "Epoch 111/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2408 - binary_accuracy: 0.9236 - val_loss: 0.5922 - val_binary_accuracy: 0.6957\n",
      "Epoch 112/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.2503 - binary_accuracy: 0.9167 - val_loss: 0.6844 - val_binary_accuracy: 0.6957\n",
      "Epoch 113/200\n",
      "144/144 [==============================] - 0s 138us/step - loss: 0.2414 - binary_accuracy: 0.9306 - val_loss: 0.6645 - val_binary_accuracy: 0.6957\n",
      "Epoch 114/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2479 - binary_accuracy: 0.9167 - val_loss: 0.6327 - val_binary_accuracy: 0.6957\n",
      "Epoch 115/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2501 - binary_accuracy: 0.9028 - val_loss: 0.6545 - val_binary_accuracy: 0.6957\n",
      "Epoch 116/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2398 - binary_accuracy: 0.9236 - val_loss: 0.6757 - val_binary_accuracy: 0.6957\n",
      "Epoch 117/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2375 - binary_accuracy: 0.9375 - val_loss: 0.6177 - val_binary_accuracy: 0.6957\n",
      "Epoch 118/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2236 - binary_accuracy: 0.9236 - val_loss: 0.6151 - val_binary_accuracy: 0.6522\n",
      "Epoch 119/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2215 - binary_accuracy: 0.9514 - val_loss: 0.6147 - val_binary_accuracy: 0.6957\n",
      "Epoch 120/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2398 - binary_accuracy: 0.9167 - val_loss: 0.7323 - val_binary_accuracy: 0.6957\n",
      "Epoch 121/200\n",
      "144/144 [==============================] - 0s 153us/step - loss: 0.2319 - binary_accuracy: 0.9375 - val_loss: 0.6422 - val_binary_accuracy: 0.6957\n",
      "Epoch 122/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2118 - binary_accuracy: 0.9514 - val_loss: 0.6217 - val_binary_accuracy: 0.6957\n",
      "Epoch 123/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2209 - binary_accuracy: 0.9375 - val_loss: 0.5909 - val_binary_accuracy: 0.6957\n",
      "Epoch 124/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2075 - binary_accuracy: 0.9583 - val_loss: 0.6117 - val_binary_accuracy: 0.6957\n",
      "Epoch 125/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2225 - binary_accuracy: 0.9236 - val_loss: 0.6317 - val_binary_accuracy: 0.6957\n",
      "Epoch 126/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2104 - binary_accuracy: 0.9444 - val_loss: 0.6481 - val_binary_accuracy: 0.6957\n",
      "Epoch 127/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2012 - binary_accuracy: 0.9444 - val_loss: 0.6993 - val_binary_accuracy: 0.6957\n",
      "Epoch 128/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.2084 - binary_accuracy: 0.9444 - val_loss: 0.6305 - val_binary_accuracy: 0.6957\n",
      "Epoch 129/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1993 - binary_accuracy: 0.9444 - val_loss: 0.6396 - val_binary_accuracy: 0.6522\n",
      "Epoch 130/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1902 - binary_accuracy: 0.9514 - val_loss: 0.6288 - val_binary_accuracy: 0.6957\n",
      "Epoch 131/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1972 - binary_accuracy: 0.9444 - val_loss: 0.6102 - val_binary_accuracy: 0.6957\n",
      "Epoch 132/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2285 - binary_accuracy: 0.9097 - val_loss: 0.6667 - val_binary_accuracy: 0.6087\n",
      "Epoch 133/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1862 - binary_accuracy: 0.9375 - val_loss: 0.7060 - val_binary_accuracy: 0.6957\n",
      "Epoch 134/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1917 - binary_accuracy: 0.9514 - val_loss: 0.6299 - val_binary_accuracy: 0.6957\n",
      "Epoch 135/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1997 - binary_accuracy: 0.9375 - val_loss: 0.6813 - val_binary_accuracy: 0.6957\n",
      "Epoch 136/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1771 - binary_accuracy: 0.9722 - val_loss: 0.6259 - val_binary_accuracy: 0.6957\n",
      "Epoch 137/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1915 - binary_accuracy: 0.9514 - val_loss: 0.6002 - val_binary_accuracy: 0.6957\n",
      "Epoch 138/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.1810 - binary_accuracy: 0.9583 - val_loss: 0.7029 - val_binary_accuracy: 0.6957\n",
      "Epoch 139/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1778 - binary_accuracy: 0.9444 - val_loss: 0.7323 - val_binary_accuracy: 0.6957\n",
      "Epoch 140/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2125 - binary_accuracy: 0.9167 - val_loss: 0.6674 - val_binary_accuracy: 0.6957\n",
      "Epoch 141/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1643 - binary_accuracy: 0.9653 - val_loss: 0.7073 - val_binary_accuracy: 0.6957\n",
      "Epoch 142/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1726 - binary_accuracy: 0.9583 - val_loss: 0.6284 - val_binary_accuracy: 0.6957\n",
      "Epoch 143/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1791 - binary_accuracy: 0.9583 - val_loss: 0.6497 - val_binary_accuracy: 0.6957\n",
      "Epoch 144/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1745 - binary_accuracy: 0.9653 - val_loss: 0.6596 - val_binary_accuracy: 0.6957\n",
      "Epoch 145/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1572 - binary_accuracy: 0.9722 - val_loss: 0.6199 - val_binary_accuracy: 0.6957\n",
      "Epoch 146/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1648 - binary_accuracy: 0.9722 - val_loss: 0.6722 - val_binary_accuracy: 0.6957\n",
      "Epoch 147/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1521 - binary_accuracy: 0.9792 - val_loss: 0.7461 - val_binary_accuracy: 0.6957\n",
      "Epoch 148/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1606 - binary_accuracy: 0.9514 - val_loss: 0.6821 - val_binary_accuracy: 0.6522\n",
      "Epoch 149/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1512 - binary_accuracy: 0.9583 - val_loss: 0.6846 - val_binary_accuracy: 0.6957\n",
      "Epoch 150/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.1610 - binary_accuracy: 0.9514 - val_loss: 0.6451 - val_binary_accuracy: 0.6957\n",
      "Epoch 151/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1531 - binary_accuracy: 0.9722 - val_loss: 0.6507 - val_binary_accuracy: 0.6957\n",
      "Epoch 152/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1401 - binary_accuracy: 0.9653 - val_loss: 0.6878 - val_binary_accuracy: 0.6957\n",
      "Epoch 153/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1397 - binary_accuracy: 0.9583 - val_loss: 0.7763 - val_binary_accuracy: 0.6957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1566 - binary_accuracy: 0.9583 - val_loss: 0.6090 - val_binary_accuracy: 0.6957\n",
      "Epoch 155/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1447 - binary_accuracy: 0.9653 - val_loss: 0.6645 - val_binary_accuracy: 0.6957\n",
      "Epoch 156/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1294 - binary_accuracy: 0.9653 - val_loss: 0.7799 - val_binary_accuracy: 0.6957\n",
      "Epoch 157/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.1599 - binary_accuracy: 0.9444 - val_loss: 0.6054 - val_binary_accuracy: 0.7391\n",
      "Epoch 158/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.1281 - binary_accuracy: 0.9792 - val_loss: 0.6702 - val_binary_accuracy: 0.6957\n",
      "Epoch 159/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.1279 - binary_accuracy: 0.9722 - val_loss: 0.5704 - val_binary_accuracy: 0.7391\n",
      "Epoch 160/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.1223 - binary_accuracy: 0.9653 - val_loss: 0.6278 - val_binary_accuracy: 0.6522\n",
      "Epoch 161/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1392 - binary_accuracy: 0.9583 - val_loss: 0.5936 - val_binary_accuracy: 0.7391\n",
      "Epoch 162/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1223 - binary_accuracy: 0.9792 - val_loss: 0.6420 - val_binary_accuracy: 0.6522\n",
      "Epoch 163/200\n",
      "144/144 [==============================] - 0s 138us/step - loss: 0.1333 - binary_accuracy: 0.9653 - val_loss: 0.5866 - val_binary_accuracy: 0.7826\n",
      "Epoch 164/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1134 - binary_accuracy: 0.9792 - val_loss: 0.5829 - val_binary_accuracy: 0.7826\n",
      "Epoch 165/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1109 - binary_accuracy: 0.9931 - val_loss: 0.6300 - val_binary_accuracy: 0.6957\n",
      "Epoch 166/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1642 - binary_accuracy: 0.9444 - val_loss: 0.5667 - val_binary_accuracy: 0.7826\n",
      "Epoch 167/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.1114 - binary_accuracy: 0.9722 - val_loss: 0.6307 - val_binary_accuracy: 0.6957\n",
      "Epoch 168/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1054 - binary_accuracy: 0.9861 - val_loss: 0.6645 - val_binary_accuracy: 0.6957\n",
      "Epoch 169/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1170 - binary_accuracy: 0.9722 - val_loss: 0.7695 - val_binary_accuracy: 0.6957\n",
      "Epoch 170/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1123 - binary_accuracy: 0.9792 - val_loss: 0.7903 - val_binary_accuracy: 0.6957\n",
      "Epoch 171/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.1264 - binary_accuracy: 0.9583 - val_loss: 0.5764 - val_binary_accuracy: 0.7826\n",
      "Epoch 172/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1122 - binary_accuracy: 0.9792 - val_loss: 0.6070 - val_binary_accuracy: 0.7391\n",
      "Epoch 173/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0995 - binary_accuracy: 0.9861 - val_loss: 0.7567 - val_binary_accuracy: 0.6957\n",
      "Epoch 174/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.0979 - binary_accuracy: 0.9931 - val_loss: 0.6747 - val_binary_accuracy: 0.6957\n",
      "Epoch 175/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0975 - binary_accuracy: 0.9931 - val_loss: 0.6859 - val_binary_accuracy: 0.6957\n",
      "Epoch 176/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1012 - binary_accuracy: 0.9722 - val_loss: 0.8852 - val_binary_accuracy: 0.6522\n",
      "Epoch 177/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1020 - binary_accuracy: 0.9861 - val_loss: 0.6065 - val_binary_accuracy: 0.6957\n",
      "Epoch 178/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1063 - binary_accuracy: 0.9722 - val_loss: 0.7157 - val_binary_accuracy: 0.6957\n",
      "Epoch 179/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1027 - binary_accuracy: 0.9861 - val_loss: 0.5481 - val_binary_accuracy: 0.7826\n",
      "Epoch 180/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.0842 - binary_accuracy: 0.9931 - val_loss: 0.6121 - val_binary_accuracy: 0.7391\n",
      "Epoch 181/200\n",
      "144/144 [==============================] - 0s 173us/step - loss: 0.0857 - binary_accuracy: 0.9931 - val_loss: 0.5850 - val_binary_accuracy: 0.7391\n",
      "Epoch 182/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.0794 - binary_accuracy: 0.9861 - val_loss: 0.7667 - val_binary_accuracy: 0.6957\n",
      "Epoch 183/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.0948 - binary_accuracy: 0.9861 - val_loss: 0.5805 - val_binary_accuracy: 0.7826\n",
      "Epoch 184/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0974 - binary_accuracy: 0.9722 - val_loss: 0.9153 - val_binary_accuracy: 0.6522\n",
      "Epoch 185/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.1056 - binary_accuracy: 0.9653 - val_loss: 0.6978 - val_binary_accuracy: 0.6957\n",
      "Epoch 186/200\n",
      "144/144 [==============================] - 0s 173us/step - loss: 0.0758 - binary_accuracy: 0.9931 - val_loss: 0.6457 - val_binary_accuracy: 0.7391\n",
      "Epoch 187/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0832 - binary_accuracy: 0.9861 - val_loss: 0.5374 - val_binary_accuracy: 0.7826\n",
      "Epoch 188/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0757 - binary_accuracy: 0.9931 - val_loss: 0.4976 - val_binary_accuracy: 0.8261\n",
      "Epoch 189/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0780 - binary_accuracy: 0.9861 - val_loss: 0.5408 - val_binary_accuracy: 0.7391\n",
      "Epoch 190/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0812 - binary_accuracy: 0.9931 - val_loss: 0.4865 - val_binary_accuracy: 0.7826\n",
      "Epoch 191/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.0711 - binary_accuracy: 0.9931 - val_loss: 0.4725 - val_binary_accuracy: 0.8261\n",
      "Epoch 192/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.0811 - binary_accuracy: 0.9792 - val_loss: 0.8146 - val_binary_accuracy: 0.6957\n",
      "Epoch 193/200\n",
      "144/144 [==============================] - 0s 180us/step - loss: 0.0926 - binary_accuracy: 0.9931 - val_loss: 0.5298 - val_binary_accuracy: 0.7391\n",
      "Epoch 194/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.0618 - binary_accuracy: 1.0000 - val_loss: 0.4769 - val_binary_accuracy: 0.8261\n",
      "Epoch 195/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.0714 - binary_accuracy: 0.9931 - val_loss: 0.6132 - val_binary_accuracy: 0.7391\n",
      "Epoch 196/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.0590 - binary_accuracy: 0.9931 - val_loss: 0.4899 - val_binary_accuracy: 0.8696\n",
      "Epoch 197/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0723 - binary_accuracy: 0.9931 - val_loss: 0.6199 - val_binary_accuracy: 0.7391\n",
      "Epoch 198/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.0549 - binary_accuracy: 1.0000 - val_loss: 0.5504 - val_binary_accuracy: 0.7391\n",
      "Epoch 199/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0535 - binary_accuracy: 1.0000 - val_loss: 0.6106 - val_binary_accuracy: 0.7391\n",
      "Epoch 200/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0743 - binary_accuracy: 0.9861 - val_loss: 0.6276 - val_binary_accuracy: 0.7391\n"
     ]
    }
   ],
   "source": [
    "model_2 = neural_model()\n",
    "\n",
    "history = model_2.fit(x_train, encoded_y_train,validation_data = (x_val, encoded_y_val), epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.3314 - binary_accuracy: 0.8537\n"
     ]
    }
   ],
   "source": [
    "results = model_2.fit(x_test, encoded_y_test, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_binary_accuracy', 'loss', 'binary_accuracy'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, \"bo\", label = \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label = \"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying K-Fold Cross-Validation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/180\n",
      "144/144 [==============================] - 0s 741us/step - loss: 0.7059 - binary_accuracy: 0.5625\n",
      "Epoch 2/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.6938 - binary_accuracy: 0.5625\n",
      "Epoch 3/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.6876 - binary_accuracy: 0.5625\n",
      "Epoch 4/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.6834 - binary_accuracy: 0.5625\n",
      "Epoch 5/180\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.6774 - binary_accuracy: 0.5625\n",
      "Epoch 6/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6737 - binary_accuracy: 0.5625\n",
      "Epoch 7/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.6702 - binary_accuracy: 0.5625\n",
      "Epoch 8/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6645 - binary_accuracy: 0.5694\n",
      "Epoch 9/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6586 - binary_accuracy: 0.5694\n",
      "Epoch 10/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6505 - binary_accuracy: 0.5833\n",
      "Epoch 11/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.6461 - binary_accuracy: 0.5972\n",
      "Epoch 12/180\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.6388 - binary_accuracy: 0.6250\n",
      "Epoch 13/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6288 - binary_accuracy: 0.6458\n",
      "Epoch 14/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.6275 - binary_accuracy: 0.6250\n",
      "Epoch 15/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.6136 - binary_accuracy: 0.6597\n",
      "Epoch 16/180\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.6085 - binary_accuracy: 0.6806\n",
      "Epoch 17/180\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.6029 - binary_accuracy: 0.6875\n",
      "Epoch 18/180\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.5946 - binary_accuracy: 0.6875\n",
      "Epoch 19/180\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.5822 - binary_accuracy: 0.6875\n",
      "Epoch 20/180\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.5741 - binary_accuracy: 0.7222\n",
      "Epoch 21/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.5660 - binary_accuracy: 0.7431\n",
      "Epoch 22/180\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.5575 - binary_accuracy: 0.7361\n",
      "Epoch 23/180\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.5549 - binary_accuracy: 0.7292\n",
      "Epoch 24/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.5505 - binary_accuracy: 0.7361\n",
      "Epoch 25/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.5367 - binary_accuracy: 0.7292\n",
      "Epoch 26/180\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.5303 - binary_accuracy: 0.7431\n",
      "Epoch 27/180\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.5273 - binary_accuracy: 0.7708\n",
      "Epoch 28/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5145 - binary_accuracy: 0.7431\n",
      "Epoch 29/180\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.5136 - binary_accuracy: 0.7431\n",
      "Epoch 30/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4997 - binary_accuracy: 0.7778\n",
      "Epoch 31/180\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.4957 - binary_accuracy: 0.7708\n",
      "Epoch 32/180\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.4868 - binary_accuracy: 0.7500\n",
      "Epoch 33/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4808 - binary_accuracy: 0.7986\n",
      "Epoch 34/180\n",
      "144/144 [==============================] - 0s 166us/step - loss: 0.4912 - binary_accuracy: 0.7500\n",
      "Epoch 35/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.4747 - binary_accuracy: 0.8056\n",
      "Epoch 36/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4664 - binary_accuracy: 0.8056\n",
      "Epoch 37/180\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.4609 - binary_accuracy: 0.7917\n",
      "Epoch 38/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4547 - binary_accuracy: 0.8125\n",
      "Epoch 39/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4618 - binary_accuracy: 0.7639\n",
      "Epoch 40/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4460 - binary_accuracy: 0.8056\n",
      "Epoch 41/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4423 - binary_accuracy: 0.8125\n",
      "Epoch 42/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.4437 - binary_accuracy: 0.7778\n",
      "Epoch 43/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.4438 - binary_accuracy: 0.8056\n",
      "Epoch 44/180\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.4274 - binary_accuracy: 0.8194\n",
      "Epoch 45/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4311 - binary_accuracy: 0.7986\n",
      "Epoch 46/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4292 - binary_accuracy: 0.8333\n",
      "Epoch 47/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4221 - binary_accuracy: 0.8264\n",
      "Epoch 48/180\n",
      "144/144 [==============================] - 0s 166us/step - loss: 0.4363 - binary_accuracy: 0.8056\n",
      "Epoch 49/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4152 - binary_accuracy: 0.8056\n",
      "Epoch 50/180\n",
      "144/144 [==============================] - 0s 138us/step - loss: 0.4101 - binary_accuracy: 0.8194\n",
      "Epoch 51/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4092 - binary_accuracy: 0.8542\n",
      "Epoch 52/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4156 - binary_accuracy: 0.8403\n",
      "Epoch 53/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4007 - binary_accuracy: 0.8472\n",
      "Epoch 54/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4222 - binary_accuracy: 0.8125\n",
      "Epoch 55/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3974 - binary_accuracy: 0.8472\n",
      "Epoch 56/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3935 - binary_accuracy: 0.8333\n",
      "Epoch 57/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3895 - binary_accuracy: 0.8472\n",
      "Epoch 58/180\n",
      "144/144 [==============================] - 0s 138us/step - loss: 0.3909 - binary_accuracy: 0.8264\n",
      "Epoch 59/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3862 - binary_accuracy: 0.8403\n",
      "Epoch 60/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3854 - binary_accuracy: 0.8542\n",
      "Epoch 61/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.3874 - binary_accuracy: 0.8125\n",
      "Epoch 62/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3756 - binary_accuracy: 0.8472\n",
      "Epoch 63/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.3786 - binary_accuracy: 0.8472\n",
      "Epoch 64/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3732 - binary_accuracy: 0.8611\n",
      "Epoch 65/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3604 - binary_accuracy: 0.8750\n",
      "Epoch 66/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3639 - binary_accuracy: 0.8472\n",
      "Epoch 67/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3778 - binary_accuracy: 0.8472\n",
      "Epoch 68/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3683 - binary_accuracy: 0.8542\n",
      "Epoch 69/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.3578 - binary_accuracy: 0.8750\n",
      "Epoch 70/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3553 - binary_accuracy: 0.8681\n",
      "Epoch 71/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3489 - binary_accuracy: 0.8403\n",
      "Epoch 72/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3533 - binary_accuracy: 0.8611\n",
      "Epoch 73/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3560 - binary_accuracy: 0.8681\n",
      "Epoch 74/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 111us/step - loss: 0.3682 - binary_accuracy: 0.8403\n",
      "Epoch 75/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3475 - binary_accuracy: 0.8611\n",
      "Epoch 76/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3365 - binary_accuracy: 0.8750\n",
      "Epoch 77/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3574 - binary_accuracy: 0.8403\n",
      "Epoch 78/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3321 - binary_accuracy: 0.8889\n",
      "Epoch 79/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3291 - binary_accuracy: 0.9097\n",
      "Epoch 80/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3321 - binary_accuracy: 0.8611\n",
      "Epoch 81/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3303 - binary_accuracy: 0.8681\n",
      "Epoch 82/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3336 - binary_accuracy: 0.8611\n",
      "Epoch 83/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3471 - binary_accuracy: 0.8611\n",
      "Epoch 84/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3213 - binary_accuracy: 0.9028\n",
      "Epoch 85/180\n",
      "144/144 [==============================] - 0s 166us/step - loss: 0.3130 - binary_accuracy: 0.8889\n",
      "Epoch 86/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3195 - binary_accuracy: 0.8750\n",
      "Epoch 87/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3218 - binary_accuracy: 0.8750\n",
      "Epoch 88/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3047 - binary_accuracy: 0.9167\n",
      "Epoch 89/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3133 - binary_accuracy: 0.8611\n",
      "Epoch 90/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3086 - binary_accuracy: 0.8750\n",
      "Epoch 91/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3041 - binary_accuracy: 0.9097\n",
      "Epoch 92/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2952 - binary_accuracy: 0.9167\n",
      "Epoch 93/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2963 - binary_accuracy: 0.8889\n",
      "Epoch 94/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3266 - binary_accuracy: 0.8611\n",
      "Epoch 95/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2921 - binary_accuracy: 0.9167\n",
      "Epoch 96/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3056 - binary_accuracy: 0.8750\n",
      "Epoch 97/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2987 - binary_accuracy: 0.8889\n",
      "Epoch 98/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2969 - binary_accuracy: 0.8958\n",
      "Epoch 99/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2863 - binary_accuracy: 0.9097\n",
      "Epoch 100/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2951 - binary_accuracy: 0.8958\n",
      "Epoch 101/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2814 - binary_accuracy: 0.9097\n",
      "Epoch 102/180\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.2979 - binary_accuracy: 0.9028\n",
      "Epoch 103/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2797 - binary_accuracy: 0.9028\n",
      "Epoch 104/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2678 - binary_accuracy: 0.8958\n",
      "Epoch 105/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2783 - binary_accuracy: 0.9097\n",
      "Epoch 106/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2829 - binary_accuracy: 0.9028\n",
      "Epoch 107/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2682 - binary_accuracy: 0.9306\n",
      "Epoch 108/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2634 - binary_accuracy: 0.9236\n",
      "Epoch 109/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2848 - binary_accuracy: 0.9236\n",
      "Epoch 110/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2595 - binary_accuracy: 0.9306\n",
      "Epoch 111/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2661 - binary_accuracy: 0.8958\n",
      "Epoch 112/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2566 - binary_accuracy: 0.8889\n",
      "Epoch 113/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2532 - binary_accuracy: 0.9306\n",
      "Epoch 114/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2561 - binary_accuracy: 0.9306\n",
      "Epoch 115/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2449 - binary_accuracy: 0.9306\n",
      "Epoch 116/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2525 - binary_accuracy: 0.9375\n",
      "Epoch 117/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2468 - binary_accuracy: 0.9097\n",
      "Epoch 118/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2455 - binary_accuracy: 0.9236\n",
      "Epoch 119/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2685 - binary_accuracy: 0.8819\n",
      "Epoch 120/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2437 - binary_accuracy: 0.9306\n",
      "Epoch 121/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2335 - binary_accuracy: 0.9236\n",
      "Epoch 122/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2382 - binary_accuracy: 0.9306\n",
      "Epoch 123/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2333 - binary_accuracy: 0.9306\n",
      "Epoch 124/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2245 - binary_accuracy: 0.9444\n",
      "Epoch 125/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2304 - binary_accuracy: 0.9306\n",
      "Epoch 126/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2482 - binary_accuracy: 0.8889\n",
      "Epoch 127/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2215 - binary_accuracy: 0.9306\n",
      "Epoch 128/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2192 - binary_accuracy: 0.9444\n",
      "Epoch 129/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2340 - binary_accuracy: 0.9306\n",
      "Epoch 130/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2112 - binary_accuracy: 0.9375\n",
      "Epoch 131/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2097 - binary_accuracy: 0.9444\n",
      "Epoch 132/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2334 - binary_accuracy: 0.9097\n",
      "Epoch 133/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2160 - binary_accuracy: 0.9306\n",
      "Epoch 134/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2346 - binary_accuracy: 0.9375\n",
      "Epoch 135/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2075 - binary_accuracy: 0.9444\n",
      "Epoch 136/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2008 - binary_accuracy: 0.9514\n",
      "Epoch 137/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2218 - binary_accuracy: 0.9167\n",
      "Epoch 138/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1972 - binary_accuracy: 0.9444\n",
      "Epoch 139/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2205 - binary_accuracy: 0.9236\n",
      "Epoch 140/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1882 - binary_accuracy: 0.9514\n",
      "Epoch 141/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1999 - binary_accuracy: 0.9375\n",
      "Epoch 142/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1958 - binary_accuracy: 0.9236\n",
      "Epoch 143/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2194 - binary_accuracy: 0.9167\n",
      "Epoch 144/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1885 - binary_accuracy: 0.9653\n",
      "Epoch 145/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1879 - binary_accuracy: 0.9583\n",
      "Epoch 146/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1935 - binary_accuracy: 0.9444\n",
      "Epoch 147/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 111us/step - loss: 0.1929 - binary_accuracy: 0.9236\n",
      "Epoch 148/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2160 - binary_accuracy: 0.9167\n",
      "Epoch 149/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1721 - binary_accuracy: 0.9514\n",
      "Epoch 150/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1710 - binary_accuracy: 0.9583\n",
      "Epoch 151/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1740 - binary_accuracy: 0.9514\n",
      "Epoch 152/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1712 - binary_accuracy: 0.9583\n",
      "Epoch 153/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1993 - binary_accuracy: 0.9375\n",
      "Epoch 154/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1630 - binary_accuracy: 0.9583\n",
      "Epoch 155/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1813 - binary_accuracy: 0.9444\n",
      "Epoch 156/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1600 - binary_accuracy: 0.9653\n",
      "Epoch 157/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1805 - binary_accuracy: 0.9444\n",
      "Epoch 158/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1622 - binary_accuracy: 0.9653\n",
      "Epoch 159/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1557 - binary_accuracy: 0.9653\n",
      "Epoch 160/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1522 - binary_accuracy: 0.9653\n",
      "Epoch 161/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1602 - binary_accuracy: 0.9653\n",
      "Epoch 162/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1653 - binary_accuracy: 0.9583\n",
      "Epoch 163/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1574 - binary_accuracy: 0.9583\n",
      "Epoch 164/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1444 - binary_accuracy: 0.9583\n",
      "Epoch 165/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1558 - binary_accuracy: 0.9722\n",
      "Epoch 166/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1342 - binary_accuracy: 0.9792\n",
      "Epoch 167/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1722 - binary_accuracy: 0.9444\n",
      "Epoch 168/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1450 - binary_accuracy: 0.9792\n",
      "Epoch 169/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1322 - binary_accuracy: 0.9792\n",
      "Epoch 170/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1435 - binary_accuracy: 0.9583\n",
      "Epoch 171/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1269 - binary_accuracy: 0.9861\n",
      "Epoch 172/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1210 - binary_accuracy: 0.9792\n",
      "Epoch 173/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1252 - binary_accuracy: 0.9792\n",
      "Epoch 174/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1602 - binary_accuracy: 0.9583\n",
      "Epoch 175/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1188 - binary_accuracy: 0.9792\n",
      "Epoch 176/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1522 - binary_accuracy: 0.9583\n",
      "Epoch 177/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1121 - binary_accuracy: 0.9792\n",
      "Epoch 178/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1134 - binary_accuracy: 0.9583\n",
      "Epoch 179/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1278 - binary_accuracy: 0.9653\n",
      "Epoch 180/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1121 - binary_accuracy: 0.9861\n",
      "Epoch 1/180\n",
      "144/144 [==============================] - 0s 741us/step - loss: 0.6910 - binary_accuracy: 0.5625\n",
      "Epoch 2/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.6828 - binary_accuracy: 0.5625\n",
      "Epoch 3/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.6778 - binary_accuracy: 0.5625\n",
      "Epoch 4/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6725 - binary_accuracy: 0.5625\n",
      "Epoch 5/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6699 - binary_accuracy: 0.5625\n",
      "Epoch 6/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6646 - binary_accuracy: 0.5625\n",
      "Epoch 7/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6584 - binary_accuracy: 0.5694\n",
      "Epoch 8/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.6555 - binary_accuracy: 0.5625\n",
      "Epoch 9/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6506 - binary_accuracy: 0.5833\n",
      "Epoch 10/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6423 - binary_accuracy: 0.5972\n",
      "Epoch 11/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.6377 - binary_accuracy: 0.6319\n",
      "Epoch 12/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.6321 - binary_accuracy: 0.6736\n",
      "Epoch 13/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6232 - binary_accuracy: 0.6736\n",
      "Epoch 14/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6158 - binary_accuracy: 0.6875\n",
      "Epoch 15/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.6098 - binary_accuracy: 0.6806\n",
      "Epoch 16/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5983 - binary_accuracy: 0.7083\n",
      "Epoch 17/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5891 - binary_accuracy: 0.7222\n",
      "Epoch 18/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5875 - binary_accuracy: 0.7500\n",
      "Epoch 19/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5764 - binary_accuracy: 0.7153\n",
      "Epoch 20/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5676 - binary_accuracy: 0.7361\n",
      "Epoch 21/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.5591 - binary_accuracy: 0.7431\n",
      "Epoch 22/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5525 - binary_accuracy: 0.7569\n",
      "Epoch 23/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5412 - binary_accuracy: 0.7500\n",
      "Epoch 24/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5337 - binary_accuracy: 0.7569\n",
      "Epoch 25/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5359 - binary_accuracy: 0.7708\n",
      "Epoch 26/180\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.5240 - binary_accuracy: 0.7917\n",
      "Epoch 27/180\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.5109 - binary_accuracy: 0.7708\n",
      "Epoch 28/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5030 - binary_accuracy: 0.8194\n",
      "Epoch 29/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4998 - binary_accuracy: 0.7847\n",
      "Epoch 30/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4949 - binary_accuracy: 0.7917\n",
      "Epoch 31/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.4841 - binary_accuracy: 0.7917\n",
      "Epoch 32/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4862 - binary_accuracy: 0.7847\n",
      "Epoch 33/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4772 - binary_accuracy: 0.8264\n",
      "Epoch 34/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4663 - binary_accuracy: 0.8194\n",
      "Epoch 35/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4721 - binary_accuracy: 0.7917\n",
      "Epoch 36/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4632 - binary_accuracy: 0.7847\n",
      "Epoch 37/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4508 - binary_accuracy: 0.8333\n",
      "Epoch 38/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4462 - binary_accuracy: 0.8333\n",
      "Epoch 39/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.4451 - binary_accuracy: 0.7847\n",
      "Epoch 40/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 118us/step - loss: 0.4379 - binary_accuracy: 0.8194\n",
      "Epoch 41/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4314 - binary_accuracy: 0.8542\n",
      "Epoch 42/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.4253 - binary_accuracy: 0.8125\n",
      "Epoch 43/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.4317 - binary_accuracy: 0.8125\n",
      "Epoch 44/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4163 - binary_accuracy: 0.8403\n",
      "Epoch 45/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4129 - binary_accuracy: 0.8403\n",
      "Epoch 46/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4134 - binary_accuracy: 0.8333\n",
      "Epoch 47/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4106 - binary_accuracy: 0.8403\n",
      "Epoch 48/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3972 - binary_accuracy: 0.8611\n",
      "Epoch 49/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4008 - binary_accuracy: 0.8472\n",
      "Epoch 50/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3915 - binary_accuracy: 0.8681\n",
      "Epoch 51/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4019 - binary_accuracy: 0.8403\n",
      "Epoch 52/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3863 - binary_accuracy: 0.8472\n",
      "Epoch 53/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3768 - binary_accuracy: 0.8542\n",
      "Epoch 54/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3779 - binary_accuracy: 0.8403\n",
      "Epoch 55/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3725 - binary_accuracy: 0.8611\n",
      "Epoch 56/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3628 - binary_accuracy: 0.8889\n",
      "Epoch 57/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3625 - binary_accuracy: 0.8611\n",
      "Epoch 58/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3602 - binary_accuracy: 0.8681\n",
      "Epoch 59/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3581 - binary_accuracy: 0.8472\n",
      "Epoch 60/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3522 - binary_accuracy: 0.8472\n",
      "Epoch 61/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3567 - binary_accuracy: 0.8472\n",
      "Epoch 62/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3434 - binary_accuracy: 0.8819\n",
      "Epoch 63/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3387 - binary_accuracy: 0.8819\n",
      "Epoch 64/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.3507 - binary_accuracy: 0.8472\n",
      "Epoch 65/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3444 - binary_accuracy: 0.8472\n",
      "Epoch 66/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3397 - binary_accuracy: 0.8542\n",
      "Epoch 67/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3311 - binary_accuracy: 0.8681\n",
      "Epoch 68/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3249 - binary_accuracy: 0.8681\n",
      "Epoch 69/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3329 - binary_accuracy: 0.8403\n",
      "Epoch 70/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3209 - binary_accuracy: 0.8750\n",
      "Epoch 71/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3189 - binary_accuracy: 0.8750\n",
      "Epoch 72/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3203 - binary_accuracy: 0.8958\n",
      "Epoch 73/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3045 - binary_accuracy: 0.8958\n",
      "Epoch 74/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3079 - binary_accuracy: 0.8958\n",
      "Epoch 75/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3063 - binary_accuracy: 0.8750\n",
      "Epoch 76/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3004 - binary_accuracy: 0.8819\n",
      "Epoch 77/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3223 - binary_accuracy: 0.8750\n",
      "Epoch 78/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2899 - binary_accuracy: 0.9097\n",
      "Epoch 79/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2867 - binary_accuracy: 0.8819\n",
      "Epoch 80/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2986 - binary_accuracy: 0.8750\n",
      "Epoch 81/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2796 - binary_accuracy: 0.8889\n",
      "Epoch 82/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2819 - binary_accuracy: 0.8958\n",
      "Epoch 83/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2786 - binary_accuracy: 0.9028\n",
      "Epoch 84/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2861 - binary_accuracy: 0.8819\n",
      "Epoch 85/180\n",
      "144/144 [==============================] - 0s 122us/step - loss: 0.2915 - binary_accuracy: 0.8889\n",
      "Epoch 86/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2728 - binary_accuracy: 0.8958\n",
      "Epoch 87/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2726 - binary_accuracy: 0.8889\n",
      "Epoch 88/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2661 - binary_accuracy: 0.8958\n",
      "Epoch 89/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2611 - binary_accuracy: 0.9097\n",
      "Epoch 90/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2660 - binary_accuracy: 0.9028\n",
      "Epoch 91/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2668 - binary_accuracy: 0.8889\n",
      "Epoch 92/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2482 - binary_accuracy: 0.9306\n",
      "Epoch 93/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2657 - binary_accuracy: 0.8889\n",
      "Epoch 94/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2587 - binary_accuracy: 0.9097\n",
      "Epoch 95/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2498 - binary_accuracy: 0.9167\n",
      "Epoch 96/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2395 - binary_accuracy: 0.9375\n",
      "Epoch 97/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2399 - binary_accuracy: 0.9028\n",
      "Epoch 98/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2561 - binary_accuracy: 0.9028\n",
      "Epoch 99/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2367 - binary_accuracy: 0.9028\n",
      "Epoch 100/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2295 - binary_accuracy: 0.9167\n",
      "Epoch 101/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2305 - binary_accuracy: 0.9306\n",
      "Epoch 102/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2258 - binary_accuracy: 0.9167\n",
      "Epoch 103/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2282 - binary_accuracy: 0.9028\n",
      "Epoch 104/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2207 - binary_accuracy: 0.9167\n",
      "Epoch 105/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2162 - binary_accuracy: 0.9514\n",
      "Epoch 106/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2330 - binary_accuracy: 0.9167\n",
      "Epoch 107/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2142 - binary_accuracy: 0.9444\n",
      "Epoch 108/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2124 - binary_accuracy: 0.9444\n",
      "Epoch 109/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1994 - binary_accuracy: 0.9375\n",
      "Epoch 110/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1956 - binary_accuracy: 0.9583\n",
      "Epoch 111/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2058 - binary_accuracy: 0.9444\n",
      "Epoch 112/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2039 - binary_accuracy: 0.9514\n",
      "Epoch 113/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 118us/step - loss: 0.1941 - binary_accuracy: 0.9375\n",
      "Epoch 114/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1865 - binary_accuracy: 0.9653\n",
      "Epoch 115/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2064 - binary_accuracy: 0.9444\n",
      "Epoch 116/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1862 - binary_accuracy: 0.9444\n",
      "Epoch 117/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1922 - binary_accuracy: 0.9444\n",
      "Epoch 118/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1925 - binary_accuracy: 0.9167\n",
      "Epoch 119/180\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.1850 - binary_accuracy: 0.9444\n",
      "Epoch 120/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1907 - binary_accuracy: 0.9514\n",
      "Epoch 121/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1679 - binary_accuracy: 0.9514\n",
      "Epoch 122/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1723 - binary_accuracy: 0.9583\n",
      "Epoch 123/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1728 - binary_accuracy: 0.9653\n",
      "Epoch 124/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1637 - binary_accuracy: 0.9653\n",
      "Epoch 125/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1624 - binary_accuracy: 0.9583\n",
      "Epoch 126/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1787 - binary_accuracy: 0.9444\n",
      "Epoch 127/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1652 - binary_accuracy: 0.9514\n",
      "Epoch 128/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1683 - binary_accuracy: 0.9792\n",
      "Epoch 129/180\n",
      "144/144 [==============================] - 0s 138us/step - loss: 0.1494 - binary_accuracy: 0.9722\n",
      "Epoch 130/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1575 - binary_accuracy: 0.9653\n",
      "Epoch 131/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1428 - binary_accuracy: 0.9722\n",
      "Epoch 132/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1584 - binary_accuracy: 0.9583\n",
      "Epoch 133/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1826 - binary_accuracy: 0.9236\n",
      "Epoch 134/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1441 - binary_accuracy: 0.9653\n",
      "Epoch 135/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1517 - binary_accuracy: 0.9722\n",
      "Epoch 136/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1325 - binary_accuracy: 0.9722\n",
      "Epoch 137/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1359 - binary_accuracy: 0.9722\n",
      "Epoch 138/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1289 - binary_accuracy: 0.9861\n",
      "Epoch 139/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1577 - binary_accuracy: 0.9444\n",
      "Epoch 140/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1361 - binary_accuracy: 0.9792\n",
      "Epoch 141/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1358 - binary_accuracy: 0.9583\n",
      "Epoch 142/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1321 - binary_accuracy: 0.9653\n",
      "Epoch 143/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1304 - binary_accuracy: 0.9722\n",
      "Epoch 144/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1306 - binary_accuracy: 0.9653\n",
      "Epoch 145/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1203 - binary_accuracy: 0.9792\n",
      "Epoch 146/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1120 - binary_accuracy: 0.9792\n",
      "Epoch 147/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1177 - binary_accuracy: 0.9722\n",
      "Epoch 148/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1309 - binary_accuracy: 0.9514\n",
      "Epoch 149/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1413 - binary_accuracy: 0.9514\n",
      "Epoch 150/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1236 - binary_accuracy: 0.9722\n",
      "Epoch 151/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1105 - binary_accuracy: 0.9792\n",
      "Epoch 152/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1128 - binary_accuracy: 0.9792\n",
      "Epoch 153/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1093 - binary_accuracy: 0.9792\n",
      "Epoch 154/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0963 - binary_accuracy: 0.9931\n",
      "Epoch 155/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1255 - binary_accuracy: 0.9653\n",
      "Epoch 156/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1022 - binary_accuracy: 0.9722\n",
      "Epoch 157/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0895 - binary_accuracy: 0.9931\n",
      "Epoch 158/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1107 - binary_accuracy: 0.9861\n",
      "Epoch 159/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0877 - binary_accuracy: 0.9931\n",
      "Epoch 160/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0880 - binary_accuracy: 0.9861\n",
      "Epoch 161/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0915 - binary_accuracy: 0.9861\n",
      "Epoch 162/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0842 - binary_accuracy: 0.9861\n",
      "Epoch 163/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1048 - binary_accuracy: 0.9792\n",
      "Epoch 164/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0877 - binary_accuracy: 0.9792\n",
      "Epoch 165/180\n",
      "144/144 [==============================] - ETA: 0s - loss: 0.0509 - binary_accuracy: 1.000 - 0s 139us/step - loss: 0.0750 - binary_accuracy: 0.9931\n",
      "Epoch 166/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0802 - binary_accuracy: 0.9931\n",
      "Epoch 167/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0825 - binary_accuracy: 0.9931\n",
      "Epoch 168/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.0764 - binary_accuracy: 0.9861\n",
      "Epoch 169/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0662 - binary_accuracy: 0.9931\n",
      "Epoch 170/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0892 - binary_accuracy: 0.9792\n",
      "Epoch 171/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1015 - binary_accuracy: 0.9583\n",
      "Epoch 172/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0616 - binary_accuracy: 1.0000\n",
      "Epoch 173/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.0694 - binary_accuracy: 0.9931\n",
      "Epoch 174/180\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.0729 - binary_accuracy: 0.9931\n",
      "Epoch 175/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0606 - binary_accuracy: 1.0000\n",
      "Epoch 176/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0571 - binary_accuracy: 1.0000\n",
      "Epoch 177/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1574 - binary_accuracy: 0.9236\n",
      "Epoch 178/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.0535 - binary_accuracy: 1.0000\n",
      "Epoch 179/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.0525 - binary_accuracy: 0.9931\n",
      "Epoch 180/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.0565 - binary_accuracy: 0.9931\n",
      "Epoch 1/180\n",
      "144/144 [==============================] - 0s 886us/step - loss: 0.7154 - binary_accuracy: 0.4375\n",
      "Epoch 2/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6880 - binary_accuracy: 0.5625\n",
      "Epoch 3/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6765 - binary_accuracy: 0.6389\n",
      "Epoch 4/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6699 - binary_accuracy: 0.5903\n",
      "Epoch 5/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6658 - binary_accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6619 - binary_accuracy: 0.5694\n",
      "Epoch 7/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6606 - binary_accuracy: 0.5694\n",
      "Epoch 8/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.6543 - binary_accuracy: 0.5903\n",
      "Epoch 9/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.6500 - binary_accuracy: 0.5833\n",
      "Epoch 10/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.6454 - binary_accuracy: 0.5903\n",
      "Epoch 11/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.6412 - binary_accuracy: 0.6111\n",
      "Epoch 12/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.6354 - binary_accuracy: 0.7083\n",
      "Epoch 13/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.6288 - binary_accuracy: 0.6458\n",
      "Epoch 14/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6232 - binary_accuracy: 0.6875\n",
      "Epoch 15/180\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.6212 - binary_accuracy: 0.7431\n",
      "Epoch 16/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.6140 - binary_accuracy: 0.6667\n",
      "Epoch 17/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.6077 - binary_accuracy: 0.6944\n",
      "Epoch 18/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.6015 - binary_accuracy: 0.7431\n",
      "Epoch 19/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.5938 - binary_accuracy: 0.7639\n",
      "Epoch 20/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5880 - binary_accuracy: 0.7153\n",
      "Epoch 21/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5862 - binary_accuracy: 0.7847\n",
      "Epoch 22/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5738 - binary_accuracy: 0.7917\n",
      "Epoch 23/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5687 - binary_accuracy: 0.7500\n",
      "Epoch 24/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5617 - binary_accuracy: 0.7708\n",
      "Epoch 25/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5553 - binary_accuracy: 0.7778\n",
      "Epoch 26/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5463 - binary_accuracy: 0.7569\n",
      "Epoch 27/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.5393 - binary_accuracy: 0.7847\n",
      "Epoch 28/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5359 - binary_accuracy: 0.7569\n",
      "Epoch 29/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.5266 - binary_accuracy: 0.7778\n",
      "Epoch 30/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5180 - binary_accuracy: 0.7986\n",
      "Epoch 31/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.5163 - binary_accuracy: 0.8194\n",
      "Epoch 32/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5062 - binary_accuracy: 0.7986\n",
      "Epoch 33/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4988 - binary_accuracy: 0.7847\n",
      "Epoch 34/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4963 - binary_accuracy: 0.7986\n",
      "Epoch 35/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4874 - binary_accuracy: 0.7986\n",
      "Epoch 36/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.4828 - binary_accuracy: 0.8056\n",
      "Epoch 37/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4845 - binary_accuracy: 0.8125\n",
      "Epoch 38/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4707 - binary_accuracy: 0.8125\n",
      "Epoch 39/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4685 - binary_accuracy: 0.8056\n",
      "Epoch 40/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4638 - binary_accuracy: 0.8194\n",
      "Epoch 41/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4588 - binary_accuracy: 0.8264\n",
      "Epoch 42/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4546 - binary_accuracy: 0.8333\n",
      "Epoch 43/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4483 - binary_accuracy: 0.8264\n",
      "Epoch 44/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4454 - binary_accuracy: 0.8333\n",
      "Epoch 45/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4361 - binary_accuracy: 0.8472\n",
      "Epoch 46/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4386 - binary_accuracy: 0.8264\n",
      "Epoch 47/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4309 - binary_accuracy: 0.8542\n",
      "Epoch 48/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4332 - binary_accuracy: 0.8750\n",
      "Epoch 49/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4214 - binary_accuracy: 0.8681\n",
      "Epoch 50/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4162 - binary_accuracy: 0.8472\n",
      "Epoch 51/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4150 - binary_accuracy: 0.8472\n",
      "Epoch 52/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4175 - binary_accuracy: 0.8403\n",
      "Epoch 53/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4046 - binary_accuracy: 0.8819\n",
      "Epoch 54/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4168 - binary_accuracy: 0.8264\n",
      "Epoch 55/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3987 - binary_accuracy: 0.8681\n",
      "Epoch 56/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3966 - binary_accuracy: 0.8472\n",
      "Epoch 57/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3896 - binary_accuracy: 0.8681\n",
      "Epoch 58/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3947 - binary_accuracy: 0.8472\n",
      "Epoch 59/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3847 - binary_accuracy: 0.8750\n",
      "Epoch 60/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3835 - binary_accuracy: 0.8611\n",
      "Epoch 61/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.3836 - binary_accuracy: 0.8681\n",
      "Epoch 62/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3749 - binary_accuracy: 0.8750\n",
      "Epoch 63/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3788 - binary_accuracy: 0.8542\n",
      "Epoch 64/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3765 - binary_accuracy: 0.8472\n",
      "Epoch 65/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3712 - binary_accuracy: 0.8750\n",
      "Epoch 66/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3730 - binary_accuracy: 0.8611\n",
      "Epoch 67/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3673 - binary_accuracy: 0.8611\n",
      "Epoch 68/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3560 - binary_accuracy: 0.8819\n",
      "Epoch 69/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3653 - binary_accuracy: 0.8542\n",
      "Epoch 70/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3524 - binary_accuracy: 0.8750\n",
      "Epoch 71/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3545 - binary_accuracy: 0.8542\n",
      "Epoch 72/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3498 - binary_accuracy: 0.8889\n",
      "Epoch 73/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3556 - binary_accuracy: 0.8681\n",
      "Epoch 74/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3478 - binary_accuracy: 0.8958\n",
      "Epoch 75/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3394 - binary_accuracy: 0.8819\n",
      "Epoch 76/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3328 - binary_accuracy: 0.8889\n",
      "Epoch 77/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3288 - binary_accuracy: 0.8958\n",
      "Epoch 78/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3392 - binary_accuracy: 0.8889\n",
      "Epoch 79/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 118us/step - loss: 0.3249 - binary_accuracy: 0.8958\n",
      "Epoch 80/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3333 - binary_accuracy: 0.8750\n",
      "Epoch 81/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3318 - binary_accuracy: 0.8819\n",
      "Epoch 82/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3329 - binary_accuracy: 0.8750\n",
      "Epoch 83/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3205 - binary_accuracy: 0.8958\n",
      "Epoch 84/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3171 - binary_accuracy: 0.8819\n",
      "Epoch 85/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3196 - binary_accuracy: 0.8889\n",
      "Epoch 86/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3114 - binary_accuracy: 0.8958\n",
      "Epoch 87/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3161 - binary_accuracy: 0.8750\n",
      "Epoch 88/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3083 - binary_accuracy: 0.8819\n",
      "Epoch 89/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3176 - binary_accuracy: 0.8681\n",
      "Epoch 90/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2966 - binary_accuracy: 0.8958\n",
      "Epoch 91/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3341 - binary_accuracy: 0.8819\n",
      "Epoch 92/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2958 - binary_accuracy: 0.9028\n",
      "Epoch 93/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2976 - binary_accuracy: 0.9097\n",
      "Epoch 94/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2890 - binary_accuracy: 0.9028\n",
      "Epoch 95/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.3064 - binary_accuracy: 0.8958\n",
      "Epoch 96/180\n",
      "144/144 [==============================] - 0s 138us/step - loss: 0.2981 - binary_accuracy: 0.8750\n",
      "Epoch 97/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2815 - binary_accuracy: 0.9028\n",
      "Epoch 98/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2809 - binary_accuracy: 0.9167\n",
      "Epoch 99/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2872 - binary_accuracy: 0.9097\n",
      "Epoch 100/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2760 - binary_accuracy: 0.9236\n",
      "Epoch 101/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2831 - binary_accuracy: 0.8889\n",
      "Epoch 102/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2732 - binary_accuracy: 0.9167\n",
      "Epoch 103/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2835 - binary_accuracy: 0.8889\n",
      "Epoch 104/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2803 - binary_accuracy: 0.8958\n",
      "Epoch 105/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2805 - binary_accuracy: 0.8889\n",
      "Epoch 106/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2641 - binary_accuracy: 0.9028\n",
      "Epoch 107/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2555 - binary_accuracy: 0.9236\n",
      "Epoch 108/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2712 - binary_accuracy: 0.9028\n",
      "Epoch 109/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2570 - binary_accuracy: 0.9028\n",
      "Epoch 110/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2496 - binary_accuracy: 0.9236\n",
      "Epoch 111/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2591 - binary_accuracy: 0.9306\n",
      "Epoch 112/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2476 - binary_accuracy: 0.9236\n",
      "Epoch 113/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2419 - binary_accuracy: 0.9306\n",
      "Epoch 114/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2399 - binary_accuracy: 0.9444\n",
      "Epoch 115/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2738 - binary_accuracy: 0.8958\n",
      "Epoch 116/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2380 - binary_accuracy: 0.9583\n",
      "Epoch 117/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2467 - binary_accuracy: 0.8958\n",
      "Epoch 118/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2335 - binary_accuracy: 0.9306\n",
      "Epoch 119/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2388 - binary_accuracy: 0.9306\n",
      "Epoch 120/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2292 - binary_accuracy: 0.9514\n",
      "Epoch 121/180\n",
      "144/144 [==============================] - 0s 117us/step - loss: 0.2410 - binary_accuracy: 0.9167\n",
      "Epoch 122/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2186 - binary_accuracy: 0.9653\n",
      "Epoch 123/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2215 - binary_accuracy: 0.9444\n",
      "Epoch 124/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2304 - binary_accuracy: 0.9306\n",
      "Epoch 125/180\n",
      "144/144 [==============================] - ETA: 0s - loss: 0.3170 - binary_accuracy: 0.843 - 0s 111us/step - loss: 0.2329 - binary_accuracy: 0.9306\n",
      "Epoch 126/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2216 - binary_accuracy: 0.9444\n",
      "Epoch 127/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2091 - binary_accuracy: 0.9514\n",
      "Epoch 128/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2311 - binary_accuracy: 0.9306\n",
      "Epoch 129/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2351 - binary_accuracy: 0.9306\n",
      "Epoch 130/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2162 - binary_accuracy: 0.9444\n",
      "Epoch 131/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2063 - binary_accuracy: 0.9514\n",
      "Epoch 132/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2118 - binary_accuracy: 0.9514\n",
      "Epoch 133/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1972 - binary_accuracy: 0.9653\n",
      "Epoch 134/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2110 - binary_accuracy: 0.9514\n",
      "Epoch 135/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2044 - binary_accuracy: 0.9375\n",
      "Epoch 136/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1917 - binary_accuracy: 0.9583\n",
      "Epoch 137/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1974 - binary_accuracy: 0.9444\n",
      "Epoch 138/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1913 - binary_accuracy: 0.9514\n",
      "Epoch 139/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1903 - binary_accuracy: 0.9722\n",
      "Epoch 140/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1876 - binary_accuracy: 0.9583\n",
      "Epoch 141/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1867 - binary_accuracy: 0.9375\n",
      "Epoch 142/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1874 - binary_accuracy: 0.9722\n",
      "Epoch 143/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1881 - binary_accuracy: 0.9722\n",
      "Epoch 144/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1953 - binary_accuracy: 0.9583\n",
      "Epoch 145/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1995 - binary_accuracy: 0.9514\n",
      "Epoch 146/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1691 - binary_accuracy: 0.9653\n",
      "Epoch 147/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1828 - binary_accuracy: 0.9583\n",
      "Epoch 148/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1688 - binary_accuracy: 0.9722\n",
      "Epoch 149/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2033 - binary_accuracy: 0.9306\n",
      "Epoch 150/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1664 - binary_accuracy: 0.9722\n",
      "Epoch 151/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1750 - binary_accuracy: 0.9583\n",
      "Epoch 152/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 111us/step - loss: 0.1670 - binary_accuracy: 0.9653\n",
      "Epoch 153/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1642 - binary_accuracy: 0.9653\n",
      "Epoch 154/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1568 - binary_accuracy: 0.9722\n",
      "Epoch 155/180\n",
      "144/144 [==============================] - 0s 201us/step - loss: 0.1632 - binary_accuracy: 0.9722\n",
      "Epoch 156/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1688 - binary_accuracy: 0.9514\n",
      "Epoch 157/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1518 - binary_accuracy: 0.9792\n",
      "Epoch 158/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1504 - binary_accuracy: 0.9722\n",
      "Epoch 159/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1576 - binary_accuracy: 0.9722\n",
      "Epoch 160/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1516 - binary_accuracy: 0.9722\n",
      "Epoch 161/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1450 - binary_accuracy: 0.9792\n",
      "Epoch 162/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1448 - binary_accuracy: 0.9722\n",
      "Epoch 163/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1825 - binary_accuracy: 0.9444\n",
      "Epoch 164/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1452 - binary_accuracy: 0.9722\n",
      "Epoch 165/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1679 - binary_accuracy: 0.9514\n",
      "Epoch 166/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1338 - binary_accuracy: 0.9722\n",
      "Epoch 167/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1346 - binary_accuracy: 0.9792\n",
      "Epoch 168/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1477 - binary_accuracy: 0.9722\n",
      "Epoch 169/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1305 - binary_accuracy: 0.9722\n",
      "Epoch 170/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1469 - binary_accuracy: 0.9792\n",
      "Epoch 171/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1365 - binary_accuracy: 0.9792\n",
      "Epoch 172/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1260 - binary_accuracy: 0.9792\n",
      "Epoch 173/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1266 - binary_accuracy: 0.9792\n",
      "Epoch 174/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1269 - binary_accuracy: 0.9861\n",
      "Epoch 175/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1262 - binary_accuracy: 0.9792\n",
      "Epoch 176/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1197 - binary_accuracy: 0.9861\n",
      "Epoch 177/180\n",
      "144/144 [==============================] - 0s 124us/step - loss: 0.1378 - binary_accuracy: 0.9653\n",
      "Epoch 178/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1341 - binary_accuracy: 0.9861\n",
      "Epoch 179/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1343 - binary_accuracy: 0.9722\n",
      "Epoch 180/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1133 - binary_accuracy: 0.9861\n",
      "Epoch 1/180\n",
      "144/144 [==============================] - 0s 790us/step - loss: 0.7738 - binary_accuracy: 0.4375\n",
      "Epoch 2/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.7056 - binary_accuracy: 0.4444\n",
      "Epoch 3/180\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.6837 - binary_accuracy: 0.5069\n",
      "Epoch 4/180\n",
      "144/144 [==============================] - 0s 138us/step - loss: 0.6753 - binary_accuracy: 0.5903\n",
      "Epoch 5/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.6654 - binary_accuracy: 0.6250\n",
      "Epoch 6/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6609 - binary_accuracy: 0.6181\n",
      "Epoch 7/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6546 - binary_accuracy: 0.6111\n",
      "Epoch 8/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6509 - binary_accuracy: 0.6042\n",
      "Epoch 9/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.6456 - binary_accuracy: 0.5903\n",
      "Epoch 10/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6400 - binary_accuracy: 0.6528\n",
      "Epoch 11/180\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.6346 - binary_accuracy: 0.6597\n",
      "Epoch 12/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6304 - binary_accuracy: 0.6875\n",
      "Epoch 13/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6232 - binary_accuracy: 0.6389\n",
      "Epoch 14/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6151 - binary_accuracy: 0.7847\n",
      "Epoch 15/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6090 - binary_accuracy: 0.7292\n",
      "Epoch 16/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.5993 - binary_accuracy: 0.7569\n",
      "Epoch 17/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.5912 - binary_accuracy: 0.7847\n",
      "Epoch 18/180\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.5824 - binary_accuracy: 0.7639\n",
      "Epoch 19/180\n",
      "144/144 [==============================] - 0s 138us/step - loss: 0.5790 - binary_accuracy: 0.7986\n",
      "Epoch 20/180\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.5656 - binary_accuracy: 0.8125\n",
      "Epoch 21/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.5606 - binary_accuracy: 0.8056\n",
      "Epoch 22/180\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.5522 - binary_accuracy: 0.7917\n",
      "Epoch 23/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5455 - binary_accuracy: 0.8125\n",
      "Epoch 24/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.5397 - binary_accuracy: 0.8125\n",
      "Epoch 25/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.5297 - binary_accuracy: 0.8194\n",
      "Epoch 26/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.5254 - binary_accuracy: 0.7708\n",
      "Epoch 27/180\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.5180 - binary_accuracy: 0.8194\n",
      "Epoch 28/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5094 - binary_accuracy: 0.8125\n",
      "Epoch 29/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.5066 - binary_accuracy: 0.7986\n",
      "Epoch 30/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4987 - binary_accuracy: 0.8056\n",
      "Epoch 31/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4941 - binary_accuracy: 0.8056\n",
      "Epoch 32/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4828 - binary_accuracy: 0.8194\n",
      "Epoch 33/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4745 - binary_accuracy: 0.8264\n",
      "Epoch 34/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4763 - binary_accuracy: 0.8403\n",
      "Epoch 35/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4665 - binary_accuracy: 0.8403\n",
      "Epoch 36/180\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.4627 - binary_accuracy: 0.8333\n",
      "Epoch 37/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4592 - binary_accuracy: 0.8333\n",
      "Epoch 38/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4473 - binary_accuracy: 0.8264\n",
      "Epoch 39/180\n",
      "144/144 [==============================] - 0s 166us/step - loss: 0.4531 - binary_accuracy: 0.8264\n",
      "Epoch 40/180\n",
      "144/144 [==============================] - 0s 201us/step - loss: 0.4405 - binary_accuracy: 0.8472\n",
      "Epoch 41/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4320 - binary_accuracy: 0.8403\n",
      "Epoch 42/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4327 - binary_accuracy: 0.8611\n",
      "Epoch 43/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4224 - binary_accuracy: 0.8681\n",
      "Epoch 44/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4179 - binary_accuracy: 0.8472\n",
      "Epoch 45/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 132us/step - loss: 0.4170 - binary_accuracy: 0.8333\n",
      "Epoch 46/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4139 - binary_accuracy: 0.8264\n",
      "Epoch 47/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4096 - binary_accuracy: 0.8472\n",
      "Epoch 48/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4063 - binary_accuracy: 0.8403\n",
      "Epoch 49/180\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.4080 - binary_accuracy: 0.8194\n",
      "Epoch 50/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3932 - binary_accuracy: 0.8750\n",
      "Epoch 51/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.3938 - binary_accuracy: 0.8542\n",
      "Epoch 52/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3887 - binary_accuracy: 0.8611\n",
      "Epoch 53/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3896 - binary_accuracy: 0.8542\n",
      "Epoch 54/180\n",
      "144/144 [==============================] - 0s 138us/step - loss: 0.3816 - binary_accuracy: 0.8750\n",
      "Epoch 55/180\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.3762 - binary_accuracy: 0.8819\n",
      "Epoch 56/180\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.3696 - binary_accuracy: 0.8819\n",
      "Epoch 57/180\n",
      "144/144 [==============================] - 0s 201us/step - loss: 0.3763 - binary_accuracy: 0.8472\n",
      "Epoch 58/180\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.3679 - binary_accuracy: 0.8681\n",
      "Epoch 59/180\n",
      "144/144 [==============================] - 0s 235us/step - loss: 0.3694 - binary_accuracy: 0.8681\n",
      "Epoch 60/180\n",
      "144/144 [==============================] - 0s 194us/step - loss: 0.3711 - binary_accuracy: 0.8403\n",
      "Epoch 61/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3724 - binary_accuracy: 0.8542\n",
      "Epoch 62/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3650 - binary_accuracy: 0.8681\n",
      "Epoch 63/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3633 - binary_accuracy: 0.8681\n",
      "Epoch 64/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3560 - binary_accuracy: 0.8472\n",
      "Epoch 65/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.3490 - binary_accuracy: 0.8750\n",
      "Epoch 66/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.3573 - binary_accuracy: 0.8611\n",
      "Epoch 67/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3521 - binary_accuracy: 0.8750\n",
      "Epoch 68/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.3580 - binary_accuracy: 0.8681\n",
      "Epoch 69/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.3402 - binary_accuracy: 0.8889\n",
      "Epoch 70/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3444 - binary_accuracy: 0.8681\n",
      "Epoch 71/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3375 - binary_accuracy: 0.8750\n",
      "Epoch 72/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3431 - binary_accuracy: 0.8611\n",
      "Epoch 73/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.3359 - binary_accuracy: 0.8889\n",
      "Epoch 74/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.3313 - binary_accuracy: 0.8611\n",
      "Epoch 75/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.3394 - binary_accuracy: 0.8889\n",
      "Epoch 76/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.3361 - binary_accuracy: 0.8472\n",
      "Epoch 77/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.3225 - binary_accuracy: 0.8958\n",
      "Epoch 78/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3231 - binary_accuracy: 0.8958\n",
      "Epoch 79/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.3345 - binary_accuracy: 0.8542\n",
      "Epoch 80/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.3200 - binary_accuracy: 0.8611\n",
      "Epoch 81/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.3206 - binary_accuracy: 0.8958\n",
      "Epoch 82/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3287 - binary_accuracy: 0.8750\n",
      "Epoch 83/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.3286 - binary_accuracy: 0.8681\n",
      "Epoch 84/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.3258 - binary_accuracy: 0.8611\n",
      "Epoch 85/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3058 - binary_accuracy: 0.8958\n",
      "Epoch 86/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3064 - binary_accuracy: 0.8958\n",
      "Epoch 87/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3053 - binary_accuracy: 0.8889\n",
      "Epoch 88/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2951 - binary_accuracy: 0.9028\n",
      "Epoch 89/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3037 - binary_accuracy: 0.8889\n",
      "Epoch 90/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2973 - binary_accuracy: 0.8819\n",
      "Epoch 91/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2972 - binary_accuracy: 0.8889\n",
      "Epoch 92/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2885 - binary_accuracy: 0.9028\n",
      "Epoch 93/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2954 - binary_accuracy: 0.8958\n",
      "Epoch 94/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2946 - binary_accuracy: 0.8958\n",
      "Epoch 95/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2884 - binary_accuracy: 0.8889\n",
      "Epoch 96/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2825 - binary_accuracy: 0.9028\n",
      "Epoch 97/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2951 - binary_accuracy: 0.8958\n",
      "Epoch 98/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2891 - binary_accuracy: 0.8958\n",
      "Epoch 99/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2729 - binary_accuracy: 0.9167\n",
      "Epoch 100/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.3009 - binary_accuracy: 0.8889\n",
      "Epoch 101/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2915 - binary_accuracy: 0.9028\n",
      "Epoch 102/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2785 - binary_accuracy: 0.9097\n",
      "Epoch 103/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2841 - binary_accuracy: 0.9028\n",
      "Epoch 104/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2692 - binary_accuracy: 0.9097\n",
      "Epoch 105/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2686 - binary_accuracy: 0.9097\n",
      "Epoch 106/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2632 - binary_accuracy: 0.9028\n",
      "Epoch 107/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2741 - binary_accuracy: 0.8958\n",
      "Epoch 108/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2712 - binary_accuracy: 0.9097\n",
      "Epoch 109/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2784 - binary_accuracy: 0.9028\n",
      "Epoch 110/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2668 - binary_accuracy: 0.9028\n",
      "Epoch 111/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2637 - binary_accuracy: 0.9097\n",
      "Epoch 112/180\n",
      "144/144 [==============================] - ETA: 0s - loss: 0.2761 - binary_accuracy: 0.937 - 0s 90us/step - loss: 0.2624 - binary_accuracy: 0.8958\n",
      "Epoch 113/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2577 - binary_accuracy: 0.9097\n",
      "Epoch 114/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2474 - binary_accuracy: 0.9236\n",
      "Epoch 115/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2557 - binary_accuracy: 0.9167\n",
      "Epoch 116/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2529 - binary_accuracy: 0.9097\n",
      "Epoch 117/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2649 - binary_accuracy: 0.8958\n",
      "Epoch 118/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 83us/step - loss: 0.2535 - binary_accuracy: 0.9028\n",
      "Epoch 119/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2405 - binary_accuracy: 0.9236\n",
      "Epoch 120/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2482 - binary_accuracy: 0.9236\n",
      "Epoch 121/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2572 - binary_accuracy: 0.9167\n",
      "Epoch 122/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2401 - binary_accuracy: 0.9097\n",
      "Epoch 123/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2381 - binary_accuracy: 0.9236\n",
      "Epoch 124/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2391 - binary_accuracy: 0.9236\n",
      "Epoch 125/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2311 - binary_accuracy: 0.9236\n",
      "Epoch 126/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2632 - binary_accuracy: 0.8889\n",
      "Epoch 127/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2375 - binary_accuracy: 0.9306\n",
      "Epoch 128/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2316 - binary_accuracy: 0.9236\n",
      "Epoch 129/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2413 - binary_accuracy: 0.9028\n",
      "Epoch 130/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2323 - binary_accuracy: 0.9306\n",
      "Epoch 131/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2256 - binary_accuracy: 0.9236\n",
      "Epoch 132/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2227 - binary_accuracy: 0.9306\n",
      "Epoch 133/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2378 - binary_accuracy: 0.9167\n",
      "Epoch 134/180\n",
      "144/144 [==============================] - 0s 76us/step - loss: 0.2202 - binary_accuracy: 0.9306\n",
      "Epoch 135/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2417 - binary_accuracy: 0.9097\n",
      "Epoch 136/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2137 - binary_accuracy: 0.9375\n",
      "Epoch 137/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2223 - binary_accuracy: 0.9444\n",
      "Epoch 138/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2148 - binary_accuracy: 0.9514\n",
      "Epoch 139/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2101 - binary_accuracy: 0.9236\n",
      "Epoch 140/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2063 - binary_accuracy: 0.9375\n",
      "Epoch 141/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2038 - binary_accuracy: 0.9514\n",
      "Epoch 142/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2255 - binary_accuracy: 0.9306\n",
      "Epoch 143/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2044 - binary_accuracy: 0.9375\n",
      "Epoch 144/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1967 - binary_accuracy: 0.9444\n",
      "Epoch 145/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2129 - binary_accuracy: 0.9306\n",
      "Epoch 146/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2057 - binary_accuracy: 0.9514\n",
      "Epoch 147/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1978 - binary_accuracy: 0.9514\n",
      "Epoch 148/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2076 - binary_accuracy: 0.9306\n",
      "Epoch 149/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2106 - binary_accuracy: 0.9375\n",
      "Epoch 150/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1856 - binary_accuracy: 0.9514\n",
      "Epoch 151/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1895 - binary_accuracy: 0.9375\n",
      "Epoch 152/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2000 - binary_accuracy: 0.9514\n",
      "Epoch 153/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1871 - binary_accuracy: 0.9514\n",
      "Epoch 154/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2031 - binary_accuracy: 0.9306\n",
      "Epoch 155/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2094 - binary_accuracy: 0.9236\n",
      "Epoch 156/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2018 - binary_accuracy: 0.9236\n",
      "Epoch 157/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1798 - binary_accuracy: 0.9583\n",
      "Epoch 158/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1824 - binary_accuracy: 0.9514\n",
      "Epoch 159/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1971 - binary_accuracy: 0.9375\n",
      "Epoch 160/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1901 - binary_accuracy: 0.9375\n",
      "Epoch 161/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1893 - binary_accuracy: 0.9514\n",
      "Epoch 162/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1785 - binary_accuracy: 0.9653\n",
      "Epoch 163/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1731 - binary_accuracy: 0.9514\n",
      "Epoch 164/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1989 - binary_accuracy: 0.9444\n",
      "Epoch 165/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1946 - binary_accuracy: 0.9375\n",
      "Epoch 166/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1845 - binary_accuracy: 0.9375\n",
      "Epoch 167/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1655 - binary_accuracy: 0.9653\n",
      "Epoch 168/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1728 - binary_accuracy: 0.9514\n",
      "Epoch 169/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1786 - binary_accuracy: 0.9514\n",
      "Epoch 170/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1647 - binary_accuracy: 0.9653\n",
      "Epoch 171/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1585 - binary_accuracy: 0.9722\n",
      "Epoch 172/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1550 - binary_accuracy: 0.9792\n",
      "Epoch 173/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1833 - binary_accuracy: 0.9444\n",
      "Epoch 174/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1549 - binary_accuracy: 0.9722\n",
      "Epoch 175/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1655 - binary_accuracy: 0.9583\n",
      "Epoch 176/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1604 - binary_accuracy: 0.9722\n",
      "Epoch 177/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1452 - binary_accuracy: 0.9722\n",
      "Epoch 178/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1714 - binary_accuracy: 0.9514\n",
      "Epoch 179/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1479 - binary_accuracy: 0.9653\n",
      "Epoch 180/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1489 - binary_accuracy: 0.9653\n",
      "Epoch 1/180\n",
      "144/144 [==============================] - 0s 852us/step - loss: 0.6846 - binary_accuracy: 0.5625\n",
      "Epoch 2/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.6764 - binary_accuracy: 0.5625\n",
      "Epoch 3/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.6716 - binary_accuracy: 0.5625\n",
      "Epoch 4/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.6648 - binary_accuracy: 0.5625\n",
      "Epoch 5/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.6612 - binary_accuracy: 0.5625\n",
      "Epoch 6/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.6536 - binary_accuracy: 0.5694\n",
      "Epoch 7/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.6477 - binary_accuracy: 0.5833\n",
      "Epoch 8/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.6397 - binary_accuracy: 0.6042\n",
      "Epoch 9/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.6374 - binary_accuracy: 0.6528\n",
      "Epoch 10/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.6248 - binary_accuracy: 0.6111\n",
      "Epoch 11/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.6171 - binary_accuracy: 0.7083\n",
      "Epoch 12/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 97us/step - loss: 0.6104 - binary_accuracy: 0.7014\n",
      "Epoch 13/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.6026 - binary_accuracy: 0.6875\n",
      "Epoch 14/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.5960 - binary_accuracy: 0.7014\n",
      "Epoch 15/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.5866 - binary_accuracy: 0.6944\n",
      "Epoch 16/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5759 - binary_accuracy: 0.7361\n",
      "Epoch 17/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5669 - binary_accuracy: 0.7639\n",
      "Epoch 18/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.5593 - binary_accuracy: 0.7500\n",
      "Epoch 19/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.5496 - binary_accuracy: 0.7639\n",
      "Epoch 20/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.5449 - binary_accuracy: 0.7569\n",
      "Epoch 21/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.5315 - binary_accuracy: 0.7917\n",
      "Epoch 22/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.5268 - binary_accuracy: 0.7778\n",
      "Epoch 23/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.5212 - binary_accuracy: 0.7778\n",
      "Epoch 24/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.5095 - binary_accuracy: 0.7986\n",
      "Epoch 25/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.5072 - binary_accuracy: 0.7986\n",
      "Epoch 26/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.4931 - binary_accuracy: 0.8194\n",
      "Epoch 27/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.4937 - binary_accuracy: 0.7778\n",
      "Epoch 28/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.4833 - binary_accuracy: 0.8056\n",
      "Epoch 29/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.4764 - binary_accuracy: 0.7778\n",
      "Epoch 30/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.4769 - binary_accuracy: 0.8056\n",
      "Epoch 31/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.4639 - binary_accuracy: 0.8194\n",
      "Epoch 32/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.4555 - binary_accuracy: 0.8333\n",
      "Epoch 33/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.4501 - binary_accuracy: 0.7986\n",
      "Epoch 34/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.4414 - binary_accuracy: 0.8542\n",
      "Epoch 35/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.4446 - binary_accuracy: 0.8194\n",
      "Epoch 36/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.4325 - binary_accuracy: 0.8472\n",
      "Epoch 37/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.4327 - binary_accuracy: 0.8333\n",
      "Epoch 38/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.4232 - binary_accuracy: 0.8403\n",
      "Epoch 39/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.4151 - binary_accuracy: 0.8472\n",
      "Epoch 40/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.4205 - binary_accuracy: 0.8472\n",
      "Epoch 41/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.4111 - binary_accuracy: 0.8542\n",
      "Epoch 42/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.4050 - binary_accuracy: 0.8681\n",
      "Epoch 43/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.4011 - binary_accuracy: 0.8542\n",
      "Epoch 44/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3922 - binary_accuracy: 0.8681\n",
      "Epoch 45/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3878 - binary_accuracy: 0.8681\n",
      "Epoch 46/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3858 - binary_accuracy: 0.8611\n",
      "Epoch 47/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3811 - binary_accuracy: 0.8750\n",
      "Epoch 48/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3683 - binary_accuracy: 0.8750\n",
      "Epoch 49/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3765 - binary_accuracy: 0.8333\n",
      "Epoch 50/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3613 - binary_accuracy: 0.8750\n",
      "Epoch 51/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3726 - binary_accuracy: 0.8542\n",
      "Epoch 52/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3574 - binary_accuracy: 0.8889\n",
      "Epoch 53/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3633 - binary_accuracy: 0.8819\n",
      "Epoch 54/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3403 - binary_accuracy: 0.8819\n",
      "Epoch 55/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3444 - binary_accuracy: 0.8750\n",
      "Epoch 56/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3426 - binary_accuracy: 0.9028\n",
      "Epoch 57/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3336 - binary_accuracy: 0.8958\n",
      "Epoch 58/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3304 - binary_accuracy: 0.8889\n",
      "Epoch 59/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3320 - binary_accuracy: 0.8750\n",
      "Epoch 60/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3239 - binary_accuracy: 0.9097\n",
      "Epoch 61/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3202 - binary_accuracy: 0.8819\n",
      "Epoch 62/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3147 - binary_accuracy: 0.8958\n",
      "Epoch 63/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3053 - binary_accuracy: 0.9236\n",
      "Epoch 64/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2997 - binary_accuracy: 0.8889\n",
      "Epoch 65/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3084 - binary_accuracy: 0.8819\n",
      "Epoch 66/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2902 - binary_accuracy: 0.9097\n",
      "Epoch 67/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3019 - binary_accuracy: 0.9097\n",
      "Epoch 68/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2896 - binary_accuracy: 0.9167\n",
      "Epoch 69/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2805 - binary_accuracy: 0.9097\n",
      "Epoch 70/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2787 - binary_accuracy: 0.9236\n",
      "Epoch 71/180\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.2682 - binary_accuracy: 0.9306\n",
      "Epoch 72/180\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2681 - binary_accuracy: 0.9306\n",
      "Epoch 73/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2692 - binary_accuracy: 0.9236\n",
      "Epoch 74/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2855 - binary_accuracy: 0.8958\n",
      "Epoch 75/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2494 - binary_accuracy: 0.9444\n",
      "Epoch 76/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2625 - binary_accuracy: 0.9306\n",
      "Epoch 77/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2443 - binary_accuracy: 0.9306\n",
      "Epoch 78/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2481 - binary_accuracy: 0.9306\n",
      "Epoch 79/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2442 - binary_accuracy: 0.9167\n",
      "Epoch 80/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2374 - binary_accuracy: 0.9375\n",
      "Epoch 81/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2379 - binary_accuracy: 0.9306\n",
      "Epoch 82/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2165 - binary_accuracy: 0.9583\n",
      "Epoch 83/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2200 - binary_accuracy: 0.9514\n",
      "Epoch 84/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2432 - binary_accuracy: 0.9306\n",
      "Epoch 85/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2207 - binary_accuracy: 0.9306\n",
      "Epoch 86/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 104us/step - loss: 0.2107 - binary_accuracy: 0.9514\n",
      "Epoch 87/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2007 - binary_accuracy: 0.9514\n",
      "Epoch 88/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2302 - binary_accuracy: 0.9306\n",
      "Epoch 89/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2158 - binary_accuracy: 0.9514\n",
      "Epoch 90/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1957 - binary_accuracy: 0.9653\n",
      "Epoch 91/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2034 - binary_accuracy: 0.9514\n",
      "Epoch 92/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1850 - binary_accuracy: 0.9514\n",
      "Epoch 93/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1850 - binary_accuracy: 0.9583\n",
      "Epoch 94/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1784 - binary_accuracy: 0.9722\n",
      "Epoch 95/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1714 - binary_accuracy: 0.9583\n",
      "Epoch 96/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1747 - binary_accuracy: 0.9722\n",
      "Epoch 97/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1834 - binary_accuracy: 0.9583\n",
      "Epoch 98/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1739 - binary_accuracy: 0.9583\n",
      "Epoch 99/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1657 - binary_accuracy: 0.9722\n",
      "Epoch 100/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1548 - binary_accuracy: 0.9722\n",
      "Epoch 101/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1688 - binary_accuracy: 0.9583\n",
      "Epoch 102/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1542 - binary_accuracy: 0.9722\n",
      "Epoch 103/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1483 - binary_accuracy: 0.9653\n",
      "Epoch 104/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1496 - binary_accuracy: 0.9722\n",
      "Epoch 105/180\n",
      "144/144 [==============================] - 0s 76us/step - loss: 0.1408 - binary_accuracy: 0.9722\n",
      "Epoch 106/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1601 - binary_accuracy: 0.9722\n",
      "Epoch 107/180\n",
      "144/144 [==============================] - 0s 76us/step - loss: 0.1441 - binary_accuracy: 0.9583\n",
      "Epoch 108/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1342 - binary_accuracy: 0.9722\n",
      "Epoch 109/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1303 - binary_accuracy: 0.9792\n",
      "Epoch 110/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1239 - binary_accuracy: 0.9861\n",
      "Epoch 111/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1329 - binary_accuracy: 0.9861\n",
      "Epoch 112/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1322 - binary_accuracy: 0.9653\n",
      "Epoch 113/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1392 - binary_accuracy: 0.9722\n",
      "Epoch 114/180\n",
      "144/144 [==============================] - 0s 76us/step - loss: 0.1223 - binary_accuracy: 0.9792\n",
      "Epoch 115/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1241 - binary_accuracy: 0.9583\n",
      "Epoch 116/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1399 - binary_accuracy: 0.9514\n",
      "Epoch 117/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1088 - binary_accuracy: 0.9861\n",
      "Epoch 118/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.0998 - binary_accuracy: 0.9931\n",
      "Epoch 119/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1037 - binary_accuracy: 0.9931\n",
      "Epoch 120/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1003 - binary_accuracy: 0.9861\n",
      "Epoch 121/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.0952 - binary_accuracy: 1.0000\n",
      "Epoch 122/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.0929 - binary_accuracy: 0.9931\n",
      "Epoch 123/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.0958 - binary_accuracy: 0.9792\n",
      "Epoch 124/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.1137 - binary_accuracy: 0.9722\n",
      "Epoch 125/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.0838 - binary_accuracy: 1.0000\n",
      "Epoch 126/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.0916 - binary_accuracy: 1.0000\n",
      "Epoch 127/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.0784 - binary_accuracy: 1.0000\n",
      "Epoch 128/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.0779 - binary_accuracy: 1.0000\n",
      "Epoch 129/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.0827 - binary_accuracy: 0.9861\n",
      "Epoch 130/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.0795 - binary_accuracy: 0.9931\n",
      "Epoch 131/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.0858 - binary_accuracy: 0.9861\n",
      "Epoch 132/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.0665 - binary_accuracy: 1.0000\n",
      "Epoch 133/180\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0725 - binary_accuracy: 1.0000\n",
      "Epoch 134/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0742 - binary_accuracy: 1.0000\n",
      "Epoch 135/180\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0656 - binary_accuracy: 1.0000\n",
      "Epoch 136/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0651 - binary_accuracy: 0.9931\n",
      "Epoch 137/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0753 - binary_accuracy: 0.9861\n",
      "Epoch 138/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.0585 - binary_accuracy: 1.0000\n",
      "Epoch 139/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.0643 - binary_accuracy: 1.0000\n",
      "Epoch 140/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.0601 - binary_accuracy: 0.9931\n",
      "Epoch 141/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.0512 - binary_accuracy: 1.0000\n",
      "Epoch 142/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.0530 - binary_accuracy: 1.0000\n",
      "Epoch 143/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.0689 - binary_accuracy: 1.0000\n",
      "Epoch 144/180\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0631 - binary_accuracy: 1.0000\n",
      "Epoch 145/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.0506 - binary_accuracy: 1.0000\n",
      "Epoch 146/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.0620 - binary_accuracy: 1.0000\n",
      "Epoch 147/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.0431 - binary_accuracy: 1.0000\n",
      "Epoch 148/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.0436 - binary_accuracy: 0.9931\n",
      "Epoch 149/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.0460 - binary_accuracy: 1.0000\n",
      "Epoch 150/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.0488 - binary_accuracy: 1.0000\n",
      "Epoch 151/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.0397 - binary_accuracy: 1.0000\n",
      "Epoch 152/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.0375 - binary_accuracy: 1.0000\n",
      "Epoch 153/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.0424 - binary_accuracy: 1.0000\n",
      "Epoch 154/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.0514 - binary_accuracy: 1.0000\n",
      "Epoch 155/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.0354 - binary_accuracy: 1.0000\n",
      "Epoch 156/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.0349 - binary_accuracy: 1.0000\n",
      "Epoch 157/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.0349 - binary_accuracy: 1.0000\n",
      "Epoch 158/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.0433 - binary_accuracy: 1.0000\n",
      "Epoch 159/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 97us/step - loss: 0.0308 - binary_accuracy: 1.0000\n",
      "Epoch 160/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.0305 - binary_accuracy: 1.0000\n",
      "Epoch 161/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.0609 - binary_accuracy: 0.9931\n",
      "Epoch 162/180\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.0285 - binary_accuracy: 1.0000\n",
      "Epoch 163/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.0272 - binary_accuracy: 1.0000\n",
      "Epoch 164/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.0267 - binary_accuracy: 1.0000\n",
      "Epoch 165/180\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.0256 - binary_accuracy: 1.0000\n",
      "Epoch 166/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.0270 - binary_accuracy: 1.0000\n",
      "Epoch 167/180\n",
      "144/144 [==============================] - 0s 76us/step - loss: 0.0255 - binary_accuracy: 1.0000\n",
      "Epoch 168/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.0246 - binary_accuracy: 1.0000\n",
      "Epoch 169/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.0232 - binary_accuracy: 1.0000\n",
      "Epoch 170/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.0485 - binary_accuracy: 1.0000\n",
      "Epoch 171/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.0247 - binary_accuracy: 1.0000\n",
      "Epoch 172/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.0205 - binary_accuracy: 1.0000\n",
      "Epoch 173/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.0204 - binary_accuracy: 1.0000\n",
      "Epoch 174/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.0199 - binary_accuracy: 1.0000\n",
      "Epoch 175/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.0191 - binary_accuracy: 1.0000\n",
      "Epoch 176/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.0236 - binary_accuracy: 1.0000\n",
      "Epoch 177/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.0222 - binary_accuracy: 1.0000\n",
      "Epoch 178/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.0177 - binary_accuracy: 1.0000\n",
      "Epoch 179/180\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.0189 - binary_accuracy: 1.0000\n",
      "Epoch 180/180\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.0209 - binary_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "n_split = 5\n",
    "\n",
    "for train_index, test_index in KFold(n_split).split(x_train):\n",
    "    #for encoded_train_index, encoded_test_index in KFold(n_split).split(encoded_y_train):\n",
    "        model = neural_model()\n",
    "        history = model.fit(x_train, encoded_y_train, epochs = 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 584us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34487391535828754, 0.9024389982223511]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, encoded_y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After applying K-Fold Cross-Validation method we examind that our accuracy reached to 90% as compaerd to our orignal training which had an accuaracy of 80% due to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "loss = history.history[\"loss\"]\n",
    "binary_accuracy = history.history[\"binary_accuracy\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, \"bo\", label = \"Loss\")\n",
    "plt.plot(epochs, binary_accuracy, \"b\", label = \"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52080244],\n",
       "       [0.9903003 ],\n",
       "       [0.98661983],\n",
       "       [0.06199324],\n",
       "       [0.00973621],\n",
       "       [0.9891951 ],\n",
       "       [0.01070124],\n",
       "       [0.95175767],\n",
       "       [0.94777656],\n",
       "       [0.07802629],\n",
       "       [0.01003894],\n",
       "       [0.02280733],\n",
       "       [0.9907207 ],\n",
       "       [0.9370628 ],\n",
       "       [0.04401565],\n",
       "       [0.99078083],\n",
       "       [0.01061001],\n",
       "       [0.02845404],\n",
       "       [0.01933962],\n",
       "       [0.00934237],\n",
       "       [0.43010992],\n",
       "       [0.60749215],\n",
       "       [0.00944394],\n",
       "       [0.99054176],\n",
       "       [0.01827976],\n",
       "       [0.985589  ],\n",
       "       [0.7950533 ],\n",
       "       [0.98898065],\n",
       "       [0.9819552 ],\n",
       "       [0.9905762 ],\n",
       "       [0.99043715],\n",
       "       [0.00884348],\n",
       "       [0.0086647 ],\n",
       "       [0.6493237 ],\n",
       "       [0.9900595 ],\n",
       "       [0.04539692],\n",
       "       [0.02837345],\n",
       "       [0.00993362],\n",
       "       [0.93253505],\n",
       "       [0.9895382 ],\n",
       "       [0.11046395]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
