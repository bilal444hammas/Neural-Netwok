{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import layers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score,StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
       "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
       "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
       "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
       "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
       "\n",
       "         9   ...      51      52      53      54      55      56      57  \\\n",
       "0    0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1    0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2    0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3    0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4    0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.2684  ...  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065  0.0115   \n",
       "204  0.2154  ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n",
       "205  0.2529  ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n",
       "206  0.2354  ...  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034  0.0079   \n",
       "207  0.2354  ...  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040  0.0036   \n",
       "\n",
       "         58      59  60  \n",
       "0    0.0090  0.0032   R  \n",
       "1    0.0052  0.0044   R  \n",
       "2    0.0095  0.0078   R  \n",
       "3    0.0040  0.0117   R  \n",
       "4    0.0107  0.0094   R  \n",
       "..      ...     ...  ..  \n",
       "203  0.0193  0.0157   M  \n",
       "204  0.0062  0.0067   M  \n",
       "205  0.0077  0.0031   M  \n",
       "206  0.0036  0.0048   M  \n",
       "207  0.0061  0.0115   M  \n",
       "\n",
       "[208 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"sonar.csv\", header = None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.0707</td>\n",
       "      <td>0.1313</td>\n",
       "      <td>0.2103</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.2524</td>\n",
       "      <td>0.3595</td>\n",
       "      <td>0.5915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0456</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>0.1075</td>\n",
       "      <td>0.1019</td>\n",
       "      <td>0.1606</td>\n",
       "      <td>0.2119</td>\n",
       "      <td>0.3061</td>\n",
       "      <td>0.2936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.0698</td>\n",
       "      <td>0.1615</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.2918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0253</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.0645</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>0.1388</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.0696</td>\n",
       "      <td>0.0873</td>\n",
       "      <td>0.0616</td>\n",
       "      <td>0.1252</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.1368</td>\n",
       "      <td>0.1078</td>\n",
       "      <td>0.1552</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.0571</td>\n",
       "      <td>0.1004</td>\n",
       "      <td>0.0668</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.0621</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>0.1129</td>\n",
       "      <td>0.0973</td>\n",
       "      <td>0.1823</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.1808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "184  0.0269  0.0383  0.0505  0.0707  0.1313  0.2103  0.2263  0.2524  0.3595   \n",
       "5    0.0286  0.0453  0.0277  0.0174  0.0384  0.0990  0.1201  0.1833  0.2105   \n",
       "170  0.0134  0.0172  0.0178  0.0363  0.0444  0.0744  0.0800  0.0456  0.0368   \n",
       "158  0.0107  0.0453  0.0289  0.0713  0.1075  0.1019  0.1606  0.2119  0.3061   \n",
       "172  0.0180  0.0444  0.0476  0.0698  0.1615  0.0887  0.0596  0.1071  0.3175   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "103  0.0162  0.0253  0.0262  0.0386  0.0645  0.0472  0.1056  0.1388  0.0598   \n",
       "59   0.0125  0.0152  0.0218  0.0175  0.0362  0.0696  0.0873  0.0616  0.1252   \n",
       "121  0.0162  0.0041  0.0239  0.0441  0.0630  0.0921  0.1368  0.1078  0.1552   \n",
       "32   0.0195  0.0213  0.0058  0.0190  0.0319  0.0571  0.1004  0.0668  0.0691   \n",
       "88   0.0274  0.0242  0.0621  0.0560  0.1129  0.0973  0.1823  0.1745  0.1440   \n",
       "\n",
       "         9   ...      51      52      53      54      55      56      57  \\\n",
       "184  0.5915  ...  0.0167  0.0199  0.0145  0.0081  0.0045  0.0043  0.0027   \n",
       "5    0.3039  ...  0.0045  0.0014  0.0038  0.0013  0.0089  0.0057  0.0027   \n",
       "170  0.1250  ...  0.0094  0.0048  0.0047  0.0016  0.0008  0.0042  0.0024   \n",
       "158  0.2936  ...  0.0164  0.0120  0.0113  0.0021  0.0097  0.0072  0.0060   \n",
       "172  0.2918  ...  0.0122  0.0114  0.0098  0.0027  0.0025  0.0026  0.0050   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "103  0.1334  ...  0.0071  0.0082  0.0232  0.0198  0.0074  0.0035  0.0100   \n",
       "59   0.1302  ...  0.0041  0.0074  0.0030  0.0050  0.0048  0.0017  0.0041   \n",
       "121  0.1779  ...  0.0173  0.0135  0.0114  0.0062  0.0157  0.0088  0.0036   \n",
       "32   0.0242  ...  0.0157  0.0074  0.0271  0.0203  0.0089  0.0095  0.0095   \n",
       "88   0.1808  ...  0.0113  0.0108  0.0085  0.0047  0.0074  0.0104  0.0161   \n",
       "\n",
       "         58      59  60  \n",
       "184  0.0055  0.0057   M  \n",
       "5    0.0051  0.0062   R  \n",
       "170  0.0027  0.0041   M  \n",
       "158  0.0017  0.0036   M  \n",
       "172  0.0073  0.0022   M  \n",
       "..      ...     ...  ..  \n",
       "103  0.0048  0.0019   M  \n",
       "59   0.0086  0.0058   R  \n",
       "121  0.0053  0.0030   M  \n",
       "32   0.0021  0.0053   R  \n",
       "88   0.0220  0.0173   R  \n",
       "\n",
       "[208 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_data = data.sample(frac = 1)\n",
    "shuffled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0269, 0.0383, 0.0505, ..., 0.0055, 0.0057, 'M'],\n",
       "       [0.0286, 0.0453, 0.0277, ..., 0.0051, 0.0062, 'R'],\n",
       "       [0.0134, 0.0172, 0.0178, ..., 0.0027, 0.0041, 'M'],\n",
       "       ...,\n",
       "       [0.0162, 0.0041, 0.0239, ..., 0.0053, 0.003, 'M'],\n",
       "       [0.0195, 0.0213, 0.0058, ..., 0.0021, 0.0053, 'R'],\n",
       "       [0.0274, 0.0242, 0.0621, ..., 0.022, 0.0173, 'R']], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = shuffled_data.values\n",
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data_set[:144,:60].astype(\"float32\")\n",
    "y_train = data_set[:144,60]\n",
    "\n",
    "x_test = data_set[144:185,:60].astype(\"float32\")\n",
    "y_test = data_set[144:185,60]\n",
    "\n",
    "x_val = data_set[185:,:60].astype(\"float32\")\n",
    "y_val = data_set[185:,60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "encoded_y_train = le.fit_transform(y_train)\n",
    "encoded_y_test = le.fit_transform(y_test)\n",
    "encoded_y_val = le.fit_transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(60, activation = \"relu\"))\n",
    "    model.add(layers.Dense(30, activation = \"relu\"))\n",
    "    model.add(layers.Dense(10, activation = \"relu\"))\n",
    "    model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "    model.compile(optimizer = optimizers.RMSprop(lr = 0.001),\n",
    "                  loss =losses.binary_crossentropy,\n",
    "                  metrics = [metrics.binary_accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = neural_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "144/144 [==============================] - 0s 748us/step - loss: 0.6902 - binary_accuracy: 0.5139\n",
      "Epoch 2/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6717 - binary_accuracy: 0.6042\n",
      "Epoch 3/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.6575 - binary_accuracy: 0.6944\n",
      "Epoch 4/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.6481 - binary_accuracy: 0.7014\n",
      "Epoch 5/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6354 - binary_accuracy: 0.6875\n",
      "Epoch 6/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6278 - binary_accuracy: 0.7014\n",
      "Epoch 7/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.6118 - binary_accuracy: 0.7500\n",
      "Epoch 8/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.5946 - binary_accuracy: 0.7639\n",
      "Epoch 9/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.5794 - binary_accuracy: 0.7569\n",
      "Epoch 10/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5695 - binary_accuracy: 0.7639\n",
      "Epoch 11/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.5456 - binary_accuracy: 0.8194\n",
      "Epoch 12/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.5287 - binary_accuracy: 0.7917\n",
      "Epoch 13/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5210 - binary_accuracy: 0.7778\n",
      "Epoch 14/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.5034 - binary_accuracy: 0.7778\n",
      "Epoch 15/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.4928 - binary_accuracy: 0.8056\n",
      "Epoch 16/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4669 - binary_accuracy: 0.8472\n",
      "Epoch 17/200\n",
      "144/144 [==============================] - 0s 180us/step - loss: 0.4574 - binary_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4521 - binary_accuracy: 0.8264\n",
      "Epoch 19/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4530 - binary_accuracy: 0.8056\n",
      "Epoch 20/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4425 - binary_accuracy: 0.8264\n",
      "Epoch 21/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.4122 - binary_accuracy: 0.8403\n",
      "Epoch 22/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.4208 - binary_accuracy: 0.8681\n",
      "Epoch 23/200\n",
      "144/144 [==============================] - 0s 166us/step - loss: 0.3957 - binary_accuracy: 0.8403\n",
      "Epoch 24/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.4090 - binary_accuracy: 0.8403\n",
      "Epoch 25/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.3885 - binary_accuracy: 0.8472\n",
      "Epoch 26/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.3758 - binary_accuracy: 0.8542\n",
      "Epoch 27/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.3763 - binary_accuracy: 0.8403\n",
      "Epoch 28/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.3656 - binary_accuracy: 0.8819\n",
      "Epoch 29/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.3616 - binary_accuracy: 0.8750\n",
      "Epoch 30/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.3498 - binary_accuracy: 0.8819\n",
      "Epoch 31/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.3439 - binary_accuracy: 0.8681\n",
      "Epoch 32/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.3324 - binary_accuracy: 0.8819\n",
      "Epoch 33/200\n",
      "144/144 [==============================] - 0s 194us/step - loss: 0.3293 - binary_accuracy: 0.8889\n",
      "Epoch 34/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3454 - binary_accuracy: 0.8542\n",
      "Epoch 35/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.3167 - binary_accuracy: 0.8819\n",
      "Epoch 36/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.3224 - binary_accuracy: 0.9028\n",
      "Epoch 37/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3227 - binary_accuracy: 0.8958\n",
      "Epoch 38/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3187 - binary_accuracy: 0.8750\n",
      "Epoch 39/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2892 - binary_accuracy: 0.8889\n",
      "Epoch 40/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2899 - binary_accuracy: 0.9097\n",
      "Epoch 41/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2902 - binary_accuracy: 0.9306\n",
      "Epoch 42/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2912 - binary_accuracy: 0.9028\n",
      "Epoch 43/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2702 - binary_accuracy: 0.9097\n",
      "Epoch 44/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.2739 - binary_accuracy: 0.8819\n",
      "Epoch 45/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2585 - binary_accuracy: 0.9167\n",
      "Epoch 46/200\n",
      "144/144 [==============================] - 0s 173us/step - loss: 0.2603 - binary_accuracy: 0.9097\n",
      "Epoch 47/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.2529 - binary_accuracy: 0.9167\n",
      "Epoch 48/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2507 - binary_accuracy: 0.8889\n",
      "Epoch 49/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2456 - binary_accuracy: 0.9028\n",
      "Epoch 50/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2538 - binary_accuracy: 0.8889\n",
      "Epoch 51/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2615 - binary_accuracy: 0.8681\n",
      "Epoch 52/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2673 - binary_accuracy: 0.9028\n",
      "Epoch 53/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2424 - binary_accuracy: 0.9097\n",
      "Epoch 54/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2567 - binary_accuracy: 0.9097\n",
      "Epoch 55/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2238 - binary_accuracy: 0.9306\n",
      "Epoch 56/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2204 - binary_accuracy: 0.9236\n",
      "Epoch 57/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2316 - binary_accuracy: 0.9167\n",
      "Epoch 58/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2130 - binary_accuracy: 0.9236\n",
      "Epoch 59/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2056 - binary_accuracy: 0.9375\n",
      "Epoch 60/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2197 - binary_accuracy: 0.9028\n",
      "Epoch 61/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2241 - binary_accuracy: 0.9167\n",
      "Epoch 62/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1941 - binary_accuracy: 0.9375\n",
      "Epoch 63/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1941 - binary_accuracy: 0.9236\n",
      "Epoch 64/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2458 - binary_accuracy: 0.9028\n",
      "Epoch 65/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1835 - binary_accuracy: 0.9444\n",
      "Epoch 66/200\n",
      "144/144 [==============================] - 0s 146us/step - loss: 0.1915 - binary_accuracy: 0.9167\n",
      "Epoch 67/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1804 - binary_accuracy: 0.9375\n",
      "Epoch 68/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1729 - binary_accuracy: 0.9444\n",
      "Epoch 69/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1934 - binary_accuracy: 0.9236\n",
      "Epoch 70/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1706 - binary_accuracy: 0.9306\n",
      "Epoch 71/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1710 - binary_accuracy: 0.9514\n",
      "Epoch 72/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1577 - binary_accuracy: 0.9514\n",
      "Epoch 73/200\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1766 - binary_accuracy: 0.9375\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 111us/step - loss: 0.1893 - binary_accuracy: 0.9236\n",
      "Epoch 75/200\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1501 - binary_accuracy: 0.9583\n",
      "Epoch 76/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1398 - binary_accuracy: 0.9653\n",
      "Epoch 77/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1625 - binary_accuracy: 0.9375\n",
      "Epoch 78/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.1588 - binary_accuracy: 0.9514\n",
      "Epoch 79/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.1325 - binary_accuracy: 0.9583\n",
      "Epoch 80/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1384 - binary_accuracy: 0.9583\n",
      "Epoch 81/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1618 - binary_accuracy: 0.9306\n",
      "Epoch 82/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1368 - binary_accuracy: 0.9514\n",
      "Epoch 83/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1434 - binary_accuracy: 0.9583\n",
      "Epoch 84/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1154 - binary_accuracy: 0.9653\n",
      "Epoch 85/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1315 - binary_accuracy: 0.9514\n",
      "Epoch 86/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1121 - binary_accuracy: 0.9861\n",
      "Epoch 87/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1395 - binary_accuracy: 0.9375\n",
      "Epoch 88/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1306 - binary_accuracy: 0.9514\n",
      "Epoch 89/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1314 - binary_accuracy: 0.9514\n",
      "Epoch 90/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1091 - binary_accuracy: 0.9583\n",
      "Epoch 91/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1243 - binary_accuracy: 0.9653\n",
      "Epoch 92/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1096 - binary_accuracy: 0.9583\n",
      "Epoch 93/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.1157 - binary_accuracy: 0.9653\n",
      "Epoch 94/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1183 - binary_accuracy: 0.9653\n",
      "Epoch 95/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0958 - binary_accuracy: 0.9861\n",
      "Epoch 96/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1214 - binary_accuracy: 0.9514\n",
      "Epoch 97/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1015 - binary_accuracy: 0.9792\n",
      "Epoch 98/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0990 - binary_accuracy: 0.9722\n",
      "Epoch 99/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1047 - binary_accuracy: 0.9722\n",
      "Epoch 100/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1038 - binary_accuracy: 0.9722\n",
      "Epoch 101/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.0810 - binary_accuracy: 0.9861\n",
      "Epoch 102/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0932 - binary_accuracy: 0.9722\n",
      "Epoch 103/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1137 - binary_accuracy: 0.9514\n",
      "Epoch 104/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.0750 - binary_accuracy: 0.9861\n",
      "Epoch 105/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0761 - binary_accuracy: 0.9931\n",
      "Epoch 106/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1137 - binary_accuracy: 0.9514\n",
      "Epoch 107/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0720 - binary_accuracy: 0.9861\n",
      "Epoch 108/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0692 - binary_accuracy: 0.9861\n",
      "Epoch 109/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0670 - binary_accuracy: 0.9792\n",
      "Epoch 110/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0784 - binary_accuracy: 0.9792\n",
      "Epoch 111/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0776 - binary_accuracy: 0.9722\n",
      "Epoch 112/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0698 - binary_accuracy: 0.9861\n",
      "Epoch 113/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0689 - binary_accuracy: 0.9861\n",
      "Epoch 114/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0648 - binary_accuracy: 0.9722\n",
      "Epoch 115/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1037 - binary_accuracy: 0.9583\n",
      "Epoch 116/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0566 - binary_accuracy: 0.9931\n",
      "Epoch 117/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0574 - binary_accuracy: 0.9931\n",
      "Epoch 118/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0594 - binary_accuracy: 0.9792\n",
      "Epoch 119/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0760 - binary_accuracy: 0.9861\n",
      "Epoch 120/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0820 - binary_accuracy: 0.9861\n",
      "Epoch 121/200\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.0794 - binary_accuracy: 0.9792\n",
      "Epoch 122/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0449 - binary_accuracy: 0.9931\n",
      "Epoch 123/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0431 - binary_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0642 - binary_accuracy: 0.9861\n",
      "Epoch 125/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0774 - binary_accuracy: 0.9861\n",
      "Epoch 126/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0456 - binary_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0405 - binary_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0432 - binary_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0643 - binary_accuracy: 0.9861\n",
      "Epoch 130/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0583 - binary_accuracy: 0.9931\n",
      "Epoch 131/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0404 - binary_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0403 - binary_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.0416 - binary_accuracy: 0.9931\n",
      "Epoch 134/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0385 - binary_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0480 - binary_accuracy: 0.9861\n",
      "Epoch 136/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0321 - binary_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0648 - binary_accuracy: 0.9792\n",
      "Epoch 138/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0271 - binary_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.0335 - binary_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0926 - binary_accuracy: 0.9514\n",
      "Epoch 141/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.0291 - binary_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0242 - binary_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0233 - binary_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.0324 - binary_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.0294 - binary_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0275 - binary_accuracy: 1.0000\n",
      "Epoch 147/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 90us/step - loss: 0.0305 - binary_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0257 - binary_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.0233 - binary_accuracy: 0.9931\n",
      "Epoch 150/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0297 - binary_accuracy: 0.9931\n",
      "Epoch 151/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0325 - binary_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0254 - binary_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0173 - binary_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.0145 - binary_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "144/144 [==============================] - ETA: 0s - loss: 0.0117 - binary_accuracy: 1.000 - 0s 125us/step - loss: 0.0168 - binary_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0435 - binary_accuracy: 0.9861\n",
      "Epoch 157/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.0428 - binary_accuracy: 0.9861\n",
      "Epoch 158/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0135 - binary_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.0140 - binary_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0124 - binary_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0238 - binary_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0131 - binary_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0164 - binary_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0362 - binary_accuracy: 0.9861\n",
      "Epoch 165/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0238 - binary_accuracy: 0.9931\n",
      "Epoch 166/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0138 - binary_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0102 - binary_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0149 - binary_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0139 - binary_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0128 - binary_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0594 - binary_accuracy: 0.9653\n",
      "Epoch 172/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0084 - binary_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0078 - binary_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0070 - binary_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0119 - binary_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0079 - binary_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0075 - binary_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0603 - binary_accuracy: 0.9653\n",
      "Epoch 179/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.0066 - binary_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0063 - binary_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.0060 - binary_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0064 - binary_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0057 - binary_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.0051 - binary_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0635 - binary_accuracy: 0.9722\n",
      "Epoch 186/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0100 - binary_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.0052 - binary_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0049 - binary_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0049 - binary_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0051 - binary_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0045 - binary_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0045 - binary_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0038 - binary_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0472 - binary_accuracy: 0.9792\n",
      "Epoch 195/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0050 - binary_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0038 - binary_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.0038 - binary_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0036 - binary_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0042 - binary_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0090 - binary_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2a29e4f1608>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, encoded_y_train, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(x_test, encoded_y_test, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9707244852694069, 0.8292682766914368]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 144 samples, validate on 23 samples\n",
      "Epoch 1/200\n",
      "144/144 [==============================] - 0s 880us/step - loss: 0.6756 - binary_accuracy: 0.5694 - val_loss: 0.6069 - val_binary_accuracy: 0.6957\n",
      "Epoch 2/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.6478 - binary_accuracy: 0.6319 - val_loss: 0.6337 - val_binary_accuracy: 0.6957\n",
      "Epoch 3/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.6201 - binary_accuracy: 0.6806 - val_loss: 0.5829 - val_binary_accuracy: 0.7391\n",
      "Epoch 4/200\n",
      "144/144 [==============================] - 0s 180us/step - loss: 0.5964 - binary_accuracy: 0.6806 - val_loss: 0.6237 - val_binary_accuracy: 0.6957\n",
      "Epoch 5/200\n",
      "144/144 [==============================] - 0s 173us/step - loss: 0.5897 - binary_accuracy: 0.7431 - val_loss: 0.5777 - val_binary_accuracy: 0.8261\n",
      "Epoch 6/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.5646 - binary_accuracy: 0.7431 - val_loss: 0.5695 - val_binary_accuracy: 0.7826\n",
      "Epoch 7/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.5466 - binary_accuracy: 0.7639 - val_loss: 0.5611 - val_binary_accuracy: 0.7826\n",
      "Epoch 8/200\n",
      "144/144 [==============================] - 0s 180us/step - loss: 0.5366 - binary_accuracy: 0.7569 - val_loss: 0.5221 - val_binary_accuracy: 0.8261\n",
      "Epoch 9/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.5146 - binary_accuracy: 0.7847 - val_loss: 0.6227 - val_binary_accuracy: 0.6087\n",
      "Epoch 10/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.5083 - binary_accuracy: 0.7639 - val_loss: 0.5745 - val_binary_accuracy: 0.7391\n",
      "Epoch 11/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4979 - binary_accuracy: 0.8333 - val_loss: 0.4947 - val_binary_accuracy: 0.7826\n",
      "Epoch 12/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.4831 - binary_accuracy: 0.7986 - val_loss: 0.5828 - val_binary_accuracy: 0.7391\n",
      "Epoch 13/200\n",
      "144/144 [==============================] - 0s 173us/step - loss: 0.4768 - binary_accuracy: 0.8056 - val_loss: 0.4787 - val_binary_accuracy: 0.8261\n",
      "Epoch 14/200\n",
      "144/144 [==============================] - 0s 153us/step - loss: 0.4653 - binary_accuracy: 0.7500 - val_loss: 0.4546 - val_binary_accuracy: 0.7826\n",
      "Epoch 15/200\n",
      "144/144 [==============================] - 0s 180us/step - loss: 0.4572 - binary_accuracy: 0.7847 - val_loss: 0.4442 - val_binary_accuracy: 0.8261\n",
      "Epoch 16/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.4529 - binary_accuracy: 0.8056 - val_loss: 0.4580 - val_binary_accuracy: 0.8696\n",
      "Epoch 17/200\n",
      "144/144 [==============================] - 0s 180us/step - loss: 0.4380 - binary_accuracy: 0.8194 - val_loss: 0.4763 - val_binary_accuracy: 0.7826\n",
      "Epoch 18/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.4332 - binary_accuracy: 0.8333 - val_loss: 0.5460 - val_binary_accuracy: 0.7391\n",
      "Epoch 19/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.4192 - binary_accuracy: 0.8542 - val_loss: 0.4256 - val_binary_accuracy: 0.8261\n",
      "Epoch 20/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.4203 - binary_accuracy: 0.8194 - val_loss: 0.4327 - val_binary_accuracy: 0.8696\n",
      "Epoch 21/200\n",
      "144/144 [==============================] - 0s 166us/step - loss: 0.4105 - binary_accuracy: 0.8125 - val_loss: 0.4246 - val_binary_accuracy: 0.8696\n",
      "Epoch 22/200\n",
      "144/144 [==============================] - 0s 166us/step - loss: 0.3997 - binary_accuracy: 0.8333 - val_loss: 0.4087 - val_binary_accuracy: 0.8696\n",
      "Epoch 23/200\n",
      "144/144 [==============================] - 0s 187us/step - loss: 0.4040 - binary_accuracy: 0.7986 - val_loss: 0.5945 - val_binary_accuracy: 0.7391\n",
      "Epoch 24/200\n",
      "144/144 [==============================] - 0s 187us/step - loss: 0.3990 - binary_accuracy: 0.8333 - val_loss: 0.4423 - val_binary_accuracy: 0.7826\n",
      "Epoch 25/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.3813 - binary_accuracy: 0.8611 - val_loss: 0.4396 - val_binary_accuracy: 0.7826\n",
      "Epoch 26/200\n",
      "144/144 [==============================] - 0s 180us/step - loss: 0.3718 - binary_accuracy: 0.8611 - val_loss: 0.4711 - val_binary_accuracy: 0.7826\n",
      "Epoch 27/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.3961 - binary_accuracy: 0.8125 - val_loss: 0.4248 - val_binary_accuracy: 0.7826\n",
      "Epoch 28/200\n",
      "144/144 [==============================] - 0s 153us/step - loss: 0.3577 - binary_accuracy: 0.8889 - val_loss: 0.3865 - val_binary_accuracy: 0.8261\n",
      "Epoch 29/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.3614 - binary_accuracy: 0.8542 - val_loss: 0.4090 - val_binary_accuracy: 0.7826\n",
      "Epoch 30/200\n",
      "144/144 [==============================] - 0s 173us/step - loss: 0.3542 - binary_accuracy: 0.8750 - val_loss: 0.3960 - val_binary_accuracy: 0.8261\n",
      "Epoch 31/200\n",
      "144/144 [==============================] - 0s 180us/step - loss: 0.3469 - binary_accuracy: 0.8333 - val_loss: 0.3703 - val_binary_accuracy: 0.8261\n",
      "Epoch 32/200\n",
      "144/144 [==============================] - 0s 242us/step - loss: 0.3490 - binary_accuracy: 0.8611 - val_loss: 0.3604 - val_binary_accuracy: 0.8696\n",
      "Epoch 33/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.3338 - binary_accuracy: 0.8611 - val_loss: 0.3611 - val_binary_accuracy: 0.8261\n",
      "Epoch 34/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.3233 - binary_accuracy: 0.8750 - val_loss: 0.5374 - val_binary_accuracy: 0.7826\n",
      "Epoch 35/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.3559 - binary_accuracy: 0.8194 - val_loss: 0.3616 - val_binary_accuracy: 0.7826\n",
      "Epoch 36/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.3288 - binary_accuracy: 0.8681 - val_loss: 0.4134 - val_binary_accuracy: 0.7826\n",
      "Epoch 37/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3142 - binary_accuracy: 0.8681 - val_loss: 0.4181 - val_binary_accuracy: 0.7826\n",
      "Epoch 38/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3144 - binary_accuracy: 0.8611 - val_loss: 0.3808 - val_binary_accuracy: 0.7391\n",
      "Epoch 39/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3087 - binary_accuracy: 0.8819 - val_loss: 0.3400 - val_binary_accuracy: 0.8696\n",
      "Epoch 40/200\n",
      "144/144 [==============================] - 0s 138us/step - loss: 0.3063 - binary_accuracy: 0.8750 - val_loss: 0.4175 - val_binary_accuracy: 0.7826\n",
      "Epoch 41/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.3048 - binary_accuracy: 0.9028 - val_loss: 0.5024 - val_binary_accuracy: 0.8261\n",
      "Epoch 42/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.3098 - binary_accuracy: 0.8889 - val_loss: 0.3956 - val_binary_accuracy: 0.7826\n",
      "Epoch 43/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.2886 - binary_accuracy: 0.9028 - val_loss: 0.3408 - val_binary_accuracy: 0.8261\n",
      "Epoch 44/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.2710 - binary_accuracy: 0.9306 - val_loss: 0.3341 - val_binary_accuracy: 0.8696\n",
      "Epoch 45/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3250 - binary_accuracy: 0.8681 - val_loss: 0.3281 - val_binary_accuracy: 0.8696\n",
      "Epoch 46/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2913 - binary_accuracy: 0.8750 - val_loss: 0.4562 - val_binary_accuracy: 0.7826\n",
      "Epoch 47/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2686 - binary_accuracy: 0.9167 - val_loss: 0.3850 - val_binary_accuracy: 0.7391\n",
      "Epoch 48/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2584 - binary_accuracy: 0.9236 - val_loss: 0.3666 - val_binary_accuracy: 0.7391\n",
      "Epoch 49/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.2608 - binary_accuracy: 0.9236 - val_loss: 0.4210 - val_binary_accuracy: 0.7826\n",
      "Epoch 50/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2740 - binary_accuracy: 0.8889 - val_loss: 0.4404 - val_binary_accuracy: 0.7826\n",
      "Epoch 51/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.2471 - binary_accuracy: 0.9306 - val_loss: 0.3879 - val_binary_accuracy: 0.7391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.2617 - binary_accuracy: 0.8750 - val_loss: 0.3213 - val_binary_accuracy: 0.8696\n",
      "Epoch 53/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2572 - binary_accuracy: 0.9097 - val_loss: 0.3977 - val_binary_accuracy: 0.7391\n",
      "Epoch 54/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2314 - binary_accuracy: 0.9236 - val_loss: 0.4978 - val_binary_accuracy: 0.8261\n",
      "Epoch 55/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.2643 - binary_accuracy: 0.9097 - val_loss: 0.3278 - val_binary_accuracy: 0.8261\n",
      "Epoch 56/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.2292 - binary_accuracy: 0.9167 - val_loss: 0.3139 - val_binary_accuracy: 0.8696\n",
      "Epoch 57/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2314 - binary_accuracy: 0.9167 - val_loss: 0.3525 - val_binary_accuracy: 0.7826\n",
      "Epoch 58/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2170 - binary_accuracy: 0.9167 - val_loss: 0.3073 - val_binary_accuracy: 0.8696\n",
      "Epoch 59/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.2166 - binary_accuracy: 0.9167 - val_loss: 0.4682 - val_binary_accuracy: 0.7826\n",
      "Epoch 60/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.2350 - binary_accuracy: 0.9236 - val_loss: 0.3534 - val_binary_accuracy: 0.8261\n",
      "Epoch 61/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2096 - binary_accuracy: 0.9236 - val_loss: 0.3296 - val_binary_accuracy: 0.8261\n",
      "Epoch 62/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1970 - binary_accuracy: 0.9375 - val_loss: 0.3223 - val_binary_accuracy: 0.8261\n",
      "Epoch 63/200\n",
      "144/144 [==============================] - 0s 173us/step - loss: 0.1997 - binary_accuracy: 0.9306 - val_loss: 0.3501 - val_binary_accuracy: 0.7391\n",
      "Epoch 64/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1905 - binary_accuracy: 0.9514 - val_loss: 0.3128 - val_binary_accuracy: 0.8696\n",
      "Epoch 65/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2111 - binary_accuracy: 0.9236 - val_loss: 0.3998 - val_binary_accuracy: 0.7391\n",
      "Epoch 66/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.1762 - binary_accuracy: 0.9306 - val_loss: 0.3140 - val_binary_accuracy: 0.8261\n",
      "Epoch 67/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1862 - binary_accuracy: 0.9375 - val_loss: 0.4363 - val_binary_accuracy: 0.7391\n",
      "Epoch 68/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.2315 - binary_accuracy: 0.9097 - val_loss: 0.3218 - val_binary_accuracy: 0.8696\n",
      "Epoch 69/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1949 - binary_accuracy: 0.9375 - val_loss: 0.3785 - val_binary_accuracy: 0.7826\n",
      "Epoch 70/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1686 - binary_accuracy: 0.9583 - val_loss: 0.3323 - val_binary_accuracy: 0.8261\n",
      "Epoch 71/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1582 - binary_accuracy: 0.9514 - val_loss: 0.3130 - val_binary_accuracy: 0.8696\n",
      "Epoch 72/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1634 - binary_accuracy: 0.9375 - val_loss: 0.4812 - val_binary_accuracy: 0.6957\n",
      "Epoch 73/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.1887 - binary_accuracy: 0.9306 - val_loss: 0.3017 - val_binary_accuracy: 0.8696\n",
      "Epoch 74/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.1688 - binary_accuracy: 0.9514 - val_loss: 0.3089 - val_binary_accuracy: 0.8696\n",
      "Epoch 75/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1694 - binary_accuracy: 0.9444 - val_loss: 0.3042 - val_binary_accuracy: 0.8696\n",
      "Epoch 76/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.1517 - binary_accuracy: 0.9514 - val_loss: 0.2982 - val_binary_accuracy: 0.8696\n",
      "Epoch 77/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1427 - binary_accuracy: 0.9653 - val_loss: 0.3779 - val_binary_accuracy: 0.7826\n",
      "Epoch 78/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1406 - binary_accuracy: 0.9722 - val_loss: 0.3193 - val_binary_accuracy: 0.8696\n",
      "Epoch 79/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1790 - binary_accuracy: 0.9375 - val_loss: 0.2931 - val_binary_accuracy: 0.8696\n",
      "Epoch 80/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.1408 - binary_accuracy: 0.9653 - val_loss: 0.3113 - val_binary_accuracy: 0.8696\n",
      "Epoch 81/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1264 - binary_accuracy: 0.9722 - val_loss: 0.3578 - val_binary_accuracy: 0.8261\n",
      "Epoch 82/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1436 - binary_accuracy: 0.9722 - val_loss: 0.3254 - val_binary_accuracy: 0.8261\n",
      "Epoch 83/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1366 - binary_accuracy: 0.9583 - val_loss: 0.3118 - val_binary_accuracy: 0.8261\n",
      "Epoch 84/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.1130 - binary_accuracy: 0.9792 - val_loss: 0.2947 - val_binary_accuracy: 0.8696\n",
      "Epoch 85/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1809 - binary_accuracy: 0.9306 - val_loss: 0.3959 - val_binary_accuracy: 0.7826\n",
      "Epoch 86/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.1190 - binary_accuracy: 0.9722 - val_loss: 0.2891 - val_binary_accuracy: 0.8696\n",
      "Epoch 87/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1211 - binary_accuracy: 0.9444 - val_loss: 0.4435 - val_binary_accuracy: 0.6957\n",
      "Epoch 88/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.1180 - binary_accuracy: 0.9722 - val_loss: 0.2925 - val_binary_accuracy: 0.8696\n",
      "Epoch 89/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.1072 - binary_accuracy: 0.9792 - val_loss: 0.3092 - val_binary_accuracy: 0.8261\n",
      "Epoch 90/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.1025 - binary_accuracy: 0.9861 - val_loss: 0.3334 - val_binary_accuracy: 0.8261\n",
      "Epoch 91/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1096 - binary_accuracy: 0.9792 - val_loss: 0.2940 - val_binary_accuracy: 0.8696\n",
      "Epoch 92/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.1068 - binary_accuracy: 0.9722 - val_loss: 0.2944 - val_binary_accuracy: 0.8696\n",
      "Epoch 93/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1004 - binary_accuracy: 0.9653 - val_loss: 0.4127 - val_binary_accuracy: 0.7391\n",
      "Epoch 94/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.1763 - binary_accuracy: 0.9375 - val_loss: 0.3075 - val_binary_accuracy: 0.8261\n",
      "Epoch 95/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.0881 - binary_accuracy: 0.9861 - val_loss: 0.3310 - val_binary_accuracy: 0.8696\n",
      "Epoch 96/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.0945 - binary_accuracy: 0.9861 - val_loss: 0.3242 - val_binary_accuracy: 0.8696\n",
      "Epoch 97/200\n",
      "144/144 [==============================] - 0s 187us/step - loss: 0.1006 - binary_accuracy: 0.9792 - val_loss: 0.3165 - val_binary_accuracy: 0.8261\n",
      "Epoch 98/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.0963 - binary_accuracy: 0.9861 - val_loss: 0.3596 - val_binary_accuracy: 0.9130\n",
      "Epoch 99/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.1063 - binary_accuracy: 0.9583 - val_loss: 0.3275 - val_binary_accuracy: 0.8261\n",
      "Epoch 100/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.0814 - binary_accuracy: 0.9792 - val_loss: 0.3446 - val_binary_accuracy: 0.8261\n",
      "Epoch 101/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0954 - binary_accuracy: 0.9861 - val_loss: 0.2927 - val_binary_accuracy: 0.8696\n",
      "Epoch 102/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0822 - binary_accuracy: 0.9861 - val_loss: 0.3108 - val_binary_accuracy: 0.8261\n",
      "Epoch 103/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 104us/step - loss: 0.0789 - binary_accuracy: 0.9792 - val_loss: 0.3482 - val_binary_accuracy: 0.9130\n",
      "Epoch 104/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.0810 - binary_accuracy: 1.0000 - val_loss: 0.3134 - val_binary_accuracy: 0.8696\n",
      "Epoch 105/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.0664 - binary_accuracy: 0.9861 - val_loss: 0.3627 - val_binary_accuracy: 0.8261\n",
      "Epoch 106/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0707 - binary_accuracy: 0.9931 - val_loss: 0.3003 - val_binary_accuracy: 0.8696\n",
      "Epoch 107/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.0631 - binary_accuracy: 0.9861 - val_loss: 0.3608 - val_binary_accuracy: 0.8696\n",
      "Epoch 108/200\n",
      "144/144 [==============================] - 0s 187us/step - loss: 0.0999 - binary_accuracy: 0.9653 - val_loss: 0.3449 - val_binary_accuracy: 0.8261\n",
      "Epoch 109/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.0635 - binary_accuracy: 1.0000 - val_loss: 0.3008 - val_binary_accuracy: 0.8696\n",
      "Epoch 110/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.0560 - binary_accuracy: 0.9931 - val_loss: 0.3376 - val_binary_accuracy: 0.9130\n",
      "Epoch 111/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0857 - binary_accuracy: 0.9861 - val_loss: 0.3185 - val_binary_accuracy: 0.8696\n",
      "Epoch 112/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0678 - binary_accuracy: 0.9861 - val_loss: 0.4100 - val_binary_accuracy: 0.9130\n",
      "Epoch 113/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.0752 - binary_accuracy: 0.9792 - val_loss: 0.3473 - val_binary_accuracy: 0.8261\n",
      "Epoch 114/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0487 - binary_accuracy: 1.0000 - val_loss: 0.3384 - val_binary_accuracy: 0.8261\n",
      "Epoch 115/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0473 - binary_accuracy: 0.9931 - val_loss: 0.3134 - val_binary_accuracy: 0.8696\n",
      "Epoch 116/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.0466 - binary_accuracy: 1.0000 - val_loss: 0.3744 - val_binary_accuracy: 0.8696\n",
      "Epoch 117/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.0875 - binary_accuracy: 0.9792 - val_loss: 0.3641 - val_binary_accuracy: 0.8261\n",
      "Epoch 118/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.0524 - binary_accuracy: 0.9931 - val_loss: 0.3336 - val_binary_accuracy: 0.8696\n",
      "Epoch 119/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0391 - binary_accuracy: 1.0000 - val_loss: 0.4008 - val_binary_accuracy: 0.8261\n",
      "Epoch 120/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0521 - binary_accuracy: 0.9931 - val_loss: 0.3801 - val_binary_accuracy: 0.8261\n",
      "Epoch 121/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.0675 - binary_accuracy: 0.9861 - val_loss: 0.3852 - val_binary_accuracy: 0.8696\n",
      "Epoch 122/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0467 - binary_accuracy: 0.9931 - val_loss: 0.3588 - val_binary_accuracy: 0.8261\n",
      "Epoch 123/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.0383 - binary_accuracy: 0.9931 - val_loss: 0.3605 - val_binary_accuracy: 0.8696\n",
      "Epoch 124/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.0347 - binary_accuracy: 1.0000 - val_loss: 0.4000 - val_binary_accuracy: 0.9130\n",
      "Epoch 125/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0562 - binary_accuracy: 0.9931 - val_loss: 0.3943 - val_binary_accuracy: 0.9130\n",
      "Epoch 126/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.0336 - binary_accuracy: 1.0000 - val_loss: 0.3788 - val_binary_accuracy: 0.8261\n",
      "Epoch 127/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.0457 - binary_accuracy: 0.9931 - val_loss: 0.3934 - val_binary_accuracy: 0.8261\n",
      "Epoch 128/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0302 - binary_accuracy: 1.0000 - val_loss: 0.3695 - val_binary_accuracy: 0.9130\n",
      "Epoch 129/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.0305 - binary_accuracy: 1.0000 - val_loss: 0.3381 - val_binary_accuracy: 0.8261\n",
      "Epoch 130/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.0619 - binary_accuracy: 0.9722 - val_loss: 0.4112 - val_binary_accuracy: 0.8696\n",
      "Epoch 131/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.0318 - binary_accuracy: 1.0000 - val_loss: 0.3853 - val_binary_accuracy: 0.8696\n",
      "Epoch 132/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.0319 - binary_accuracy: 1.0000 - val_loss: 0.3839 - val_binary_accuracy: 0.8696\n",
      "Epoch 133/200\n",
      "144/144 [==============================] - 0s 138us/step - loss: 0.0253 - binary_accuracy: 1.0000 - val_loss: 0.3762 - val_binary_accuracy: 0.8696\n",
      "Epoch 134/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.0412 - binary_accuracy: 0.9861 - val_loss: 0.4590 - val_binary_accuracy: 0.9130\n",
      "Epoch 135/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.0406 - binary_accuracy: 1.0000 - val_loss: 0.4051 - val_binary_accuracy: 0.8696\n",
      "Epoch 136/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0259 - binary_accuracy: 1.0000 - val_loss: 0.4148 - val_binary_accuracy: 0.8261\n",
      "Epoch 137/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0231 - binary_accuracy: 1.0000 - val_loss: 0.3895 - val_binary_accuracy: 0.8696\n",
      "Epoch 138/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0193 - binary_accuracy: 1.0000 - val_loss: 0.4128 - val_binary_accuracy: 0.8261\n",
      "Epoch 139/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.0238 - binary_accuracy: 1.0000 - val_loss: 0.4491 - val_binary_accuracy: 0.8261\n",
      "Epoch 140/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0252 - binary_accuracy: 1.0000 - val_loss: 0.3800 - val_binary_accuracy: 0.8696\n",
      "Epoch 141/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.0197 - binary_accuracy: 1.0000 - val_loss: 0.3659 - val_binary_accuracy: 0.8261\n",
      "Epoch 142/200\n",
      "144/144 [==============================] - 0s 173us/step - loss: 0.0515 - binary_accuracy: 0.9931 - val_loss: 0.4073 - val_binary_accuracy: 0.8696\n",
      "Epoch 143/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.0176 - binary_accuracy: 1.0000 - val_loss: 0.4255 - val_binary_accuracy: 0.8696\n",
      "Epoch 144/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.0199 - binary_accuracy: 1.0000 - val_loss: 0.4044 - val_binary_accuracy: 0.8696\n",
      "Epoch 145/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0143 - binary_accuracy: 1.0000 - val_loss: 0.4145 - val_binary_accuracy: 0.8696\n",
      "Epoch 146/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0146 - binary_accuracy: 1.0000 - val_loss: 0.4270 - val_binary_accuracy: 0.8261\n",
      "Epoch 147/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.0314 - binary_accuracy: 0.9931 - val_loss: 0.4035 - val_binary_accuracy: 0.8696\n",
      "Epoch 148/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.0147 - binary_accuracy: 1.0000 - val_loss: 0.4456 - val_binary_accuracy: 0.8696\n",
      "Epoch 149/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0153 - binary_accuracy: 1.0000 - val_loss: 0.4870 - val_binary_accuracy: 0.9130\n",
      "Epoch 150/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.0663 - binary_accuracy: 0.9861 - val_loss: 0.4874 - val_binary_accuracy: 0.8696\n",
      "Epoch 151/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0192 - binary_accuracy: 1.0000 - val_loss: 0.4420 - val_binary_accuracy: 0.8696\n",
      "Epoch 152/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0111 - binary_accuracy: 1.0000 - val_loss: 0.4495 - val_binary_accuracy: 0.8696\n",
      "Epoch 153/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0111 - binary_accuracy: 1.0000 - val_loss: 0.4596 - val_binary_accuracy: 0.8696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.0111 - binary_accuracy: 1.0000 - val_loss: 0.4563 - val_binary_accuracy: 0.8696\n",
      "Epoch 155/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.0104 - binary_accuracy: 1.0000 - val_loss: 0.5062 - val_binary_accuracy: 0.8696\n",
      "Epoch 156/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0108 - binary_accuracy: 1.0000 - val_loss: 0.4784 - val_binary_accuracy: 0.8696\n",
      "Epoch 157/200\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.0265 - binary_accuracy: 0.9931 - val_loss: 0.5651 - val_binary_accuracy: 0.9130\n",
      "Epoch 158/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0236 - binary_accuracy: 0.9931 - val_loss: 0.5040 - val_binary_accuracy: 0.8261\n",
      "Epoch 159/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0092 - binary_accuracy: 1.0000 - val_loss: 0.4862 - val_binary_accuracy: 0.8261\n",
      "Epoch 160/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0089 - binary_accuracy: 1.0000 - val_loss: 0.5019 - val_binary_accuracy: 0.8261\n",
      "Epoch 161/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.0096 - binary_accuracy: 1.0000 - val_loss: 0.5110 - val_binary_accuracy: 0.8696\n",
      "Epoch 162/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0095 - binary_accuracy: 1.0000 - val_loss: 0.5032 - val_binary_accuracy: 0.8696\n",
      "Epoch 163/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0072 - binary_accuracy: 1.0000 - val_loss: 0.5295 - val_binary_accuracy: 0.8696\n",
      "Epoch 164/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.0549 - binary_accuracy: 0.9792 - val_loss: 0.5280 - val_binary_accuracy: 0.9130\n",
      "Epoch 165/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.0124 - binary_accuracy: 1.0000 - val_loss: 0.4795 - val_binary_accuracy: 0.8696\n",
      "Epoch 166/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0062 - binary_accuracy: 1.0000 - val_loss: 0.4834 - val_binary_accuracy: 0.8696\n",
      "Epoch 167/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0060 - binary_accuracy: 1.0000 - val_loss: 0.4844 - val_binary_accuracy: 0.8696\n",
      "Epoch 168/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.0060 - binary_accuracy: 1.0000 - val_loss: 0.4912 - val_binary_accuracy: 0.8696\n",
      "Epoch 169/200\n",
      "144/144 [==============================] - 0s 138us/step - loss: 0.0056 - binary_accuracy: 1.0000 - val_loss: 0.5033 - val_binary_accuracy: 0.8696\n",
      "Epoch 170/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0070 - binary_accuracy: 1.0000 - val_loss: 0.5638 - val_binary_accuracy: 0.9130\n",
      "Epoch 171/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0421 - binary_accuracy: 0.9792 - val_loss: 0.5203 - val_binary_accuracy: 0.8261\n",
      "Epoch 172/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0057 - binary_accuracy: 1.0000 - val_loss: 0.5260 - val_binary_accuracy: 0.8696\n",
      "Epoch 173/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0050 - binary_accuracy: 1.0000 - val_loss: 0.5397 - val_binary_accuracy: 0.8696\n",
      "Epoch 174/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.0049 - binary_accuracy: 1.0000 - val_loss: 0.5144 - val_binary_accuracy: 0.8696\n",
      "Epoch 175/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0053 - binary_accuracy: 1.0000 - val_loss: 0.5466 - val_binary_accuracy: 0.8696\n",
      "Epoch 176/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0046 - binary_accuracy: 1.0000 - val_loss: 0.5367 - val_binary_accuracy: 0.9130\n",
      "Epoch 177/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0082 - binary_accuracy: 1.0000 - val_loss: 0.5878 - val_binary_accuracy: 0.9130\n",
      "Epoch 178/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.0070 - binary_accuracy: 1.0000 - val_loss: 0.5334 - val_binary_accuracy: 0.8696\n",
      "Epoch 179/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0071 - binary_accuracy: 1.0000 - val_loss: 0.5621 - val_binary_accuracy: 0.9130\n",
      "Epoch 180/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0254 - binary_accuracy: 0.9931 - val_loss: 0.5288 - val_binary_accuracy: 0.8696\n",
      "Epoch 181/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0043 - binary_accuracy: 1.0000 - val_loss: 0.5289 - val_binary_accuracy: 0.8696\n",
      "Epoch 182/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0038 - binary_accuracy: 1.0000 - val_loss: 0.5442 - val_binary_accuracy: 0.8696\n",
      "Epoch 183/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0034 - binary_accuracy: 1.0000 - val_loss: 0.5499 - val_binary_accuracy: 0.8696\n",
      "Epoch 184/200\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.0039 - binary_accuracy: 1.0000 - val_loss: 0.5614 - val_binary_accuracy: 0.8696\n",
      "Epoch 185/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0044 - binary_accuracy: 1.0000 - val_loss: 0.5811 - val_binary_accuracy: 0.8261\n",
      "Epoch 186/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.0275 - binary_accuracy: 1.0000 - val_loss: 0.5613 - val_binary_accuracy: 0.8696\n",
      "Epoch 187/200\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.0037 - binary_accuracy: 1.0000 - val_loss: 0.5825 - val_binary_accuracy: 0.8696\n",
      "Epoch 188/200\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.0033 - binary_accuracy: 1.0000 - val_loss: 0.5784 - val_binary_accuracy: 0.8696\n",
      "Epoch 189/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0028 - binary_accuracy: 1.0000 - val_loss: 0.5782 - val_binary_accuracy: 0.8696\n",
      "Epoch 190/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.0027 - binary_accuracy: 1.0000 - val_loss: 0.5765 - val_binary_accuracy: 0.8696\n",
      "Epoch 191/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.0026 - binary_accuracy: 1.0000 - val_loss: 0.5881 - val_binary_accuracy: 0.8696\n",
      "Epoch 192/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0024 - binary_accuracy: 1.0000 - val_loss: 0.5875 - val_binary_accuracy: 0.8696\n",
      "Epoch 193/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.0041 - binary_accuracy: 1.0000 - val_loss: 0.5975 - val_binary_accuracy: 0.8696\n",
      "Epoch 194/200\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.0025 - binary_accuracy: 1.0000 - val_loss: 0.7550 - val_binary_accuracy: 0.8261\n",
      "Epoch 195/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0105 - binary_accuracy: 1.0000 - val_loss: 0.5986 - val_binary_accuracy: 0.8696\n",
      "Epoch 196/200\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0022 - binary_accuracy: 1.0000 - val_loss: 0.5730 - val_binary_accuracy: 0.8696\n",
      "Epoch 197/200\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0020 - binary_accuracy: 1.0000 - val_loss: 0.6040 - val_binary_accuracy: 0.8696\n",
      "Epoch 198/200\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.0021 - binary_accuracy: 1.0000 - val_loss: 0.5799 - val_binary_accuracy: 0.8261\n",
      "Epoch 199/200\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.0579 - binary_accuracy: 0.9722 - val_loss: 0.5573 - val_binary_accuracy: 0.8696\n",
      "Epoch 200/200\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.0028 - binary_accuracy: 1.0000 - val_loss: 0.5772 - val_binary_accuracy: 0.8696\n"
     ]
    }
   ],
   "source": [
    "model_2 = neural_model()\n",
    "\n",
    "history = model_2.fit(x_train, encoded_y_train,validation_data = (x_val, encoded_y_val), epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.8973 - binary_accuracy: 0.8293\n"
     ]
    }
   ],
   "source": [
    "results = model_2.fit(x_test, encoded_y_test, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_binary_accuracy', 'loss', 'binary_accuracy'])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, \"bo\", label = \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label = \"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "144/144 [==============================] - 0s 741us/step - loss: 0.6903 - binary_accuracy: 0.4931\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.6823 - binary_accuracy: 0.5903\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.6723 - binary_accuracy: 0.6875\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.6669 - binary_accuracy: 0.6944\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 166us/step - loss: 0.6570 - binary_accuracy: 0.7361\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6472 - binary_accuracy: 0.7292\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.6426 - binary_accuracy: 0.7292\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6282 - binary_accuracy: 0.7222\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.6298 - binary_accuracy: 0.7153\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.6130 - binary_accuracy: 0.7292\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.6020 - binary_accuracy: 0.7431\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.5932 - binary_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.5803 - binary_accuracy: 0.7639\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.5736 - binary_accuracy: 0.7431\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.5632 - binary_accuracy: 0.7500\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 0s 166us/step - loss: 0.5510 - binary_accuracy: 0.7361\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.5421 - binary_accuracy: 0.7500\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 0s 180us/step - loss: 0.5311 - binary_accuracy: 0.7986\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.5165 - binary_accuracy: 0.7778\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.5079 - binary_accuracy: 0.7708\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.5018 - binary_accuracy: 0.8125\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.4814 - binary_accuracy: 0.7847\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.4720 - binary_accuracy: 0.7847\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4640 - binary_accuracy: 0.7986\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4601 - binary_accuracy: 0.8333\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4464 - binary_accuracy: 0.8194\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.4502 - binary_accuracy: 0.8194\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 0s 166us/step - loss: 0.4350 - binary_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4233 - binary_accuracy: 0.8403\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4126 - binary_accuracy: 0.8472\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.4038 - binary_accuracy: 0.8472\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.4107 - binary_accuracy: 0.8194\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.4059 - binary_accuracy: 0.8403\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.3855 - binary_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.3779 - binary_accuracy: 0.8542\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3736 - binary_accuracy: 0.8681\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3743 - binary_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3673 - binary_accuracy: 0.8889\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3688 - binary_accuracy: 0.8403\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.3630 - binary_accuracy: 0.8819\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.3539 - binary_accuracy: 0.8611\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3444 - binary_accuracy: 0.8819\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3400 - binary_accuracy: 0.8611\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.3683 - binary_accuracy: 0.8472\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3310 - binary_accuracy: 0.8889\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3233 - binary_accuracy: 0.8681\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3170 - binary_accuracy: 0.8889\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3374 - binary_accuracy: 0.8611\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.3201 - binary_accuracy: 0.8611\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3058 - binary_accuracy: 0.8958\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3053 - binary_accuracy: 0.8750\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3064 - binary_accuracy: 0.8889\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2829 - binary_accuracy: 0.8819\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3474 - binary_accuracy: 0.8125\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2982 - binary_accuracy: 0.8681\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2766 - binary_accuracy: 0.8958\n",
      "Epoch 57/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3021 - binary_accuracy: 0.8472\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2843 - binary_accuracy: 0.9028\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2803 - binary_accuracy: 0.8958\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2757 - binary_accuracy: 0.9028\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2779 - binary_accuracy: 0.9167\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2846 - binary_accuracy: 0.8681\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2594 - binary_accuracy: 0.9097\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.2571 - binary_accuracy: 0.9097\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2588 - binary_accuracy: 0.9097\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.2555 - binary_accuracy: 0.9167\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2657 - binary_accuracy: 0.9167\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2540 - binary_accuracy: 0.9236\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2512 - binary_accuracy: 0.9167\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2482 - binary_accuracy: 0.9097\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2326 - binary_accuracy: 0.9306\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2435 - binary_accuracy: 0.9028\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2420 - binary_accuracy: 0.8958\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 118us/step - loss: 0.2539 - binary_accuracy: 0.9167\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2183 - binary_accuracy: 0.9514\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2247 - binary_accuracy: 0.9236\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2281 - binary_accuracy: 0.9097\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2133 - binary_accuracy: 0.9306\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2416 - binary_accuracy: 0.9028\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2110 - binary_accuracy: 0.9028\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 0s 146us/step - loss: 0.2021 - binary_accuracy: 0.9514\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2109 - binary_accuracy: 0.9306\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1932 - binary_accuracy: 0.9514\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2049 - binary_accuracy: 0.9236\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1954 - binary_accuracy: 0.9375\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1815 - binary_accuracy: 0.9514\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1842 - binary_accuracy: 0.9583\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1876 - binary_accuracy: 0.9583\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1852 - binary_accuracy: 0.9375\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1918 - binary_accuracy: 0.9306\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1701 - binary_accuracy: 0.9653\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1950 - binary_accuracy: 0.9375\n",
      "Epoch 93/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1850 - binary_accuracy: 0.9444\n",
      "Epoch 94/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1769 - binary_accuracy: 0.9306\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1598 - binary_accuracy: 0.9444\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1650 - binary_accuracy: 0.9583\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1848 - binary_accuracy: 0.9167\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1649 - binary_accuracy: 0.9583\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1439 - binary_accuracy: 0.9653\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1634 - binary_accuracy: 0.9444\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.6857 - binary_accuracy: 0.5556\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6630 - binary_accuracy: 0.5417\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6436 - binary_accuracy: 0.5417\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6286 - binary_accuracy: 0.5625\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6142 - binary_accuracy: 0.6042\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6060 - binary_accuracy: 0.5972\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5962 - binary_accuracy: 0.6319\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5802 - binary_accuracy: 0.6667\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5737 - binary_accuracy: 0.7153\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5648 - binary_accuracy: 0.6944\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5517 - binary_accuracy: 0.7292\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5492 - binary_accuracy: 0.7292\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5352 - binary_accuracy: 0.7569\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5225 - binary_accuracy: 0.7431\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.5081 - binary_accuracy: 0.8264\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5073 - binary_accuracy: 0.7847\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4984 - binary_accuracy: 0.8125\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.5016 - binary_accuracy: 0.7778\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4772 - binary_accuracy: 0.7847\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4741 - binary_accuracy: 0.8194\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.4556 - binary_accuracy: 0.8611\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4568 - binary_accuracy: 0.8264\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4418 - binary_accuracy: 0.8403\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4251 - binary_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4326 - binary_accuracy: 0.8194\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4289 - binary_accuracy: 0.8542\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3986 - binary_accuracy: 0.8403\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.4213 - binary_accuracy: 0.8611\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3969 - binary_accuracy: 0.8542\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4168 - binary_accuracy: 0.8194\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3745 - binary_accuracy: 0.8611\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3709 - binary_accuracy: 0.8750\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3604 - binary_accuracy: 0.8889\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - ETA: 0s - loss: 0.3246 - binary_accuracy: 0.937 - 0s 111us/step - loss: 0.3813 - binary_accuracy: 0.8264\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3384 - binary_accuracy: 0.8889\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3421 - binary_accuracy: 0.9097\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3383 - binary_accuracy: 0.8958\n",
      "Epoch 38/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3433 - binary_accuracy: 0.8819\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3342 - binary_accuracy: 0.8542\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3245 - binary_accuracy: 0.8750\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3241 - binary_accuracy: 0.8889\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3089 - binary_accuracy: 0.8958\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3451 - binary_accuracy: 0.8681\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3092 - binary_accuracy: 0.9167\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2960 - binary_accuracy: 0.8958\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2959 - binary_accuracy: 0.8958\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 125us/step - loss: 0.2851 - binary_accuracy: 0.8958\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2715 - binary_accuracy: 0.9028\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3051 - binary_accuracy: 0.8819\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2720 - binary_accuracy: 0.9167\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2683 - binary_accuracy: 0.9167\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2792 - binary_accuracy: 0.8958\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2627 - binary_accuracy: 0.8958\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2778 - binary_accuracy: 0.8958\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2461 - binary_accuracy: 0.9236\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2385 - binary_accuracy: 0.9514\n",
      "Epoch 57/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2760 - binary_accuracy: 0.8681\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2463 - binary_accuracy: 0.9375\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2686 - binary_accuracy: 0.9097\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2261 - binary_accuracy: 0.9306\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2160 - binary_accuracy: 0.9444\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2177 - binary_accuracy: 0.9236\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2517 - binary_accuracy: 0.9167\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2089 - binary_accuracy: 0.9306\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2389 - binary_accuracy: 0.9167\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2187 - binary_accuracy: 0.9167\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - ETA: 0s - loss: 0.2568 - binary_accuracy: 0.906 - 0s 125us/step - loss: 0.2065 - binary_accuracy: 0.9514\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 0s 166us/step - loss: 0.2060 - binary_accuracy: 0.9444\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1943 - binary_accuracy: 0.9375\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2124 - binary_accuracy: 0.9167\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1828 - binary_accuracy: 0.9375\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2241 - binary_accuracy: 0.9167\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2168 - binary_accuracy: 0.9097\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1943 - binary_accuracy: 0.9514\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1678 - binary_accuracy: 0.9444\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1860 - binary_accuracy: 0.9444\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1703 - binary_accuracy: 0.9583\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2269 - binary_accuracy: 0.8958\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1597 - binary_accuracy: 0.9514\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1582 - binary_accuracy: 0.9514\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1567 - binary_accuracy: 0.9583\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1510 - binary_accuracy: 0.9583\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1496 - binary_accuracy: 0.9722\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1645 - binary_accuracy: 0.9306\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1718 - binary_accuracy: 0.9306\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1369 - binary_accuracy: 0.9653\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1491 - binary_accuracy: 0.9583\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1642 - binary_accuracy: 0.9514\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1542 - binary_accuracy: 0.9514\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1512 - binary_accuracy: 0.9514\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1427 - binary_accuracy: 0.9583\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1291 - binary_accuracy: 0.9722\n",
      "Epoch 93/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1455 - binary_accuracy: 0.9514\n",
      "Epoch 94/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1354 - binary_accuracy: 0.9514\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1271 - binary_accuracy: 0.9722\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1269 - binary_accuracy: 0.9792\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1341 - binary_accuracy: 0.9583\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1239 - binary_accuracy: 0.9722\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1217 - binary_accuracy: 0.9722\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1214 - binary_accuracy: 0.9722\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 0s 727us/step - loss: 0.6885 - binary_accuracy: 0.5278\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.6741 - binary_accuracy: 0.5417\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 138us/step - loss: 0.6545 - binary_accuracy: 0.5764\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6418 - binary_accuracy: 0.6042\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6242 - binary_accuracy: 0.6597\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6164 - binary_accuracy: 0.6458\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6016 - binary_accuracy: 0.7292\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.5806 - binary_accuracy: 0.6944\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.5718 - binary_accuracy: 0.7431\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5527 - binary_accuracy: 0.7431\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5613 - binary_accuracy: 0.6944\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5326 - binary_accuracy: 0.7639\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5147 - binary_accuracy: 0.7431\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5017 - binary_accuracy: 0.7847\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4893 - binary_accuracy: 0.7708\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.4825 - binary_accuracy: 0.7847\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4745 - binary_accuracy: 0.7431\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4732 - binary_accuracy: 0.7639\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4501 - binary_accuracy: 0.7639\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 90us/step - loss: 0.4627 - binary_accuracy: 0.8194\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.4360 - binary_accuracy: 0.7778\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.4367 - binary_accuracy: 0.8056\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4311 - binary_accuracy: 0.8194\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4134 - binary_accuracy: 0.8403\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4169 - binary_accuracy: 0.7986\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4320 - binary_accuracy: 0.7986\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3958 - binary_accuracy: 0.8403\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3931 - binary_accuracy: 0.8403\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4065 - binary_accuracy: 0.7778\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3992 - binary_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.3898 - binary_accuracy: 0.8264\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3865 - binary_accuracy: 0.8056\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3674 - binary_accuracy: 0.8403\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3676 - binary_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3860 - binary_accuracy: 0.8194\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3593 - binary_accuracy: 0.8472\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3814 - binary_accuracy: 0.8264\n",
      "Epoch 38/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3416 - binary_accuracy: 0.8681\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3482 - binary_accuracy: 0.8403\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3458 - binary_accuracy: 0.8403\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3346 - binary_accuracy: 0.8472\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3423 - binary_accuracy: 0.8611\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3614 - binary_accuracy: 0.8333\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3246 - binary_accuracy: 0.8819\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3130 - binary_accuracy: 0.9028\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3103 - binary_accuracy: 0.8750\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3189 - binary_accuracy: 0.8750\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3271 - binary_accuracy: 0.8264\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3079 - binary_accuracy: 0.8819\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2991 - binary_accuracy: 0.8750\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2907 - binary_accuracy: 0.8819\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2943 - binary_accuracy: 0.9028\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2999 - binary_accuracy: 0.8819\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2975 - binary_accuracy: 0.8889\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2787 - binary_accuracy: 0.9167\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2825 - binary_accuracy: 0.8889\n",
      "Epoch 57/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2656 - binary_accuracy: 0.9167\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2743 - binary_accuracy: 0.8681\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2671 - binary_accuracy: 0.8889\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 0s 166us/step - loss: 0.2604 - binary_accuracy: 0.9097\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2548 - binary_accuracy: 0.9028\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2549 - binary_accuracy: 0.9167\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2667 - binary_accuracy: 0.8750\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2811 - binary_accuracy: 0.9028\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2485 - binary_accuracy: 0.9167\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2317 - binary_accuracy: 0.9236\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2849 - binary_accuracy: 0.8819\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2281 - binary_accuracy: 0.9236\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2542 - binary_accuracy: 0.8958\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2311 - binary_accuracy: 0.9236\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2762 - binary_accuracy: 0.8819\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2129 - binary_accuracy: 0.9236\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2146 - binary_accuracy: 0.9236\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2061 - binary_accuracy: 0.9444\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2372 - binary_accuracy: 0.8889\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2233 - binary_accuracy: 0.9236\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2096 - binary_accuracy: 0.9306\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2161 - binary_accuracy: 0.9236\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2577 - binary_accuracy: 0.9028\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2011 - binary_accuracy: 0.9444\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1981 - binary_accuracy: 0.9306\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2001 - binary_accuracy: 0.9306\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1857 - binary_accuracy: 0.9444\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1958 - binary_accuracy: 0.9375\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1831 - binary_accuracy: 0.9375\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1885 - binary_accuracy: 0.9306\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1925 - binary_accuracy: 0.9444\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1982 - binary_accuracy: 0.9306\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1621 - binary_accuracy: 0.9514\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1878 - binary_accuracy: 0.9444\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1839 - binary_accuracy: 0.9306\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1711 - binary_accuracy: 0.9444\n",
      "Epoch 93/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1850 - binary_accuracy: 0.9306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1609 - binary_accuracy: 0.9514\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1649 - binary_accuracy: 0.9375\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1899 - binary_accuracy: 0.9097\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1518 - binary_accuracy: 0.9583\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1646 - binary_accuracy: 0.9444\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1857 - binary_accuracy: 0.9375\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1352 - binary_accuracy: 0.9653\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 0s 727us/step - loss: 0.6890 - binary_accuracy: 0.5625\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.6788 - binary_accuracy: 0.6250\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6694 - binary_accuracy: 0.6250\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6595 - binary_accuracy: 0.6528\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.6453 - binary_accuracy: 0.6875\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.6360 - binary_accuracy: 0.6944\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6186 - binary_accuracy: 0.7153\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.6054 - binary_accuracy: 0.7222\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5981 - binary_accuracy: 0.7222\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5796 - binary_accuracy: 0.7569\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5732 - binary_accuracy: 0.7083\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.5624 - binary_accuracy: 0.7083\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5531 - binary_accuracy: 0.7083\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5360 - binary_accuracy: 0.7500\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5279 - binary_accuracy: 0.7639\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.5200 - binary_accuracy: 0.7639\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.5057 - binary_accuracy: 0.7569\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.4940 - binary_accuracy: 0.7569\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4853 - binary_accuracy: 0.7569\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4892 - binary_accuracy: 0.7431\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4709 - binary_accuracy: 0.7569\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4569 - binary_accuracy: 0.8125\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4483 - binary_accuracy: 0.7778\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4394 - binary_accuracy: 0.8264\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4355 - binary_accuracy: 0.7639\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4394 - binary_accuracy: 0.7917\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4187 - binary_accuracy: 0.7847\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4191 - binary_accuracy: 0.8264\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4226 - binary_accuracy: 0.7986\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4303 - binary_accuracy: 0.7708\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3941 - binary_accuracy: 0.7847\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4033 - binary_accuracy: 0.8194\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3870 - binary_accuracy: 0.8194\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3766 - binary_accuracy: 0.8264\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3652 - binary_accuracy: 0.8472\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3839 - binary_accuracy: 0.8333\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3858 - binary_accuracy: 0.8403\n",
      "Epoch 38/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3557 - binary_accuracy: 0.8542\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3628 - binary_accuracy: 0.8125\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3453 - binary_accuracy: 0.8472\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3382 - binary_accuracy: 0.8542\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3473 - binary_accuracy: 0.8333\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3317 - binary_accuracy: 0.8750\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3417 - binary_accuracy: 0.8542\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3339 - binary_accuracy: 0.8542\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3272 - binary_accuracy: 0.8681\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3332 - binary_accuracy: 0.8333\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3108 - binary_accuracy: 0.8750\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3126 - binary_accuracy: 0.8611\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3152 - binary_accuracy: 0.8472\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2934 - binary_accuracy: 0.8542\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2887 - binary_accuracy: 0.8889\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3053 - binary_accuracy: 0.8958\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2938 - binary_accuracy: 0.8750\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3039 - binary_accuracy: 0.8542\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2899 - binary_accuracy: 0.8750\n",
      "Epoch 57/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2697 - binary_accuracy: 0.8889\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2877 - binary_accuracy: 0.8750\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2687 - binary_accuracy: 0.9028\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2615 - binary_accuracy: 0.8958\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2822 - binary_accuracy: 0.8681\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2501 - binary_accuracy: 0.9306\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2531 - binary_accuracy: 0.9236\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2513 - binary_accuracy: 0.9167\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2546 - binary_accuracy: 0.8958\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2339 - binary_accuracy: 0.9167\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2701 - binary_accuracy: 0.8819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2506 - binary_accuracy: 0.8889\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2175 - binary_accuracy: 0.9375\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2241 - binary_accuracy: 0.9306\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2513 - binary_accuracy: 0.8958\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2294 - binary_accuracy: 0.9028\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2118 - binary_accuracy: 0.9444\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2407 - binary_accuracy: 0.8958\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2362 - binary_accuracy: 0.8889\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2004 - binary_accuracy: 0.9444\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2109 - binary_accuracy: 0.9444\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2064 - binary_accuracy: 0.9444\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2112 - binary_accuracy: 0.9306\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2283 - binary_accuracy: 0.9097\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1873 - binary_accuracy: 0.9375\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.1828 - binary_accuracy: 0.9514\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1770 - binary_accuracy: 0.9444\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2409 - binary_accuracy: 0.8819\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1817 - binary_accuracy: 0.9444\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1908 - binary_accuracy: 0.9375\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1752 - binary_accuracy: 0.9375\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1907 - binary_accuracy: 0.9583\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1682 - binary_accuracy: 0.9514\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1607 - binary_accuracy: 0.9444\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1721 - binary_accuracy: 0.9444\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1801 - binary_accuracy: 0.9375\n",
      "Epoch 93/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1684 - binary_accuracy: 0.9514\n",
      "Epoch 94/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1604 - binary_accuracy: 0.9514\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1523 - binary_accuracy: 0.9444\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1490 - binary_accuracy: 0.9583\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1761 - binary_accuracy: 0.9097\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1437 - binary_accuracy: 0.9583\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1734 - binary_accuracy: 0.9375\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1487 - binary_accuracy: 0.9444\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 0s 720us/step - loss: 0.6875 - binary_accuracy: 0.5417\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.6631 - binary_accuracy: 0.5903\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.6444 - binary_accuracy: 0.6042\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.6250 - binary_accuracy: 0.6250\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.6121 - binary_accuracy: 0.7014\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5911 - binary_accuracy: 0.6806\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5780 - binary_accuracy: 0.7153\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5762 - binary_accuracy: 0.7153\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5529 - binary_accuracy: 0.7292\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5366 - binary_accuracy: 0.7292\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5216 - binary_accuracy: 0.7778\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5109 - binary_accuracy: 0.7917\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4997 - binary_accuracy: 0.7500\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4903 - binary_accuracy: 0.7569\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4749 - binary_accuracy: 0.7917\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4668 - binary_accuracy: 0.7917\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4623 - binary_accuracy: 0.7500\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4525 - binary_accuracy: 0.7917\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4343 - binary_accuracy: 0.8125\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.4286 - binary_accuracy: 0.8194\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4235 - binary_accuracy: 0.8194\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4153 - binary_accuracy: 0.8264\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.4060 - binary_accuracy: 0.8264\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4090 - binary_accuracy: 0.8194\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3844 - binary_accuracy: 0.8333\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3827 - binary_accuracy: 0.8542\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3649 - binary_accuracy: 0.8611\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3796 - binary_accuracy: 0.8125\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3560 - binary_accuracy: 0.8750\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3589 - binary_accuracy: 0.8542\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3409 - binary_accuracy: 0.8611\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3440 - binary_accuracy: 0.8681\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3509 - binary_accuracy: 0.8542\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3251 - binary_accuracy: 0.8889\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3184 - binary_accuracy: 0.8958\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3295 - binary_accuracy: 0.8681\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3151 - binary_accuracy: 0.8889\n",
      "Epoch 38/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3167 - binary_accuracy: 0.8889\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2917 - binary_accuracy: 0.8958\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 0s 83us/step - loss: 0.2967 - binary_accuracy: 0.9097\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2791 - binary_accuracy: 0.9028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3113 - binary_accuracy: 0.8750\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2955 - binary_accuracy: 0.8681\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2696 - binary_accuracy: 0.9167\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2897 - binary_accuracy: 0.8889\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2720 - binary_accuracy: 0.8958\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2609 - binary_accuracy: 0.9236\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2637 - binary_accuracy: 0.9028\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2550 - binary_accuracy: 0.9167\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2648 - binary_accuracy: 0.9167\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2577 - binary_accuracy: 0.9028\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2699 - binary_accuracy: 0.9097\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2300 - binary_accuracy: 0.9236\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2336 - binary_accuracy: 0.9306\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2383 - binary_accuracy: 0.9167\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2315 - binary_accuracy: 0.9097\n",
      "Epoch 57/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2313 - binary_accuracy: 0.9167\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2294 - binary_accuracy: 0.9444\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2200 - binary_accuracy: 0.9167\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2254 - binary_accuracy: 0.9097\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2113 - binary_accuracy: 0.9444\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1982 - binary_accuracy: 0.9514\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1999 - binary_accuracy: 0.9514\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1930 - binary_accuracy: 0.9583\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2090 - binary_accuracy: 0.9167\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1842 - binary_accuracy: 0.9444\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1742 - binary_accuracy: 0.9514\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1811 - binary_accuracy: 0.9444\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1842 - binary_accuracy: 0.9375\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1696 - binary_accuracy: 0.9375\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1634 - binary_accuracy: 0.9583\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1684 - binary_accuracy: 0.9514\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1625 - binary_accuracy: 0.9653\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1784 - binary_accuracy: 0.9306\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1450 - binary_accuracy: 0.9722\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1499 - binary_accuracy: 0.9722\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1734 - binary_accuracy: 0.9306\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1427 - binary_accuracy: 0.9792\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1359 - binary_accuracy: 0.9792\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1349 - binary_accuracy: 0.9653\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1468 - binary_accuracy: 0.9375\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1532 - binary_accuracy: 0.9583\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1235 - binary_accuracy: 0.9861\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1216 - binary_accuracy: 0.9792\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1246 - binary_accuracy: 0.9722\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1453 - binary_accuracy: 0.9722\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1233 - binary_accuracy: 0.9653\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1367 - binary_accuracy: 0.9583\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1260 - binary_accuracy: 0.9792\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1084 - binary_accuracy: 0.9861\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0990 - binary_accuracy: 0.9792\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1131 - binary_accuracy: 0.9583\n",
      "Epoch 93/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1088 - binary_accuracy: 0.9792\n",
      "Epoch 94/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1071 - binary_accuracy: 0.9861\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0973 - binary_accuracy: 0.9861\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.0977 - binary_accuracy: 0.9861\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.0869 - binary_accuracy: 0.9931\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0916 - binary_accuracy: 0.9792\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.0980 - binary_accuracy: 0.9861\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.0911 - binary_accuracy: 0.9861\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 0s 741us/step - loss: 0.6873 - binary_accuracy: 0.5764\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.6633 - binary_accuracy: 0.6736\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.6435 - binary_accuracy: 0.6806\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 159us/step - loss: 0.6243 - binary_accuracy: 0.7292\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6165 - binary_accuracy: 0.7361\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6009 - binary_accuracy: 0.7222\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.5922 - binary_accuracy: 0.7431\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.5771 - binary_accuracy: 0.7292\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5678 - binary_accuracy: 0.7222\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.5563 - binary_accuracy: 0.7639\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5422 - binary_accuracy: 0.7639\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5313 - binary_accuracy: 0.7569\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5216 - binary_accuracy: 0.7431\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5063 - binary_accuracy: 0.7847\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5060 - binary_accuracy: 0.7431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4879 - binary_accuracy: 0.7500\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.4820 - binary_accuracy: 0.7500\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4691 - binary_accuracy: 0.7639\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4667 - binary_accuracy: 0.7708\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4656 - binary_accuracy: 0.7708\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4619 - binary_accuracy: 0.7708\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4621 - binary_accuracy: 0.7917\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4352 - binary_accuracy: 0.7986\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4379 - binary_accuracy: 0.8125\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4231 - binary_accuracy: 0.7986\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4309 - binary_accuracy: 0.7986\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4227 - binary_accuracy: 0.7847\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4052 - binary_accuracy: 0.8056\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4127 - binary_accuracy: 0.8056\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3991 - binary_accuracy: 0.8056\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3913 - binary_accuracy: 0.8125\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3952 - binary_accuracy: 0.7847\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3915 - binary_accuracy: 0.8056\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3782 - binary_accuracy: 0.8264\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3806 - binary_accuracy: 0.8403\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3651 - binary_accuracy: 0.8264\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3729 - binary_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3629 - binary_accuracy: 0.8264\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3573 - binary_accuracy: 0.8472\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3657 - binary_accuracy: 0.8125\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3507 - binary_accuracy: 0.8611\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3416 - binary_accuracy: 0.8264\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3288 - binary_accuracy: 0.8611\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3362 - binary_accuracy: 0.8472\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3397 - binary_accuracy: 0.8264\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3278 - binary_accuracy: 0.8611\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3278 - binary_accuracy: 0.8542\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 0s 138us/step - loss: 0.3136 - binary_accuracy: 0.8681\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3083 - binary_accuracy: 0.8750\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3120 - binary_accuracy: 0.8819\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3230 - binary_accuracy: 0.8472\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2968 - binary_accuracy: 0.8889\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2860 - binary_accuracy: 0.9028\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2942 - binary_accuracy: 0.8889\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2767 - binary_accuracy: 0.9097\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2947 - binary_accuracy: 0.8681\n",
      "Epoch 57/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2858 - binary_accuracy: 0.8750\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2673 - binary_accuracy: 0.8958\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2831 - binary_accuracy: 0.8681\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2657 - binary_accuracy: 0.9097\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2603 - binary_accuracy: 0.9028\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2470 - binary_accuracy: 0.9028\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2454 - binary_accuracy: 0.8889\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2472 - binary_accuracy: 0.8958\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2311 - binary_accuracy: 0.9375\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2791 - binary_accuracy: 0.8681\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2401 - binary_accuracy: 0.9097\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2393 - binary_accuracy: 0.9375\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2311 - binary_accuracy: 0.9167\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2386 - binary_accuracy: 0.9028\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2293 - binary_accuracy: 0.9375\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2230 - binary_accuracy: 0.9167\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2119 - binary_accuracy: 0.9236\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2092 - binary_accuracy: 0.9583\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2065 - binary_accuracy: 0.9375\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1978 - binary_accuracy: 0.9236\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2046 - binary_accuracy: 0.9236\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1952 - binary_accuracy: 0.9375\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1803 - binary_accuracy: 0.9722\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1861 - binary_accuracy: 0.9514\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2046 - binary_accuracy: 0.9236\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1704 - binary_accuracy: 0.9653\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1966 - binary_accuracy: 0.9375\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1768 - binary_accuracy: 0.9306\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1578 - binary_accuracy: 0.9861\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1674 - binary_accuracy: 0.9583\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1717 - binary_accuracy: 0.9236\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1635 - binary_accuracy: 0.9514\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 90us/step - loss: 0.1545 - binary_accuracy: 0.9583\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1465 - binary_accuracy: 0.9444\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1438 - binary_accuracy: 0.9722\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1752 - binary_accuracy: 0.9444\n",
      "Epoch 93/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1519 - binary_accuracy: 0.9167\n",
      "Epoch 94/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1346 - binary_accuracy: 0.9722\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1293 - binary_accuracy: 0.9861\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1390 - binary_accuracy: 0.9722\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1664 - binary_accuracy: 0.9444\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1237 - binary_accuracy: 0.9722\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1169 - binary_accuracy: 0.9792\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1035 - binary_accuracy: 0.9931\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 0s 734us/step - loss: 0.6951 - binary_accuracy: 0.5972\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.6755 - binary_accuracy: 0.5625\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.6661 - binary_accuracy: 0.5764\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.6586 - binary_accuracy: 0.5625\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6542 - binary_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6458 - binary_accuracy: 0.6667\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6418 - binary_accuracy: 0.5972\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.6327 - binary_accuracy: 0.6597\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6250 - binary_accuracy: 0.6806\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6252 - binary_accuracy: 0.6319\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.6128 - binary_accuracy: 0.6944\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.6050 - binary_accuracy: 0.6806\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5986 - binary_accuracy: 0.7431\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5885 - binary_accuracy: 0.6875\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5834 - binary_accuracy: 0.7431\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5764 - binary_accuracy: 0.7292\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5688 - binary_accuracy: 0.7361\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5563 - binary_accuracy: 0.7500\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5506 - binary_accuracy: 0.7847\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5501 - binary_accuracy: 0.7778\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.5315 - binary_accuracy: 0.7708\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5288 - binary_accuracy: 0.7986\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5231 - binary_accuracy: 0.8125\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5078 - binary_accuracy: 0.8125\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.5028 - binary_accuracy: 0.7986\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.4904 - binary_accuracy: 0.8194\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.4819 - binary_accuracy: 0.7917\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4705 - binary_accuracy: 0.8056\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4445 - binary_accuracy: 0.8542\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4397 - binary_accuracy: 0.8125\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4119 - binary_accuracy: 0.8611\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4254 - binary_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3972 - binary_accuracy: 0.8542\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3982 - binary_accuracy: 0.8611\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3672 - binary_accuracy: 0.8750\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3977 - binary_accuracy: 0.8264\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3658 - binary_accuracy: 0.8681\n",
      "Epoch 38/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3675 - binary_accuracy: 0.8611\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3553 - binary_accuracy: 0.8542\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3515 - binary_accuracy: 0.8611\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3416 - binary_accuracy: 0.8889\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3473 - binary_accuracy: 0.8681\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3292 - binary_accuracy: 0.8819\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3435 - binary_accuracy: 0.8750\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3224 - binary_accuracy: 0.8542\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3242 - binary_accuracy: 0.8611\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3082 - binary_accuracy: 0.8819\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3044 - binary_accuracy: 0.8958\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3397 - binary_accuracy: 0.8333\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - ETA: 0s - loss: 0.2831 - binary_accuracy: 0.906 - 0s 97us/step - loss: 0.3002 - binary_accuracy: 0.8958\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2951 - binary_accuracy: 0.8819\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3081 - binary_accuracy: 0.8750\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2908 - binary_accuracy: 0.8958\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2812 - binary_accuracy: 0.9097\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2883 - binary_accuracy: 0.8958\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2762 - binary_accuracy: 0.9097\n",
      "Epoch 57/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2899 - binary_accuracy: 0.8750\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2734 - binary_accuracy: 0.9028\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2638 - binary_accuracy: 0.8958\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2571 - binary_accuracy: 0.9167\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3098 - binary_accuracy: 0.8542\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 111us/step - loss: 0.2505 - binary_accuracy: 0.9167\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2566 - binary_accuracy: 0.9028\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2428 - binary_accuracy: 0.9167\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2586 - binary_accuracy: 0.8889\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2396 - binary_accuracy: 0.9097\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2472 - binary_accuracy: 0.8958\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2534 - binary_accuracy: 0.8889\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2278 - binary_accuracy: 0.9236\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2565 - binary_accuracy: 0.8958\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2243 - binary_accuracy: 0.9236\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2226 - binary_accuracy: 0.9097\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2489 - binary_accuracy: 0.9028\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2611 - binary_accuracy: 0.8958\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2156 - binary_accuracy: 0.9167\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2151 - binary_accuracy: 0.9167\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2411 - binary_accuracy: 0.8889\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2179 - binary_accuracy: 0.8958\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2292 - binary_accuracy: 0.9097\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2060 - binary_accuracy: 0.9097\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2221 - binary_accuracy: 0.9167\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2101 - binary_accuracy: 0.9028\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2031 - binary_accuracy: 0.9167\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2341 - binary_accuracy: 0.9097\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1979 - binary_accuracy: 0.9375\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1889 - binary_accuracy: 0.9514\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2104 - binary_accuracy: 0.9097\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1947 - binary_accuracy: 0.9097\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1820 - binary_accuracy: 0.9236\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1786 - binary_accuracy: 0.9236\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2318 - binary_accuracy: 0.9097\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1901 - binary_accuracy: 0.9236\n",
      "Epoch 93/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1701 - binary_accuracy: 0.9306\n",
      "Epoch 94/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1764 - binary_accuracy: 0.9236\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1918 - binary_accuracy: 0.9167\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1905 - binary_accuracy: 0.8958\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1723 - binary_accuracy: 0.9306\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1685 - binary_accuracy: 0.9167\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1874 - binary_accuracy: 0.9097\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1612 - binary_accuracy: 0.9375\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 0s 734us/step - loss: 0.6947 - binary_accuracy: 0.4861\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.6786 - binary_accuracy: 0.5833\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.6691 - binary_accuracy: 0.6806\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.6610 - binary_accuracy: 0.6528\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6557 - binary_accuracy: 0.6458\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.6419 - binary_accuracy: 0.7014\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6347 - binary_accuracy: 0.7500\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6280 - binary_accuracy: 0.7222\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.6155 - binary_accuracy: 0.7431\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.6153 - binary_accuracy: 0.7153\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 0s 152us/step - loss: 0.5969 - binary_accuracy: 0.7431\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5890 - binary_accuracy: 0.7361\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5863 - binary_accuracy: 0.7431\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.5662 - binary_accuracy: 0.7639\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5592 - binary_accuracy: 0.7639\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.5402 - binary_accuracy: 0.7986\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5367 - binary_accuracy: 0.7569\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5186 - binary_accuracy: 0.7778\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5115 - binary_accuracy: 0.7778\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.4992 - binary_accuracy: 0.8125\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4866 - binary_accuracy: 0.7847\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4713 - binary_accuracy: 0.8125\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4681 - binary_accuracy: 0.7986\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4548 - binary_accuracy: 0.8056\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4490 - binary_accuracy: 0.8056\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4405 - binary_accuracy: 0.7917\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4463 - binary_accuracy: 0.7986\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4279 - binary_accuracy: 0.8194\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.4161 - binary_accuracy: 0.8125\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4095 - binary_accuracy: 0.8125\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3952 - binary_accuracy: 0.8472\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4001 - binary_accuracy: 0.8056\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3815 - binary_accuracy: 0.8472\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3754 - binary_accuracy: 0.8403\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3876 - binary_accuracy: 0.8264\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 111us/step - loss: 0.3668 - binary_accuracy: 0.8611\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3559 - binary_accuracy: 0.8958\n",
      "Epoch 38/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3480 - binary_accuracy: 0.8889\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3471 - binary_accuracy: 0.8889\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3301 - binary_accuracy: 0.9028\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3286 - binary_accuracy: 0.8889\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3268 - binary_accuracy: 0.8750\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3337 - binary_accuracy: 0.8750\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3050 - binary_accuracy: 0.9097\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.3361 - binary_accuracy: 0.8958\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2983 - binary_accuracy: 0.9167\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2930 - binary_accuracy: 0.9097\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2955 - binary_accuracy: 0.8819\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2824 - binary_accuracy: 0.8958\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2915 - binary_accuracy: 0.9028\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2792 - binary_accuracy: 0.9167\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2890 - binary_accuracy: 0.8819\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2825 - binary_accuracy: 0.8889\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2855 - binary_accuracy: 0.8889\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2555 - binary_accuracy: 0.8958\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2621 - binary_accuracy: 0.9028\n",
      "Epoch 57/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2494 - binary_accuracy: 0.9167\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2434 - binary_accuracy: 0.9375\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2418 - binary_accuracy: 0.9375\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2374 - binary_accuracy: 0.9236\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2326 - binary_accuracy: 0.9306\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2507 - binary_accuracy: 0.9028\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2586 - binary_accuracy: 0.8958\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2220 - binary_accuracy: 0.9375\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2244 - binary_accuracy: 0.9514\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2123 - binary_accuracy: 0.9306\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2081 - binary_accuracy: 0.9375\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2016 - binary_accuracy: 0.9444\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2034 - binary_accuracy: 0.9583\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2201 - binary_accuracy: 0.9167\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1902 - binary_accuracy: 0.9583\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2235 - binary_accuracy: 0.9097\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1901 - binary_accuracy: 0.9514\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2014 - binary_accuracy: 0.9167\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1729 - binary_accuracy: 0.9583\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1746 - binary_accuracy: 0.9444\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1792 - binary_accuracy: 0.9444\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2043 - binary_accuracy: 0.9167\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1746 - binary_accuracy: 0.9306\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1596 - binary_accuracy: 0.9583\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1695 - binary_accuracy: 0.9306\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1478 - binary_accuracy: 0.9583\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1542 - binary_accuracy: 0.9514\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1449 - binary_accuracy: 0.9653\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1933 - binary_accuracy: 0.9236\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1437 - binary_accuracy: 0.9653\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1528 - binary_accuracy: 0.9653\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1369 - binary_accuracy: 0.9722\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1357 - binary_accuracy: 0.9722\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1620 - binary_accuracy: 0.9583\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1291 - binary_accuracy: 0.9722\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1275 - binary_accuracy: 0.9722\n",
      "Epoch 93/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1343 - binary_accuracy: 0.9583\n",
      "Epoch 94/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1276 - binary_accuracy: 0.9722\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1157 - binary_accuracy: 0.9722\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1493 - binary_accuracy: 0.9514\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1128 - binary_accuracy: 0.9722\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1103 - binary_accuracy: 0.9792\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1397 - binary_accuracy: 0.9514\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1004 - binary_accuracy: 0.9722\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 0s 727us/step - loss: 0.6898 - binary_accuracy: 0.4861\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.6626 - binary_accuracy: 0.7500\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6491 - binary_accuracy: 0.7222\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.6351 - binary_accuracy: 0.7292\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 145us/step - loss: 0.6254 - binary_accuracy: 0.7292\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6094 - binary_accuracy: 0.7500\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.6022 - binary_accuracy: 0.7639\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5873 - binary_accuracy: 0.7847\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 0s 173us/step - loss: 0.5802 - binary_accuracy: 0.7569\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 97us/step - loss: 0.5661 - binary_accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5518 - binary_accuracy: 0.7708\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5375 - binary_accuracy: 0.7986\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.5285 - binary_accuracy: 0.8056\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5103 - binary_accuracy: 0.8125\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4953 - binary_accuracy: 0.7847\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4893 - binary_accuracy: 0.7986\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5010 - binary_accuracy: 0.7569\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4745 - binary_accuracy: 0.7917\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4623 - binary_accuracy: 0.8056\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.4487 - binary_accuracy: 0.8056\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4398 - binary_accuracy: 0.8194\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.4334 - binary_accuracy: 0.7917\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4375 - binary_accuracy: 0.8056\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4170 - binary_accuracy: 0.8611\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4238 - binary_accuracy: 0.8403\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4122 - binary_accuracy: 0.8264\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4048 - binary_accuracy: 0.8194\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3935 - binary_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3857 - binary_accuracy: 0.8403\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3824 - binary_accuracy: 0.8194\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3997 - binary_accuracy: 0.8264\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3688 - binary_accuracy: 0.8542\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3661 - binary_accuracy: 0.8750\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3735 - binary_accuracy: 0.8403\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3530 - binary_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3556 - binary_accuracy: 0.8542\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3546 - binary_accuracy: 0.8472\n",
      "Epoch 38/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3463 - binary_accuracy: 0.8472\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3375 - binary_accuracy: 0.8611\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3355 - binary_accuracy: 0.8681\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3313 - binary_accuracy: 0.8958\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3434 - binary_accuracy: 0.8542\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3402 - binary_accuracy: 0.8611\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3182 - binary_accuracy: 0.8819\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3135 - binary_accuracy: 0.8889\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3013 - binary_accuracy: 0.8889\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3123 - binary_accuracy: 0.8889\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2943 - binary_accuracy: 0.8819\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2984 - binary_accuracy: 0.8958\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2878 - binary_accuracy: 0.9028\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2926 - binary_accuracy: 0.8681\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2805 - binary_accuracy: 0.8958\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2714 - binary_accuracy: 0.8958\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2593 - binary_accuracy: 0.9167\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2834 - binary_accuracy: 0.8958\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2768 - binary_accuracy: 0.8958\n",
      "Epoch 57/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3000 - binary_accuracy: 0.8681\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2611 - binary_accuracy: 0.9167\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2598 - binary_accuracy: 0.9097\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2516 - binary_accuracy: 0.9167\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2466 - binary_accuracy: 0.9097\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2382 - binary_accuracy: 0.9375\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2528 - binary_accuracy: 0.9028\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2450 - binary_accuracy: 0.9167\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2664 - binary_accuracy: 0.9097\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2297 - binary_accuracy: 0.9306\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2325 - binary_accuracy: 0.9236\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2300 - binary_accuracy: 0.9167\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2074 - binary_accuracy: 0.9653\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2285 - binary_accuracy: 0.9097\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2134 - binary_accuracy: 0.9375\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2103 - binary_accuracy: 0.9444\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2016 - binary_accuracy: 0.9444\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1890 - binary_accuracy: 0.9514\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1988 - binary_accuracy: 0.9375\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2046 - binary_accuracy: 0.9236\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.1833 - binary_accuracy: 0.9583\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2038 - binary_accuracy: 0.9306\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1779 - binary_accuracy: 0.9653\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1980 - binary_accuracy: 0.9306\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1969 - binary_accuracy: 0.9514\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1647 - binary_accuracy: 0.9444\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1650 - binary_accuracy: 0.9583\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 111us/step - loss: 0.1530 - binary_accuracy: 0.9583\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1640 - binary_accuracy: 0.9583\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1547 - binary_accuracy: 0.9722\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1870 - binary_accuracy: 0.9028\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1894 - binary_accuracy: 0.9583\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1481 - binary_accuracy: 0.9444\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1665 - binary_accuracy: 0.9444\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1497 - binary_accuracy: 0.9583\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1407 - binary_accuracy: 0.9583\n",
      "Epoch 93/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1323 - binary_accuracy: 0.9792\n",
      "Epoch 94/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1268 - binary_accuracy: 0.9792\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1796 - binary_accuracy: 0.9167\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1279 - binary_accuracy: 0.9792\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.1219 - binary_accuracy: 0.9792\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1175 - binary_accuracy: 0.9861\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1211 - binary_accuracy: 0.9653\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1289 - binary_accuracy: 0.9722\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 0s 727us/step - loss: 0.6864 - binary_accuracy: 0.5347\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.6614 - binary_accuracy: 0.5556\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 139us/step - loss: 0.6407 - binary_accuracy: 0.5764\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6224 - binary_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.6035 - binary_accuracy: 0.7083\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5928 - binary_accuracy: 0.7014\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.5802 - binary_accuracy: 0.7222\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.5724 - binary_accuracy: 0.7083\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5567 - binary_accuracy: 0.7500\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5480 - binary_accuracy: 0.7569\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.5358 - binary_accuracy: 0.7778\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5284 - binary_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.5233 - binary_accuracy: 0.7778\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.5048 - binary_accuracy: 0.7847\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4971 - binary_accuracy: 0.7778\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.4832 - binary_accuracy: 0.7847\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.4801 - binary_accuracy: 0.7917\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4788 - binary_accuracy: 0.7778\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4573 - binary_accuracy: 0.8264\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4495 - binary_accuracy: 0.8056\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.4461 - binary_accuracy: 0.8403\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4351 - binary_accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4485 - binary_accuracy: 0.8056\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4335 - binary_accuracy: 0.7986\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4093 - binary_accuracy: 0.8542\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.4168 - binary_accuracy: 0.8056\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.4115 - binary_accuracy: 0.8333\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3906 - binary_accuracy: 0.8819\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.3971 - binary_accuracy: 0.8264\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3859 - binary_accuracy: 0.8542\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3793 - binary_accuracy: 0.8542\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3820 - binary_accuracy: 0.8194\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3823 - binary_accuracy: 0.8542\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3706 - binary_accuracy: 0.8750\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3669 - binary_accuracy: 0.8611\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3686 - binary_accuracy: 0.8611\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3587 - binary_accuracy: 0.8889\n",
      "Epoch 38/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3483 - binary_accuracy: 0.8819\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.3628 - binary_accuracy: 0.8403\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3346 - binary_accuracy: 0.8889\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3489 - binary_accuracy: 0.8750\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3311 - binary_accuracy: 0.8889\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.3277 - binary_accuracy: 0.8750\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.3156 - binary_accuracy: 0.9167\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3295 - binary_accuracy: 0.8889\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3104 - binary_accuracy: 0.9097\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3104 - binary_accuracy: 0.8611\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.3501 - binary_accuracy: 0.8403\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3038 - binary_accuracy: 0.9028\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2937 - binary_accuracy: 0.9097\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.3017 - binary_accuracy: 0.9028\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.2929 - binary_accuracy: 0.8958\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.2811 - binary_accuracy: 0.9097\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2896 - binary_accuracy: 0.9236\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2743 - binary_accuracy: 0.9306\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2632 - binary_accuracy: 0.9167\n",
      "Epoch 57/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2900 - binary_accuracy: 0.9097\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 118us/step - loss: 0.2497 - binary_accuracy: 0.9097\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2582 - binary_accuracy: 0.9375\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 0s 97us/step - loss: 0.2493 - binary_accuracy: 0.9097\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.3165 - binary_accuracy: 0.8681\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2444 - binary_accuracy: 0.9167\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2458 - binary_accuracy: 0.9167\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2530 - binary_accuracy: 0.9097\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2324 - binary_accuracy: 0.9444\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2495 - binary_accuracy: 0.9236\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2462 - binary_accuracy: 0.9167\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.2302 - binary_accuracy: 0.9097\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2217 - binary_accuracy: 0.9375\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2109 - binary_accuracy: 0.9306\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2151 - binary_accuracy: 0.9306\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2295 - binary_accuracy: 0.9306\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2309 - binary_accuracy: 0.9097\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2536 - binary_accuracy: 0.8958\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.2075 - binary_accuracy: 0.9306\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1988 - binary_accuracy: 0.9583\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2476 - binary_accuracy: 0.9306\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1923 - binary_accuracy: 0.9514\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2031 - binary_accuracy: 0.9444\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 0s 132us/step - loss: 0.2070 - binary_accuracy: 0.9306\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 0s 125us/step - loss: 0.1807 - binary_accuracy: 0.9444\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1760 - binary_accuracy: 0.9583\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.2135 - binary_accuracy: 0.9306\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1893 - binary_accuracy: 0.9583\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1762 - binary_accuracy: 0.9583\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 0s 90us/step - loss: 0.1586 - binary_accuracy: 0.9514\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1938 - binary_accuracy: 0.9306\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 0s 104us/step - loss: 0.1787 - binary_accuracy: 0.9306\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1785 - binary_accuracy: 0.9375\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1711 - binary_accuracy: 0.9514\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1809 - binary_accuracy: 0.9375\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1712 - binary_accuracy: 0.9236\n",
      "Epoch 93/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1589 - binary_accuracy: 0.9583\n",
      "Epoch 94/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1428 - binary_accuracy: 0.9583\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1349 - binary_accuracy: 0.9583\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1380 - binary_accuracy: 0.9653\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1557 - binary_accuracy: 0.9444\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1755 - binary_accuracy: 0.9306\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 0s 111us/step - loss: 0.1324 - binary_accuracy: 0.9583\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 0s 118us/step - loss: 0.1242 - binary_accuracy: 0.9722\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "n_split = 10\n",
    "\n",
    "for train_index, test_index in KFold(n_split).split(x_train):\n",
    "    \n",
    "    \n",
    "    model = neural_model()\n",
    "    model.fit(x_train, encoded_y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 657us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5508243805024682, 0.8048780560493469]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00179562],\n",
       "       [0.65310025],\n",
       "       [0.36306882],\n",
       "       [0.9822478 ],\n",
       "       [0.89769125],\n",
       "       [0.28915465],\n",
       "       [0.01953667],\n",
       "       [0.97051835],\n",
       "       [0.00334761],\n",
       "       [0.94109356],\n",
       "       [0.01014447],\n",
       "       [0.08625752],\n",
       "       [0.9941151 ],\n",
       "       [0.37232274],\n",
       "       [0.01073679],\n",
       "       [0.98395205],\n",
       "       [0.963135  ],\n",
       "       [0.97889465],\n",
       "       [0.33112264],\n",
       "       [0.98239726],\n",
       "       [0.97019804],\n",
       "       [0.9909166 ],\n",
       "       [0.84243476],\n",
       "       [0.40469098],\n",
       "       [0.97338355],\n",
       "       [0.78242266],\n",
       "       [0.98521936],\n",
       "       [0.51934916],\n",
       "       [0.93468106],\n",
       "       [0.9831512 ],\n",
       "       [0.98867476],\n",
       "       [0.01825038],\n",
       "       [0.43786857],\n",
       "       [0.96216017],\n",
       "       [0.09783021],\n",
       "       [0.1792219 ],\n",
       "       [0.98956275],\n",
       "       [0.05810469],\n",
       "       [0.42179716],\n",
       "       [0.96470356],\n",
       "       [0.1928694 ]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
